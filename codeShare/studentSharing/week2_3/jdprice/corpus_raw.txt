<article url="https://finance.yahoo.com/news/27-incredible-examples-artificial-intelligence-061610973.html" parent_folder="ai_corpus" id="file14034839" filename="27-incredible-examples-artificial-intelligence-061610973.html">
<p> -40.03(-1.22%) </p>
<p> -402.30(-1.39%) </p>
<p> -92.96(-1.00%) </p>
<p> -28.17(-1.71%) </p>
<p> -0.20(-0.38%) </p>
<p> +1.70(+0.11%) </p>
<p> +0.07(+0.38%) </p>
<p> +0.0045(+0.4101%) </p>
<p> 27 Incredible Examples Of Artificial Intelligence (AI) And Machine Learning In Practice </p>
<p> There are so many amazing ways artificial intelligence and machine learning are used behind the scenes to impact our everyday lives and inform business decisions and optimize operations for some of the world’s leading companies. Here are 27 amazing practical examples of AI and machine learning. </p>
<p> Consumer goods </p>
<p> Using natural language processing, machine learning and advanced analytics, Hello Barbie listens and responds to a child. A microphone on Barbie’s necklace records what is said and transmits it to the servers at ToyTalk. There, the recording is analyzed to determine the appropriate response from 8,000 lines of dialogue. Servers transmit the correct response back to Barbie in under a second so she can respond to the child. Answers to questions such as what their favorite food is are stored so that it can be used in conversation later. </p>
<p> Coca-Cola’s global market and extensive product list—more than 500 drink brands sold in more than 200 countries—make it the largest beverage company in the world. Not only does the company create a lot of data, it has embraced new technology and puts that data into practice to support new product development, capitalize on artificial intelligence bots and even trialing augmented reality in bottling plants. </p>
<p> Even though Dutch company Heineken has been a worldwide brewing leader for the last 150 years, they are looking to catapult their success specifically in the United States by leveraging the vast amount of data they collect. From data-driven marketing to the Internet of Things to improving operations through data analytics, Heineken looks to AI augmentation and data to improve its operations, marketing, advertising and customer service. </p>
<p> Creative Arts </p>
<p> Culinary arts require the human touch, right? Yes and no. AI-enabled Chef Watson from IBM offers a glimpse of how artificial intelligence can become a sous-chef in the kitchen to help develop recipes and advise their human counterparts on food combinations to create completely unique flavors. Working together, AI and humans can create more in the kitchen than working alone. </p>
<p> Another way AI and big data can augment creativity is in the world of art and design. In one example, IBM’s machine learning system, Watson, was fed hundreds of images of artist Gaudi’s work along with other complementary material to help the machine learn possible influences for his work including Barcelona, its culture, biographies, historical articles and song lyrics. Watson analyzed all the information and delivered inspiration to the human artists who were charged with the creating a sculpture “informed” by Watson and in the style of Gaudi. </p>
<p> Music-generating algorithms are now inspiring new songs. Given enough input—millions of conversations, newspaper headlines and speeches—insights are gleaned that can help create a theme for lyrics. There are machines such as Watson BEAT that can come up with different musical elements to inspire composers. AI helps musicians understand what their audiences want and to help determine more accurately what songs might ultimately be hits. </p>
<p> Energy </p>
<p> Global energy leader, BP is at the forefront of realizing the opportunities big data and artificial intelligence has for the energy industry. They use the technology to drive new levels of performance, improve the use of resources and safety and reliability of oil and gas production and refining. From sensors that relay the conditions at each site to using AI technology to improve operations, BP puts data at the fingertips of engineers, scientists and decision-makers to help drive high performance. </p>
<p> In an attempt to deliver energy into the 21st century, GE Power uses big data, machine learning and Internet of Things (IoT) technology to build an “internet of energy.” Advanced analytics and machine learning enable predictive maintenance and power, operations and business optimization to help GE Power work toward its vision of a “digital power plant.” </p>
<p> Financial Services </p>
<p> With approximately 3.6 petabytes of data (and growing) about individuals around the world, credit reference agency Experian gets its extraordinary amount of data from marketing databases, transactional records and public information records. They are actively embedding machine learning into their products to allow for quicker and more effective decision-making. Over time, the machines can learn to distinguish what data points are important from those that aren’t. Insight extracted from the machines will allow Experian to optimize its processes. </p>
<p> Story continues </p>
<p> American Express processes $1 trillion in transaction and has 110 million AmEx cards in operation. They rely heavily on data analytics and machine learning algorithms to help detect fraud in near real time, therefore saving millions in losses. Additionally, AmEx is leveraging its data flows to develop apps that can connect a cardholder with products or services and special offers. They are also giving merchants online business trend analysis and industry peer benchmarking. </p>
<p> Healthcare </p>
<p> AI and deep learning is being put to use to save lives by Infervision. In China, where there aren’t enough radiologists to keep up with the demand of reviewing 1.4 billion CT scans each year to look for early signs of lung cancer. Radiologists need to review hundreds of scans each day which is not only tedious, but human fatigue can lead to errors. Infervision trained and taught algorithms to augment the work of radiologists to allow them to diagnose cancer more accurately and efficiently. </p>
<p> Neuroscience is the inspiration and foundation for Google’s DeepMind, creating a machine that can mimic the thought processes of our own brains. While DeepMind has successfully beaten humans at games, what’s really intriguing are the possibilities for healthcare applications such as reducing the time it takes to plan treatments and using machines to help diagnose ailments. </p>
<p> Manufacturing </p>
<p> Cars are increasingly connected and generate data that can be used in a number of ways. Volvo uses data to help predict when parts would fail or when vehicles need servicing, uphold its impressive safety record by monitoring vehicle performance during hazardous situations and to improve driver and passenger convenience. Volvo is also conducting its own research and development on autonomous vehicles. </p>
<p> BMW has big data-related technology at the heart of its business model and data guides decisions throughout the business from design and engineering to sales and aftercare. The company is also a leader in driverless technology and plans for its cars to deliver Level 5 autonomy—the vehicle can drive itself without any human intervention—by 2021. </p>
<p> The AI tech revolution has hit farming as well, and John Deere is getting data-driven analytical tools and automation into the hands of farmers. They acquired Blue River Technology for its solution to use advanced machine learning algorithms to allow robots to make decisions based on visual data about whether or not a plan is a pest to treat it with a pesticide. The company already offers automated farm vehicles to plough and sow with pinpoint-accurate GPS systems and its Farmsight system is designed to help agricultural decision-making. </p>
<p> Media </p>
<p> The BBC project, Talking with Machines is an audio drama that allows listeners to join in and have a two-way conversation via their smart speaker. Listeners get to be a part of the story as it prompts them to answer questions and insert their own lines into the story. Created specifically for smart speakers Amazon Echo and Google Home, the BBC expects to expand to other voice-activated devices in the future. </p>
<p> UK news agency Press Association (PA) is hoping robots and artificial intelligence might be able to save local news. They partnered with news automation specialist Urbs Media to have robots write 30,000 local news stories each month in a project called RADAR (Reporters and Data and Robots). Fed with a variety of data from government, public services and local authorities, the machine uses natural language generation technology to write local news stories. These robots are filling a gap in news coverage that wasn’t being filled by humans. </p>
<p> Big data analytics is helping Netflix predict what its customers will enjoy watching. They are also increasingly a content creator, not just a distributor, and use data to drive what content it will invest in creating. Due to the confidence they have in the data findings, they are willing to buck convention and commission multiple seasons of a new show rather than just a pilot episode. </p>
<p> Retail </p>
<p> When you first think of Burberry, you likely consider its luxury fashion and not first consider them a digital business. However, they have been busy reinventing themselves and use big data and AI to combat counterfeit products and improve sales and customer relationships. The company’s strategy for increasing sales is to nurture deep, personal connections with its customers. As part of that, they have reward and loyalty programs that create data to help them personalize the shopping experience for each customer. In fact, they are making the shopping experience at their brick-and-mortar stores just as innovative as an online experience. </p>
<p> As the world’s second-largest retailer, Walmart is on the cutting edge of finding ways to transform retail and provide better service to its customers. They use big data, machine learning, AI and the IoT to ensure a seamless experience between the online customer experience and the in-store experience (with 11,000 brick-and-mortar stores, something rival Amazon isn’t able to do. Enhancements include using the Scan and Go feature on the app, Pick-up Towers and they are experimenting with facial recognition technology to determine if customers are happy or sad. </p>
<p> Service </p>
<p> Central to everything Microsoft does is leveraging smart machines. Microsoft has Cortana, a virtual assistant; chatbots that run Skype and answer customer service queries or deliver info such as weather or travel updates and the company has rolled out intelligent features within its Office enterprise. Other companies can use the Microsoft AI Platform to create their own intelligent tools. In the future, Microsoft wants to see intelligent machines with generalized AI capabilities that allow them to complete any task. </p>
<p> When you bring together cloud computing, geo-mapping and machine learning, some really interesting things can happen. Google is using AI and satellite data to prevent illegal fishing. On any given day, 22 million data points are created that show where ships are in the world’s waterways. Google engineers found that when they applied machine learning to the data, they could identify why a vessel was at sea. They ultimately created Global Fishing Watch that shows where fishing is happening and could then identify when fishing was happening illegally. </p>
<p> Always at the top of delivery extraordinary service, Disney is getting even better thanks to big data. Every visitor gets their own MagicBand wristband that serves as ID, hotel room key, tickets, FastPasses and payment system. While guest enough the convenience, Disney gets a lot of data that helps them anticipate guests’ needs and deliver an amazing, personalized experience. They can resolve traffic jams, give extra services to guests who may have been inconvenienced by a closed attraction and data even allows the company to schedule staff more efficiently. </p>
<p> Google is one of the pioneers of deep learning from its initial foray with the Google Brain project in 2011. Google first used deep learning for image recognition and now is able to use it for image enhancement. Google has also applied deep learning to language processing and to provide better video recommendations on YouTube, because it studies viewers’ habits and preferences when they stream content. Next up, Google’s self-driving car division also leverages deep learning. Google also used machine learning to help it figure out the right configuration of hardware and coolers in their data centers to reduce the amount of energy expended to keep them operational. AI and machine learning has helped Google unlock new ways of sustainability. </p>
<p> Social Media </p>
<p> From what tweets to recommend to fighting inappropriate or racist content and enhancing the user experience, Twitter has begun to use artificial intelligence behind the scenes to enhance their product. They process lots of data through deep neural networks to learn over time what users preferences are. </p>
<p> Deep learning is helping Facebook draw value from a larger portion of its unstructured datasets created by almost 2 billion people updating their statuses 293,000 times per minute. Most of its deep learning technology is built on the Torch platform that focuses on deep learning technologies and neural networks. </p>
<p> Instagram also uses big data and artificial intelligence to target advertising and fight cyberbullying and delete offensive comments. As the amount of content grows in the platform, artificial intelligence is critical to be able to show users of the platform information they might like, fight spam and enhance the user experience. </p>
<p> Also, you might like to read more about how data and analytics are transforming HR in Data-Driven HR. It’s packed with real-life examples and practical ways HR teams can deliver maximum value in our increasingly data-driven world. </p>
</article>
<article url="https://www.usatoday.com/story/tech/2019/02/13/preventing-next-parkland-artificial-intelligence-may-help/2801369002/" parent_folder="ai_corpus" id="file14034866" filename="2801369002">
<p> Welcome to USA TODAY NETWORK’S EUROPEAN UNION EXPERIENCE </p>
<p> Can artificial intelligence prevent the next Parkland shooting? </p>
<p> Edward C. Baig USA TODAY </p>
<p> Published 2:30 PM EST Feb 14, 2019 </p>
<p> Schools are increasingly turning to artificial intelligence-backed solutions to stop tragic acts of student violence such as the shooting at the Marjory Stoneman Douglas High School in Parkland, Florida, a year ago. </p>
<p> Bark Technologies, Gaggle.Net, and Securly Inc. are three companies that employ AI and machine learning to scan student emails, texts, documents, and in some cases, social media activity. They look for warning signs of cyber bullying, sexting, drug and alcohol use, depression, and to flag students who may pose a violent risk not only to themselves, but classmates. </p>
<p> When potential problems are found, and depending on the severity, school administrators, parents – and under the most extreme cases – law enforcement officials, are alerted. </p>
<p> In the fall of 2017, Bark ran a test pilot with 25 schools. “We found some pretty alarming issues, including a bombing and school shooting threat,” says Bark chief parent officer, Titania Jordan. </p>
<p> A few months later Parkland happened and we knew what we had, and how it could help, but “we didn’t want to seem opportunistic or capitalize on a tragedy,” Jordan said. </p>
<p> The Bark product is free to schools in the U.S. for perpetuity. The company says it can afford to give the service away to schools, because of the money it makes from a version aimed at parents. </p>
<p> There are limitations. </p>
<p> None of the companies USA TODAY talked to for this story claim the ability to catch suspect behavior every time. Loosely defined, artificial intelligence describes machines that may demonstrate human behavior and learn from the data they digest. False positives sometimes arise. </p>
<p> A school can't police a student's smartphone or other devices outside the ones it issued, unless the student signed into a social media, or other account, using the email or credentials the school provided. </p>
<p> Students also are often more tech savvy than their parents and won't tell them about every account they have. </p>
<p> Parkland one year later: 'They have made change': 1 year after carnage in Parkland, where key figures are now </p>
<p> If an issue is detected, Bark sends a text and/or email alert to parents and schools, with recommended steps on how to address the issue. </p>
<p> Bark’s parent product costs $9 per month, per family, or $99 per year, and includes monitoring across more than 25 social media platforms, from Twitter and Instagram to Snapchat and YouTube. </p>
<p> Students from Marjory Stoneman Douglas High School make their way inside the Florida state Capitol in Tallahassee. </p>
<p> COLIN ABBEY, EPA-EFE </p>
<p> Bark is currently used in more than 1,100 school districts, covering 2.6 million children. If it detects something that is considered exceedingly severe such as a child abduction or school shooting threat, the issue is escalated to the FBI. </p>
<p> According to Jordan, Bark sends out between 35,000 and 55,000 alerts each day, many just instances of profanity. But 16 plausible school shootings have been reported to the FBI since Bark launched its school product last February, she says. </p>
<p> Preventing deaths by suicide </p>
<p> Gaggle, which has been around 20 years, charges schools $6 per student, per year. Since July 1, the company claims to have stopped 447 deaths by suicide at the 1,400 school districts that use its service, and that last year it prevented 542 potential deaths by suicide. </p>
<p> Gaggle also says it stopped 240 instances last year where a child brought a weapon to school to harm another student or intended to. Under such circumstances, Gaggle will immediately alert an emergency contact at the school and, if needed, law enforcement. </p>
<p> "Studies have shown that kids will communicate before a violent act happens and they will communicate electronically. If you don't have the means to hear those cries out for help you're going to have children in jeopardy," said Bill McCullough, vice president of sales at Gaggle. </p>
<p> Bark for Schools monitors student communications. </p>
<p> Bark </p>
<p> McCullough adds that the company doesn’t rely on machine learning alone to make threat determinations. If a Gaggle scan of school-issued emails and documents uncovers a child in crisis, the content is analyzed by trained human safety experts who verify whether the threat is legitimate and then determine its severity. If the threat is deemed minor, maybe the use of profanity, a student may be warned directly. If a student’s life is considered to be in jeopardy, an emergency contact at the school is notified immediately. </p>
<p> For its part, a third company, Securly, works with about 2,000 school districts. It charges $3 per student per year for a flagship product called Filter, with premium add-ons that can add about $2.50 per student to the cost. </p>
<p> This past October, one of Securly's premium services known as 24 – it combines AI with trained human analysts – flagged a student who had searched Google for both "how to make a bomb" and "how to kill yourself." The analyst contacted the school. </p>
<p> Another recent example involved a student who searched for "painless ways to kill yourself" and watched YouTube videos on the topic. </p>
<p> Real threat or harmless language? </p>
<p> As AI systems have become more sophisticated, so has the machines' ability to apply contextual analysis to determine if there’s real danger, or if school-age friends are harmlessly using what looks like threatening language to just rag on one another, maybe when playing a game. </p>
<p> “Our machine learning algorithm is smart enough to know the difference between a tween texting another tween “KMS” which stands for “kill myself” if they’re just embarrassed….and using it as a colloquialism. (Or) somebody with an actual propensity to have depression, anxiety or expressing the desire to take their own life or do harm," Jordan says. </p>
<p> McCullough at Gaggle, says the company’s algorithms are constantly being updated to detect the tone of despair in a message, to pick up symbols and misspellings, and to better analyze language. </p>
<p> “We’ve had suicides that we’ve stopped where there’s no word of “kill” or “suicide” in there, McCullough says. </p>
<p> Gaggle may even warn the authorities of threats coming not from a school district it monitors but outside. </p>
<p> "We had one instance where a third grade girl was getting solicited by an outside email address asking for nude pictures or that person was going to kill her parents," McCullough says. "She tried to send those pictures but because we run our service live, it never got out of our environment.” The person was arrested. </p>
<p> Balancing privacy, cost </p>
<p> There is a “delicate balance” on privacy, says Rob McCartney, director of technology at the Sioux Central school district in Iowa, which uses Bark. “Even though the school district we manage and maintain owns the student’s email addresses, the (student) has the right to a sufficient amount of privacy without us going in and looking and saying, `oh this is who your boyfriend is, or you came home late last night?’ That’s not what we’re there for.” </p>
<p> Vinay Mahadik, CEO of Securly, also navigates the fine line between privacy and security: “We go to a lot of effort in trying to be a responsible company. Not a single time has a parent that we’ve served or a school district that we helped come back and told us that this is an awful thing that you’re doing." </p>
<p> McCartney appreciates that Bark is free, given the tight budget constraints many school districts face. </p>
<p> But Rich O’Malley, superintendent of Florence 1 schools in South Carolina, a district which pays for Gaggle, says that “just saving one life or being able to touch one student who has an issue makes it priceless. As a superintendent, probably the number one issue I hear from parents is school security." </p>
<p> Email: ebaig@usatoday.com; Follow @edbaig on Twitter </p>
</article>
<article url="https://www.usatoday.com/story/money/2020/01/27/artificial-intelligence-how-invest/4542467002/" parent_folder="ai_corpus" id="file14034865" filename="4542467002">
<p> Welcome to USA TODAY NETWORK’S EUROPEAN UNION EXPERIENCE </p>
<p> How to invest in artificial intelligence </p>
<p> By Adam Shell Special to USA TODAY </p>
<p> Published 6:02 AM EST Jan 27, 2020 </p>
<p> The first big investment wave in tech was the personal computer. Then came software, the internet, smartphones, social media and cloud computing. </p>
<p> The next big thing is artificial intelligence, or AI, professional stock pickers say. </p>
<p> AI is the science-fiction-like technology in which computers are programmed to think and perform the tasks ordinarily done by humans. </p>
<p> The size of the global AI market is expected to grow to $202.6 billion by 2026, up from $20.7 billion in 2018, according to Fortune Business Insights. Funding of upstart AI companies by venture capitalists remains brisk. Last year, 956 deals valued at $13.5 billion took place through the third quarter, putting AI deal activity on pace for “another record year,” according to PitchBook-NVCA Venture Monitor. </p>
<p> Autonomous cars &nbsp; &nbsp; &bull; Category: Business A self-driving car uses sensors, cameras, radars, and artificial intelligence to do what humans may soon not do at all – transport themselves between destinations. Driverless cars are not yet available for the masses, but they are expected to revolutionize transportation as well as cause major disruptions to shipping industries. Waymo, which is owned by Alphabet, Google’s parent company, started testing driverless taxis in the Phoenix suburbs late last year. Several companies are testing autonomous cars in Pittsburgh. The University of Michigan has a test facility which, in partnership with Ford and Toyota, tests safety standards for autonomous vehicles. ALSO READ: Most Dangerous Countries for Women </p>
<p> metamorworks / Getty Images </p>
<p> Should you marry your money? After the wedding, should you marry your money in a joint account? Here are 3 approaches. </p>
<p> Apple store closed: Apple says it resolved outage that knocked out the App Store for some customers </p>
<p> Mike Lippert, manager of the Baron Opportunity fund, says AI touches more than half of the 60-plus stock holdings in his mutual fund. Those stocks are all about innovation, transformation and disruption, three traits AI has in abundance. </p>
<p> “I won’t claim AI is in every stock in the portfolio, but it’s all over my portfolio,” Lippert tells USA TODAY. </p>
<p> AI is creeping into every business, boosting productivity, customer service, sales, product innovation and operating efficiency. The technology is all about crunching reams of data from around the world, making sense of it and using the information to help businesses add services and operate more efficiently. </p>
<p> “AI applications can be found in virtually every industry today, from marketing to health care to finance,” Xiaomin Mou, IFC’s senior investment officer, wrote in a report. </p>
<p> It's paving the road to driverless cars, making decisions such as what lane to drive in and when to stop. It’s behind the software that tells salespeople which client prospect to call first. It's the brains behind virtual assistants that can interpret voice commands and play songs or provide weather updates. </p>
<p> “There are not a lot of companies, especially if they are growing, that are not benefiting from AI in some ways,” Lippert says. </p>
<p> The potential danger of AI, Lippert notes, is that advances such as autonomous driving and more sophisticated machine learning will take jobs from workers. </p>
<p> How can investors who want to get in early on the next Microsoft, Amazon, Apple or Facebook gain exposure to AI in a way that gives them the potential to profit over the long term without too much risk? </p>
<p> Investors must take a long-term approach and not just bet on one or two companies they think will emerge as big winners in AI, says Nidhi Gupta, technology sector leader at Fidelity Investments. </p>
<p> “Diversification is really important,” Gupta says, adding that investing in AI exposes investors to a “wide range of outcomes.” </p>
<p> In searching for AI winners, look for three things to “unlock value,” Gupta says. </p>
<p> 1. “Rich data sets” that help create the algorithms and apps that make people's lives better. </p>
<p> 2. “Scaled computing power” as big data centers with big servers are needed. </p>
<p> 3. “AI engineering talent” to avoid brainpower “bottlenecks.” </p>
<p> Among the AI stocks to watch: </p>
<p> •Big AI platforms: Leading AI players include well-known, large-cap tech stocks Google parent Alphabet (GOOGL), Amazon (AMZN) and Microsoft (MSFT). These three companies have the rich data sets, computing power and AI engineering talent that Gupta says are key to success. </p>
<p> •Chipmakers: Nvidia’s (NVDA) powerful and fast computer chips have been found effective for use in machine learning, AI training purposes, data centers and cloud-based computing. Another chipmaker with AI expertise is Xilinx (XLNX), says John Freeman, an analyst at Wall Street research firm CFRA. </p>
<p> •Companies benefiting from AI: Many businesses, such as Salesforce (CRM), stand apart from their peers and competitors by integrating AI into their business, says Baron’s Lippert. Salesforce Einstein AI, for example, analyzes all types of customer data, ranging from emails to tweets, to better predict which sales leads will convert to new business, he says. Netflix (NFLX) uses AI to recommend shows and programming viewers might like. China’s online retailer Alibaba (BABA) uses AI to crunch every customer interaction to make the online sales process smoother. Electric-car maker Tesla (TSLA) uses AI to enable software that is the driving force behind autonomous cars. </p>
<p> •Software makers: Other companies use AI to make software smarter and help solve business problems, Lippert says. Guidewire Software (GWRE), for example, uses AI to help insurers properly price policies, analyze risk, process submitted claims faster and identify insurance fraud. Adobe (ADBE) uses AI to analyze data to quickly identify cyberthreats. Datadog (DDOG) offers AI-inspired cloud monitoring services that let clients know if their web-based apps are behaving properly. </p>
<p> FICO (FICO) is best-known for calculating consumer credit scores. It uses AI to make sense of financial data to help clients, such as banks, determine the credit worthiness of borrowers or help detect fraud, CFRA’s Freeman says. </p>
<p> Investors who don’t want to pick their own stocks can invest in a tech-focused mutual fund or an ETF that focuses specifically on AI. Some examples include iShares Robotics & Artificial Intelligence ETF (IRBO) and Global X Robotics & Artificial Intelligence ETF (BOTZ). </p>
<p> “I do think AI is as significant an investing opportunity as the first era of computers,” Lippert says. </p>
<p> Investors should expect bumps in the road investing in AI, Freeman warns. </p>
<p> “This is a multi-decade trend,” he says. “AI is going to go through some mini-bubbles as well as some very healthy cycles.” </p>
</article>
<article url="https://www.washingtonpost.com/opinions/artificial-intelligence-can-transform-the-economy/2018/09/18/50c9c9c8-bab8-11e8-bdc0-90f81cc58c5d_story.html" parent_folder="ai_corpus" id="file14034868" filename="50c9c9c8-bab8-11e8-bdc0-90f81cc58c5d_story.html">
<p> Artificial intelligence can transform the economy </p>
<p> By Erik Brynjolfsson, Xiang Hui and Meng Liu </p>
<p> September 18, 2018 at 9:39 AM EDT </p>
<p> Erik Brynjolfsson is the director of the MIT Initiative on the Digital Economy and co-author, with Andrew McAfee, of “Machine/Platform/Crowd.” Xiang Hui is an assistant professor of marketing at Washington University, where Meng Liu is a visiting assistant professor of marketing; both are research fellows at the MIT initiative. </p>
<p> After half a century of hype and false starts, artificial intelligence may finally be starting to transform the U.S. economy. An example is machine translation, as we found when analyzing eBay’s deployment in 2014 of an AI-based tool that learned to translate by digesting millions of lines of eBay data and data from the Web. The aim is to allow eBay sellers and buyers in different countries to more easily connect with one another. The tool detects the location of an eBay user’s Internet Protocol address in, say, a Spanish-speaking country and automatically translates the English title of the eBay offering. </p>
<p> After eBay unveiled its English-Spanish translator for search queries and item titles, exports on eBay from the United States to Latin America increased by more than 17 percent. Other language pairs produced similarly significant gains. But the machine-learning tool is imperfect — it doesn’t translate the entire description of an eBay offering. Refinements would almost certainly drive even larger increases. </p>
<p> AD </p>
<p> AD </p>
<p> The eBay machine-translation results show how two barriers to productivity improvement can be overcome. That’s a reason for optimism, but it also warrants a renewed effort to ensure that the economic gains from artificial intelligence are widely shared. </p>
<p> First, the reason for optimism: Language differences that throughout history have hindered trade are steadily going to become irrelevant as machine translation shrinks the world. Historically, countries separated by languages or by geographic distance engaged in less trade than countries without those hurdles. Our research found that the increased trade enabled by machine translation was the equivalent of cutting the distance between countries by 37 percent. </p>
<p> In addition to lowering the language barrier to trade, machine learning will overcome the historic barrier know as Polanyi’s Paradox: “We know more than we can tell.” Bilingual people switch almost seamlessly between languages, translating almost as a reflex, but they’ve been unable to effectively explain to computers how to do it. Unlike previous information technologies that required humans to explicitly codify tasks for computers, machine learning is designed essentially to teach itself by automatically studying millions of examples, such as pairs of corresponding English and Spanish sentences. </p>
<p> AD </p>
<p> AD </p>
<p> The machine-learning approach has proven remarkably powerful, not only for language translation but also for speech recognition (Apple’s Siri), facial recognition (Facebook’s photo tagging), product recommendations (Amazon) and even cancer diagnoses. </p>
<p> Machine translation is of course just part of a broader technological revolution that is on the cusp of transforming industries and professions. Bigger changes will come with smarter algorithms and faster computers. As companies adopt these technologies, we can expect a productivity boom. </p>
<p> Surging productivity and the general rise in incomes it brings would be welcome, of course, but that isn’t sufficient. The same questions being raised about the advance of robotics in the workplace apply to machine learning. While new jobs would be created, many existing jobs — from doctors and financial advisers to translators and call-center operators — are susceptible to displacement or much-reduced roles. No economic law guarantees that productivity growth benefits everyone equally. Unless we thoughtfully manage the transition, some people, even a majority, are vulnerable to being left behind even as others reap billions. </p>
<p> AD </p>
<p> AD </p>
<p> Shared prosperity depends less on technology itself than on the choices made by each of us, as workers and entrepreneurs, and as citizens and voters. Entrepreneurs need to invent new business models, workers need access to new skills, and policymakers need to be urged by voters to invest in research that will redesign approaches to human learning for an era of machine learning. </p>
<p> At the Massachusetts Institute of Technology, the Inclusive Innovation Challenge was inaugurated three years ago to help speed the transition to a high-growth and high-opportunity digital economy. More than $1 million is awarded annually to recognize and reward people and organizations that are working toward the goal of more widely shared participation in the digital economy. </p>
<p> Award recipients include Laboratoria, a six-month coding boot camp that trains low-income women in both technical skills and soft skills such as teamwork and collaboration. After graduation, 80 percent of Laboratoria’s students find jobs that pay three times what they earned before the program. Another recipient, Apli, uses an AI-enabled chatbot to “interview” students, single mothers, shift workers and other job-seekers, then uses machine learning to match them with employment opportunities. This approach connects them with jobs within 24 hours rather than the 52-day average recruiting cycle. </p>
<p> AD </p>
<p> AD </p>
<p> Artificial intelligence is beginning to transform the economy. Human intelligence is needed to make sure it benefits the many, not just the few. </p>
<p> Today's Headlines </p>
<p> We noticed you’re blocking ads! </p>
<p> Keep supporting great journalism by turning off your ad blocker. Or purchase a subscription for unlimited access to real news you can count on. </p>
</article>
<article url="https://in.finance.yahoo.com/news/ai-machine-learning-innovation-virtual-214135902.html" parent_folder="ai_corpus" id="file14034850" filename="ai-machine-learning-innovation-virtual-214135902.html">
<p> -94.10(-1.01%) </p>
<p> -15,675.81(-2.31%) </p>
<p> -3.49(-1.79%) </p>
<p> -136.50(-0.52%) </p>
<p> AI-machine learning innovation: Virtual Humans to foldable screens, unlocking big gains for mankind </p>
<p> In 2014, artificial intelligence (AI) first passed the Turing test-designed by English mathematician and computer science pioneer Alan Turing in 1950, to check if a machine is capable of thinking like a human. Ever since, many pieces of AI tech have successfully passed the test. With current technology evolving much faster than before, technological innovations are breaching new frontiers every day. The recent Consumer Electronic Show (CES) seemed almost like the future dragged into the present. For instance, Samsung's NEON is a virtual human-actually, an AI chatbot with a human-like avatar that will converse with and learn from users until its 'emotion' and 'intelligence' are indistinguishable from a human's. The world has had digital personal assistants for a long time now, but NEON, Samsung says, won't be one; it will be a virtual human being. What need they serve is an important question. Loneliness, especially among the young, is on the rise in most of the developed world, and technology can play a role in addressing it-OECD data shows that the share of 15-year-olds that feel lonely at school rose sharply between 2003 and 2015, and in the US and UK, nearly a quarter of the adult population have reported feeling lonely or lacking companionship. Chatbots are increasingly being seen as a tool to combat depression, and the NEON avatar may do this better by acting as a friend. </p>
<p> Virtual humans, though, aren't the only talking point in consumer tech. While smartphone makers unveiled foldable phones last year, Dell and Lenovo have showcased laptops that can do the same. Acer last year had launched a dual-screen laptop, but new devices at CES have unity displays where the computer can turn into one giant tablet. Still a proof of concept-and likely expensive-folding screens are going to be the next significant innovation. It also means that as technology advances, tablets are going to lose out. Like point-and-shoot cameras have become redundant with the coming of smartphones-Xiaomi last year launched a phone with 108MP camera-tablets are headed for a similar trajectory if foldable phones can host an 8-9 inch screen. The latest from Samsung's stable has a 7.3-inch display. Although larger screens do translate into higher battery consumption, larger battery capacity would make phones clunkier. Companies, thus, will have to look for more efficient batteries as devices come equipped with more RAM and space. The highest specification in a smartphone, at 12GB RAM and 512 GB space, is already better than low-end laptops. </p>
<p> While smartphones are already increasingly replacing laptops, the pace is going to accelerate further. In the first quarter of 2010, 85 million PCs were sold worldwide, compared with 55 million smartphones. While analysts had predicted smartphone shipments to outstrip PC sales in 2012, this happened much earlier than expected. By the first quarter of 2011, PC shipments had fallen to 82 million whereas smartphone shipments crossed the 100-million mark. By 2018, laptop shipments at 161 million for the whole of the year were less than a tenth of total smartphone shipments. As smartphones look to consolidate the market-Samsung has been pushing DeX, which can turn it into a Windows-like OS-both laptops and tablets are going to lose out. The convergence of devices is finally coming. In the coming decade, there will be fewer screens, but reliance on technology and AI will increase. After all, if your friend and personal assistant can both reside in your phone, why look anywhere else? </p>
</article>
<article url="https://www.newyorker.com/magazine/2017/04/03/ai-versus-md" parent_folder="ai_corpus" id="file14034863" filename="ai-versus-md">
<p> A.I. Versus M.D. </p>
<p> In some trials, “deep learning” systems have outperformed human experts.Illustration by Daniel Savage </p>
<p> One evening last November, a fifty-four-year-old woman from the Bronx arrived at the emergency room at Columbia University’s medical center with a grinding headache. Her vision had become blurry, she told the E.R. doctors, and her left hand felt numb and weak. The doctors examined her and ordered a CT scan of her head. </p>
<p> A few months later, on a morning this January, a team of four radiologists-in-training huddled in front of a computer in a third-floor room of the hospital. The room was windowless and dark, aside from the light from the screen, which looked as if it had been filtered through seawater. The residents filled a cubicle, and Angela Lignelli-Dipple, the chief of neuroradiology at Columbia, stood behind them with a pencil and pad. She was training them to read CT scans. </p>
<p> “It’s easy to diagnose a stroke once the brain is dead and gray,” she said. “The trick is to diagnose the stroke before too many nerve cells begin to die.” Strokes are usually caused by blockages or bleeds, and a neuroradiologist has about a forty-five-minute window to make a diagnosis, so that doctors might be able to intervene—to dissolve a growing clot, say. “Imagine you are in the E.R.,” Lignelli-Dipple continued, raising the ante. “Every minute that passes, some part of the brain is dying. Time lost is brain lost.” </p>
<p> She glanced at a clock on the wall, as the seconds ticked by. “So where’s the problem?” she asked. </p>
<p> Strokes are typically asymmetrical. The blood supply to the brain branches left and right and then breaks into rivulets and tributaries on each side. A clot or a bleed usually affects only one of these branches, leading to a one-sided deficit in a part of the brain. As the nerve cells lose their blood supply and die, the tissue swells subtly. On a scan, the crisp borders between the anatomical structures can turn hazy. Eventually, the tissue shrinks, trailing a parched shadow. But that shadow usually appears on the scan several hours, or even days, after the stroke, when the window of intervention has long closed. “Before that,” Lignelli-Dipple told me, “there’s just a hint of something on a scan”—the premonition of a stroke. </p>
<p> The images on the Bronx woman’s scan cut through the skull from its base to the apex in horizontal planes, like a melon sliced from bottom to top. The residents raced through the layers of images, as if thumbing through a flipbook, calling out the names of the anatomical structures: cerebellum, hippocampus, insular cortex, striatum, corpus callosum, ventricles. Then one of the residents, a man in his late twenties, stopped at a picture and motioned with the tip of a pencil at an area on the right edge of the brain. “There’s something patchy here,” he said. “The borders look hazy.” To me, the whole image looked patchy and hazy—a blur of pixels—but he had obviously seen something unusual. </p>
<p> “Hazy?” Lignelli-Dipple prodded. “Can you describe it a little more?” </p>
<p> The resident fumbled for words. He paused, as if going through the anatomical structures in his mind, weighing the possibilities. “It’s just not uniform.” He shrugged. “I don’t know. Just looks funny.” </p>
<p> Lignelli-Dipple pulled up a second CT scan, taken twenty hours later. The area pinpointed by the resident, about the diameter of a grape, was dull and swollen. A series of further scans, taken days apart, told the rest of the story. A distinct wedge-shaped field of gray appeared. Soon after the woman got to the E.R., neurologists had tried to open the clogged artery with clot-busting drugs, but she had arrived too late. A few hours after the initial scan, she lost consciousness, and was taken to the I.C.U. Two months later, the woman was still in a ward upstairs. The left side of her body—from the upper arms to the leg—was paralyzed. </p>
<p> I walked with Lignelli-Dipple to her office. I was there to learn about learning: How do doctors learn to diagnose? And could machines learn to do it, too? </p>
<p> My own induction into diagnosis began in the fall of 1997, in Boston, as I started my clinical rotations. To prepare, I read a textbook, a classic in medical education, that divided the act of diagnosis into four tidy phases. First, the doctor uses a patient’s history and a physical exam to collect facts about her complaint or condition. Next, this information is collated to generate a comprehensive list of potential causes. Then questions and preliminary tests help eliminate one hypothesis and strengthen another—so-called “differential diagnosis.” Weight is given to how common a disease might be, and to a patient’s prior history, risks, exposures. (“When you hear hoofbeats,” the saying goes, “think horses, not zebras.”) The list narrows; the doctor refines her assessment. In the final phase, definitive lab tests, X-rays, or CT scans are deployed to confirm the hypothesis and seal the diagnosis. Variations of this stepwise process were faithfully reproduced in medical textbooks for decades, and the image of the diagnostician who plods methodically from symptom to cause had been imprinted on generations of medical students. </p>
<p> But the real art of diagnosis, I soon learned, wasn’t so straightforward. My preceptor in medical school was an elegant New Englander with polished loafers and a starched accent. He prided himself on being an expert diagnostician. He would ask a patient to demonstrate the symptom—a cough, say—and then lean back in his chair, letting adjectives roll over his tongue. “Raspy and tinny,” he might say, or “base, with an ejaculated thrum,” as if he were describing a vintage bottle of Bordeaux. To me, all the coughs sounded exactly the same, but I’d play along—“Raspy, yes”—like an anxious impostor at a wine tasting. </p>
<p> The taxonomist of coughs would immediately narrow down the diagnostic possibilities. “It sounds like a pneumonia,” he might say, or “the wet rales of congestive heart failure.” He would then let loose a volley of questions. Had the patient experienced recent weight gain? Was there a history of asbestos exposure? He’d ask the patient to cough again and he’d lean down, listening intently with his stethoscope. Depending on the answers, he might generate another series of possibilities, as if strengthening and weakening synapses. Then, with the élan of a roadside magician, he’d proclaim his diagnosis—“Heart failure!”—and order tests to prove that it was correct. It usually was. </p>
<p> A few years ago, researchers in Brazil studied the brains of expert radiologists in order to understand how they reached their diagnoses. Were these seasoned diagnosticians applying a mental “rule book” to the images, or did they apply “pattern recognition or non-analytical reasoning”? </p>
<p> Twenty-five such radiologists were asked to evaluate X-rays of the lung while inside MRI machines that could track the activities of their brains. (There’s a marvellous series of recursions here: to diagnose diagnosis, the imagers had to be imaged.) X-rays were flashed before them. Some contained a single pathological lesion that might be commonly encountered—perhaps a palm-shaped shadow of a pneumonia, or the dull, opaque wall of fluid that had accumulated behind the lining of the lung. Embedded in a second group of diagnostic images were line drawings of animals; within a third group, the outlines of letters of the alphabet. The radiologists were shown the three types of images in random order, and then asked to call out the name of the lesion, the animal, or the letter as quickly as possible while the MRI machine traced the activity of their brains. It took the radiologists an average of 1.33 seconds to come up with a diagnosis. In all three cases, the same areas of the brain lit up: a wide delta of neurons near the left ear, and a moth-shaped band above the posterior base of the skull. </p>
<p> Advertisement </p>
<p> “Our results support the hypothesis that a process similar to naming things in everyday life occurs when a physician promptly recognizes a characteristic and previously known lesion,” the researchers concluded. Identifying a lesion was a process similar to naming the animal. When you recognize a rhinoceros, you’re not considering and eliminating alternative candidates. Nor are you mentally fusing a unicorn, an armadillo, and a small elephant. You recognize a rhinoceros in its totality—as a pattern. The same was true for radiologists. They weren’t cogitating, recollecting, differentiating; they were seeing a commonplace object. For my preceptor, similarly, those wet rales were as recognizable as a familiar jingle. </p>
<p> In 1945, the British philosopher Gilbert Ryle gave an influential lecture about two kinds of knowledge. A child knows that a bicycle has two wheels, that its tires are filled with air, and that you ride the contraption by pushing its pedals forward in circles. Ryle termed this kind of knowledge—the factual, propositional kind—“knowing that.” But to learn to ride a bicycle involves another realm of learning. A child learns how to ride by falling off, by balancing herself on two wheels, by going over potholes. Ryle termed this kind of knowledge—implicit, experiential, skill-based—“knowing how.” </p>
<p> The two kinds of knowledge would seem to be interdependent: you might use factual knowledge to deepen your experiential knowledge, and vice versa. But Ryle warned against the temptation to think that “knowing how” could be reduced to “knowing that”—a playbook of rules couldn’t teach a child to ride a bike. Our rules, he asserted, make sense only because we know how to use them: “Rules, like birds, must live before they can be stuffed.” One afternoon, I watched my seven-year-old daughter negotiate a small hill on her bike. The first time she tried, she stalled at the steepest part of the slope and fell off. The next time, I saw her lean forward, imperceptibly at first, and then more visibly, and adjust her weight back on the seat as the slope decreased. But I hadn’t taught her rules to ride a bike up that hill. When her daughter learns to negotiate the same hill, I imagine, she won’t teach her the rules, either. We pass on a few precepts about the universe but leave the brain to figure out the rest. </p>
<p> Some time after Lignelli-Dipple’s session with the radiology trainees, I spoke to Steffen Haider, the young man who had picked up the early stroke on the CT scan. How had he found that culprit lesion? Was it “knowing that” or “knowing how”? He began by telling me about learned rules. He knew that strokes are often one-sided; that they result in the subtle “graying” of tissue; that the tissue often swells slightly, causing a loss of anatomical borders. “There are spots in the brain where the blood supply is particularly vulnerable,” he said. To identify the lesion, he’d have to search for these signs on one side which were not present on the other. </p>
<p> I reminded him that there were plenty of asymmetries in the image that he had ignored. This CT scan, like most, had other gray squiggles on the left that weren’t on the right—artifacts of movement, or chance, or underlying changes in the woman’s brain that preceded the stroke. How had he narrowed his focus to that one area? He paused as the thought pedalled forward and gathered speed in his mind. “I don’t know—it was partly subconscious,” he said, finally. </p>
<p> “That’s what happens—a clicking together—as you grow and learn as a radiologist,” Lignelli-Dipple told me. The question was whether a machine could “grow and learn” in the same manner. </p>
<p> In January, 2015, the computer scientist Sebastian Thrun became fascinated by a conundrum in medical diagnostics. Thrun, who grew up in Germany, is lean, with a shaved head and an air of comic exuberance; he looks like some fantastical fusion of Michel Foucault and Mr. Bean. Formerly a professor at Stanford, where he directed the Artificial Intelligence Lab, Thrun had gone off to start Google X, directing work on self-learning robots and driverless cars. But he found himself drawn to learning devices in medicine. His mother had died of breast cancer when she was forty-nine years old—Thrun’s age now. “Most patients with cancer have no symptoms at first,” Thrun told me. “My mother didn’t. By the time she went to her doctor, her cancer had already metastasized. I became obsessed with the idea of detecting cancer in its earliest stage—at a time when you could still cut it out with a knife. And I kept thinking, Could a machine-learning algorithm help?” </p>
<p> Early efforts to automate diagnosis tended to hew closely to the textbook realm of explicit knowledge. Take the electrocardiogram, which renders the heart’s electrical activity as lines on a page or a screen. For the past twenty years, computer interpretation has often been a feature of these systems. The programs that do the work tend to be fairly straightforward. Characteristic waveforms are associated with various conditions—atrial fibrillation, or the blockage of a blood vessel—and rules to recognize these waveforms are fed into the appliance. When the machine recognizes the waveforms, it flags a heartbeat as “atrial fibrillation.” </p>
<p> In mammography, too, “computer-aided detection” is becoming commonplace. Pattern-recognition software highlights suspicious areas, and radiologists review the results. But here again the recognition software typically uses a rule-based system to identify a suspicious lesion. Such programs have no built-in mechanism to learn: a machine that has seen three thousand X-rays is no wiser than one that has seen just four. These limitations became starkly evident in a 2007 study that compared the accuracy of mammography before and after the implementation of computer-aided diagnostic devices. One might have expected the accuracy of diagnosis to have increased dramatically after the devices had been implemented. As it happens, the devices had a complicated effect. The rate of biopsies shot up in the computer-assisted group. Yet the detection of small, invasive breast cancers—the kind that oncologists are most keen to detect—decreased. (Even later studies have shown problems with false positives.) </p>
<p> Thrun was convinced that he could outdo these first-generation diagnostic devices by moving away from rule-based algorithms to learning-based ones—from rendering a diagnosis by “knowing that” to doing so by “knowing how.” Increasingly, learning algorithms of the kind that Thrun works with involve a computing strategy known as a “neural network,” because it’s inspired by a model of how the brain functions. In the brain, neural synapses are strengthened and weakened through repeated activation; these digital systems aim to achieve something similar through mathematical means, adjusting the “weights” of the connections to move toward the desired output. The more powerful ones have something akin to layers of neurons, each processing the input data and sending the results up to the next layer. Hence, “deep learning.” </p>
<p> Thrun began with skin cancer; in particular, keratinocyte carcinoma (the most common class of cancer in the U.S.) and melanoma (the most dangerous kind of skin cancer). Could a machine be taught to distinguish skin cancer from a benign skin condition—acne, a rash, or a mole—by scanning a photograph? “If a dermatologist can do it, then a machine should be able to do it as well,” Thrun reasoned. “Perhaps a machine could do it even better.” </p>
<p> Advertisement </p>
<p> Traditionally, dermatological teaching about melanoma begins with a rule-based system that, as medical students learn, comes with a convenient mnemonic: ABCD. Melanomas are often asymmetrical (“A”), their borders (“B”) are uneven, their color (“C”) can be patchy and variegated, and their diameter (“D”) is usually greater than six millimetres. But, when Thrun looked through specimens of melanomas in medical textbooks and on the Web, he found examples where none of these rules applied. </p>
<p> Thrun, who had maintained an adjunct position at Stanford, enlisted two students he worked with there, Andre Esteva and Brett Kuprel. Their first task was to create a so-called “teaching set”: a vast trove of images that would be used to teach the machine to recognize a malignancy. Searching online, Esteva and Kuprel found eighteen repositories of skin-lesion images that had been classified by dermatologists. This rogues’ gallery contained nearly a hundred and thirty thousand images—of acne, rashes, insect bites, allergic reactions, and cancers—that dermatologists had categorized into nearly two thousand diseases. Notably, there was a set of two thousand lesions that had also been biopsied and examined by pathologists, and thereby diagnosed with near-certainty. </p>
<p> Esteva and Kuprel began to train the system. They didn’t program it with rules; they didn’t teach it about ABCD. Instead, they fed the images, and their diagnostic classifications, to the neural network. I asked Thrun to describe what such a network did. </p>
<p> “Imagine an old-fashioned program to identify a dog,” he said. “A software engineer would write a thousand if-then-else statements: if it has ears, and a snout, and has hair, and is not a rat . . . and so forth, ad infinitum. But that’s not how a child learns to identify a dog, of course. At first, she learns by seeing dogs and being told that they are dogs. She makes mistakes, and corrects herself. She thinks that a wolf is a dog—but is told that it belongs to an altogether different category. And so she shifts her understanding bit by bit: this is ‘dog,’ that is ‘wolf.’ The machine-learning algorithm, like the child, pulls information from a training set that has been classified. Here’s a dog, and here’s not a dog. It then extracts features from one set versus another. And, by testing itself against hundreds and thousands of classified images, it begins to create its own way to recognize a dog—again, the way a child does.” It just knows how to do it. </p>
<p> In June, 2015, Thrun’s team began to test what the machine had learned from the master set of images by presenting it with a “validation set”: some fourteen thousand images that had been diagnosed by dermatologists (although not necessarily by biopsy). Could the system correctly classify the images into three diagnostic categories—benign lesions, malignant lesions, and non-cancerous growths? The system got the answer right seventy-two per cent of the time. (The actual output of the algorithm is not “yes” or “no” but a probability that a given lesion belongs to a category of interest.) Two board-certified dermatologists who were tested alongside did worse: they got the answer correct sixty-six per cent of the time. </p>
<p> Thrun, Esteva, and Kuprel then widened the study to include twenty-five dermatologists, and this time they used a gold-standard “test set” of roughly two thousand biopsy-proven images. In almost every test, the machine was more sensitive than doctors: it was less likely to miss a melanoma. It was also more specific: it was less likely to call something a melanoma when it wasn’t. “In every test, the network outperformed expert dermatologists,” the team concluded, in a report published in Nature. </p>
<p> “There’s one rather profound thing about the network that wasn’t fully emphasized in the paper,” Thrun told me. In the first iteration of the study, he and the team had started with a totally naïve neural network. But they found that if they began with a neural network that had already been trained to recognize some unrelated feature (dogs versus cats, say) it learned faster and better. Perhaps our brains function similarly. Those mind-numbing exercises in high school—factoring polynomials, conjugating verbs, memorizing the periodic table—were possibly the opposite: mind-sensitizing. </p>
<p> When teaching the machine, the team had to take some care with the images. Thrun hoped that people could one day simply submit smartphone pictures of their worrisome lesions, and that meant that the system had to be undaunted by a wide range of angles and lighting conditions. But, he recalled, “In some pictures, the melanomas had been marked with yellow disks. We had to crop them out—otherwise, we might teach the computer to pick out a yellow disk as a sign of cancer.” </p>
<p> It was an old conundrum: a century ago, the German public became entranced by Clever Hans, a horse that could supposedly add and subtract, and would relay the answer by tapping its hoof. As it turns out, Clever Hans was actually sensing its handler’s bearing. As the horse’s hoof-taps approached the correct answer, the handler’s expression and posture relaxed. The animal’s neural network had not learned arithmetic; it had learned to detect changes in human body language. “That’s the bizarre thing about neural networks,” Thrun said. “You cannot tell what they are picking up. They are like black boxes whose inner workings are mysterious.” </p>
<p> The “black box” problem is endemic in deep learning. The system isn’t guided by an explicit store of medical knowledge and a list of diagnostic rules; it has effectively taught itself to differentiate moles from melanomas by making vast numbers of internal adjustments—something analogous to strengthening and weakening synaptic connections in the brain. Exactly how did it determine that a lesion was a melanoma? We can’t know, and it can’t tell us. All the internal adjustments and processing that allow the network to learn happen away from our scrutiny. As is true of our own brains. When you make a slow turn on a bicycle, you lean in the opposite direction. My daughter knows to do this, but she doesn’t know that she does it. The melanoma machine must be extracting certain features from the images; does it matter that it can’t tell us which? It’s like the smiling god of knowledge. Encountering such a machine, one gets a glimpse of how an animal might perceive a human mind: all-knowing but perfectly impenetrable. </p>
<p> Thrun blithely envisages a world in which we’re constantly under diagnostic surveillance. Our cell phones would analyze shifting speech patterns to diagnose Alzheimer’s. A steering wheel would pick up incipient Parkinson’s through small hesitations and tremors. A bathtub would perform sequential scans as you bathe, via harmless ultrasound or magnetic resonance, to determine whether there’s a new mass in an ovary that requires investigation. Big Data would watch, record, and evaluate you: we would shuttle from the grasp of one algorithm to the next. To enter Thrun’s world of bathtubs and steering wheels is to enter a hall of diagnostic mirrors, each urging more tests. </p>
<p> It’s hard not to be seduced by this vision. Might a medical panopticon that constantly scans us in granular—perhaps even cellular—detail, comparing images day by day, enable us to catch cancer at its earliest stages? Could it provide a breakthrough in cancer detection? It sounds impressive, but there’s a catch: many cancers are destined to be self-limited. We die with them, not of them. What if such an immersive diagnostic engine led to millions of unnecessary biopsies? In medicine, there are cases where early diagnosis can save or prolong life. There are also cases where you’ll be worried longer but won’t live longer. It’s hard to know how much you want to know. </p>
<p> Advertisement </p>
<p> “I’m interested in magnifying human ability,” Thrun said, when I asked him about the impact of such systems on human diagnosticians. “Look, did industrial farming eliminate some forms of farming? Absolutely, but it amplified our capacity to produce agricultural goods. Not all of this was good, but it allowed us to feed more people. The industrial revolution amplified the power of human muscle. When you use a phone, you amplify the power of human speech. You cannot shout from New York to California”—Thrun and I were, indeed, speaking across that distance—“and yet this rectangular device in your hand allows the human voice to be transmitted across three thousand miles. Did the phone replace the human voice? No, the phone is an augmentation device. The cognitive revolution will allow computers to amplify the capacity of the human mind in the same manner. Just as machines made human muscles a thousand times stronger, machines will make the human brain a thousand times more powerful.” Thrun insists that these deep-learning devices will not replace dermatologists and radiologists. They will augment the professionals, offering them expertise and assistance. </p>
<p> Geoffrey Hinton, a computer scientist at the University of Toronto, speaks less gently about the role that learning machines will play in clinical medicine. Hinton—the great-great-grandson of George Boole, whose Boolean algebra is a keystone of digital computing—has sometimes been called the father of deep learning; it’s a topic he’s worked on since the mid-nineteen-seventies, and many of his students have become principal architects of the field today. </p>
<p> “I think that if you work as a radiologist you are like Wile E. Coyote in the cartoon,” Hinton told me. “You’re already over the edge of the cliff, but you haven’t yet looked down. There’s no ground underneath.” Deep-learning systems for breast and heart imaging have already been developed commercially. “It’s just completely obvious that in five years deep learning is going to do better than radiologists,” he went on. “It might be ten years. I said this at a hospital. It did not go down too well.” </p>
<p> Hinton’s actual words, in that hospital talk, were blunt: “They should stop training radiologists now.” When I brought up the challenge to Angela Lignelli-Dipple, she pointed out that diagnostic radiologists aren’t merely engaged in yes-no classification. They’re not just locating the embolism that brought on a stroke. They’re noticing the small bleed elsewhere that might make it disastrous to use a clot-busting drug; they’re picking up on an unexpected, maybe still asymptomatic tumor. </p>
<p> Hinton now qualifies the provocation. “The role of radiologists will evolve from doing perceptual things that could probably be done by a highly trained pigeon to doing far more cognitive things,” he told me. His prognosis for the future of automated medicine is based on a simple principle: “Take any old classification problem where you have a lot of data, and it’s going to be solved by deep learning. There’s going to be thousands of applications of deep learning.” He wants to use learning algorithms to read X-rays, CT scans, and MRIs of every variety—and that’s just what he considers the near-term prospects. In the future, he said, “learning algorithms will make pathological diagnoses.” They might read Pap smears, listen to heart sounds, or predict relapses in psychiatric patients. </p>
<p> We discussed the black-box problem. Although computer scientists are working on it, Hinton acknowledged that the challenge of opening the black box, of trying to find out exactly what these powerful learning systems know and how they know it, was “far from trivial—don’t believe anyone who says that it is.” Still, it was a problem he thought we could live with. “Imagine pitting a baseball player against a physicist in a contest to determine where a ball might land,” he said. “The baseball player, who’s thrown a ball over and over again a million times, might not know any equations but knows exactly how high the ball will rise, the velocity it will reach, and where it will come down to the ground. The physicist can write equations to determine the same thing. But, ultimately, both come to the identical point.” </p>
<p> I recalled the disappointing results from older generations of computer-assisted detection and diagnosis in mammography. Any new system would need to be evaluated through rigorous clinical trials, Hinton conceded. Yet the new intelligent systems, he stressed, are designed to learn from their mistakes—to improve over time. “We could build in a system that would take every missed diagnosis—a patient who developed lung cancer eventually—and feed it back to the machine. We could ask, What did you miss here? Could you refine the diagnosis? There’s no such system for a human radiologist. If you miss something, and a patient develops cancer five years later, there’s no systematic routine that tells you how to correct yourself. But you could build in a system to teach the computer to achieve exactly that.” </p>
<p> Some of the most ambitious versions of diagnostic machine-learning algorithms seek to integrate natural-language processing (permitting them to read a patient’s medical records) and an encyclopedic knowledge of medical conditions gleaned from textbooks, journals, and medical databases. Both I.B.M.’s Watson Health, headquartered in Cambridge, Massachusetts, and DeepMind, in London, hope to create such comprehensive systems. I watched some of these systems operate in pilot demonstrations, but many of their features, especially the deep-learning components, are still in development. </p>
<p> Hinton is passionate about the future of deep-learning diagnosis, in part, because of his own experience. As he was developing such algorithms, his wife was found to have advanced pancreatic cancer. His son was diagnosed with a malignant melanoma, but then the biopsy showed that the lesion was a basal-cell carcinoma, a far less serious kind of cancer. “There’s much more to learn here,” Hinton said, letting out a small sigh. “Early and accurate diagnosis is not a trivial problem. We can do better. Why not let machines help us?” </p>
<p> On an icy March morning, a few days after my conversations with Thrun and Hinton, I went to Columbia University’s dermatology clinic, on Fifty-first Street in Manhattan. Lindsey Bordone, the attending physician, was scheduled to see forty-nine patients that day. By ten o’clock, the waiting room was filled with people. (Identifying details have been changed.) A bearded man, about sixty years old, sat in the corner concealing a rash on his neck with a woollen scarf. An anxious couple huddled over the Times. </p>
<p> Bordone saw her patients in rapid succession. In a fluorescent-lit room in the back, a nurse sat facing a computer and gave a one-sentence summary—“fifty years old with no prior history and new suspicious spot on the skin”—and then Bordone rushed into the examining room, her blond hair flying behind her. </p>
<p> A young man in his thirties had a scaly red rash on his face. As Bordone examined him, the skin flaked and fell off his nose. Bordone pulled him into the light and looked at the skin carefully, and then focussed her handheld dermoscope on it. </p>
<p> “Do you have dandruff in your hair?” she asked. </p>
<p> The man looked confused. “Sure,” he said. </p>
<p> “Well, this is facial dandruff,” Bordone told him. “It’s a particularly bad case. But the question is why it appeared now, and why it’s getting worse. Have you been using some new product in your hair? Is there some unusual stress in your family?” </p>
<p> Advertisement </p>
<p> “There’s definitely been some stress,” he said. He had lost his job recently, and was dealing with the financial repercussions. </p>
<p> “Keep a diary,” she advised. “We can determine if there’s a link.” She wrote a prescription for a steroidal cream, and asked him to return in a month. </p>
<p> In the next room, there was a young paralegal with a spray of itchy bumps on his scalp. He winced as Bordone felt his scalp. “Seborrheic dermatitis,” she said, concluding her exam. </p>
<p> The woman in another room had undressed and donned a hospital gown. In the past, she had been diagnosed with a melanoma, and she was diligent about getting preventive exams. Bordone pored over her skin, freckle by freckle. It took her twenty minutes, but she was thorough and comprehensive, running her fingers over the landscape of moles and skin tags and calling out diagnoses as she moved. There were nevi and keratoses, but no melanomas or carcinomas. </p>
<p> “Looks all good,” she said cheerfully at the end. The woman sighed in relief. </p>
<p> And so it went: Bordone came; she saw; she diagnosed. Far from Hinton’s coyote, she seemed like a somewhat manic roadrunner, trying to keep pace with the succession of cases that treadmilled beneath her. As she wrote her notes in the back room, I asked her about Thrun’s vision for diagnosis: an iPhone pic e-mailed to a powerful off-site network marshalling undoubted but inscrutable expertise. A dermatologist in full-time practice, such as Bordone, will see about two hundred thousand cases during her lifetime. The Stanford machine’s algorithm ingested nearly a hundred and thirty thousand cases in about three months. And, whereas each new dermatology resident needs to start from scratch, Thrun’s algorithm keeps ingesting, growing, and learning. </p>
<p> Bordone shrugged. “If it helps me make decisions with greater accuracy, I’d welcome it,” she said. “Some of my patients could take pictures of their skin problems before seeing me, and it would increase the reach of my clinic.” </p>
<p> That sounded like a reasonable response, and I remembered Thrun’s reassuring remarks about augmentation. But, as machines learn more and more, will humans learn less and less? It’s the perennial anxiety of the parent whose child has a spell-check function on her phone: what if the child stops learning how to spell? The phenomenon has been called “automation bias.” When cars gain automated driver assistance, drivers may become less alert, and something similar may happen in medicine. Maybe Bordone was a lone John Henry in a world where the steam drills were about to come online. But it was impossible to miss how her own concentration never wavered and how seriously she took every skin tag and mole that she ran her fingers over. Would that continue to be true if she partnered with a machine? </p>
<p> I noticed other patterns in Bordone’s interactions with her patients. For one thing, they almost always left feeling better. They had been touched and scrutinized; a conversation took place. Even the naming of lesions—“nevus,” “keratosis”—was an emollient: there was something deeply reassuring about the process. The woman who’d had the skin exam left looking fresh and unburdened, her anxiety exfoliated. </p>
<p> There was more. The diagnostic moment, as the Brazilian researchers might have guessed, came to Bordone in a flash of recognition. As she called out “dermatitis” or “eczema,” it was as if she were identifying a rhinoceros: you could almost see the pyramid of neurons in the lower posterior of her brain spark as she recognized the pattern. But the visit did not end there. In almost every case, Bordone spent the bulk of her time investigating causes. Why had the symptoms appeared? Was it stress? A new shampoo? Had someone changed the chlorine in the pool? Why now? </p>
<p> The most powerful element in these clinical encounters, I realized, was not knowing that or knowing how—not mastering the facts of the case, or perceiving the patterns they formed. It lay in yet a third realm of knowledge: knowing why. </p>
<p> Explanations run shallow and deep. You have a red blister on your finger because you touched a hot iron; you have a red blister on your finger because the burn excited an inflammatory cascade of prostaglandins and cytokines, in a regulated process that we still understand only imperfectly. Knowing why—asking why—is our conduit to every kind of explanation, and explanation, increasingly, is what powers medical advances. Hinton spoke about baseball players and physicists. Diagnosticians, artificial or human, would be the baseball players—proficient but opaque. Medical researchers would be the physicists, as removed from the clinical field as theorists are from the baseball field, but with a desire to know “why.” It’s a convenient division of responsibilities—yet might it represent a loss? </p>
<p> “A deep-learning system doesn’t have any explanatory power,” as Hinton put it flatly. A black box cannot investigate cause. Indeed, he said, “the more powerful the deep-learning system becomes, the more opaque it can become. As more features are extracted, the diagnosis becomes increasingly accurate. Why these features were extracted out of millions of other features, however, remains an unanswerable question.” The algorithm can solve a case. It cannot build a case. </p>
<p> Yet in my own field, oncology, I couldn’t help noticing how often advances were made by skilled practitioners who were also curious and penetrating researchers. Indeed, for the past few decades, ambitious doctors have strived to be at once baseball players and physicists: they’ve tried to use diagnostic acumen to understand the pathophysiology of disease. Why does an asymmetrical border of a skin lesion predict a melanoma? Why do some melanomas regress spontaneously, and why do patches of white skin appear in some of these cases? As it happens, this observation, made by diagnosticians in the clinic, was eventually linked to the creation of some of the most potent immunological medicines used clinically today. (The whitening skin, it turned out, was the result of an immune reaction that was also turning against the melanoma.) The chain of discovery can begin in the clinic. If more and more clinical practice were relegated to increasingly opaque learning machines, if the daily, spontaneous intimacy between implicit and explicit forms of knowledge—knowing how, knowing that, knowing why—began to fade, is it possible that we’d get better at doing what we do but less able to reconceive what we ought to be doing, to think outside the algorithmic black box? </p>
<p> I spoke to David Bickers, the chair of dermatology at Columbia, about our automated future. “Believe me, I’ve tried to understand all the ramifications of Thrun’s paper,” he said. “I don’t understand the math behind it, but I do know that such algorithms might change the practice of dermatology. Will dermatologists be out of jobs? I don’t think so, but I think we have to think hard about how to integrate these programs into our practice. How will we pay for them? What are the legal liabilities if the machine makes the wrong prediction? And will it diminish our practice, or our self-image as diagnosticians, to rely on such algorithms? Instead of doctors, will we end up training a generation of technicians?” </p>
<p> He checked the time. A patient was waiting to see him, and he got up to leave. “I’ve spent my life as a diagnostician and a scientist,” he said. “I know how much a patient relies on my capacity to tell a malignant lesion from a benign one. I also know that medical knowledge emerges from diagnosis.” </p>
<p> The word “diagnosis,” he reminded me, comes from the Greek for “knowing apart.” Machine-learning algorithms will only become better at such knowing apart—at partitioning, at distinguishing moles from melanomas. But knowing, in all its dimensions, transcends those task-focussed algorithms. In the realm of medicine, perhaps the ultimate rewards come from knowing together. ♦ </p>
<p> This Week’s Issue </p>
<p> Never miss a big New Yorker story again. Sign up for This Week’s Issue and get an e-mail every week with the stories you have to read. </p>
</article>
<article url="https://finance.yahoo.com/news/applications-machine-learning-life-sciences-095915938.html" parent_folder="ai_corpus" id="file14034840" filename="applications-machine-learning-life-sciences-095915938.html">
<p> Applications of Machine Learning in the Life Sciences Industry </p>
<p> Artificial intelligence (AI) is a term used to identify a scientific field that covers the creation of machines (e.g., robots) as well as computer hardware and software aimed at reproducing wholly or in part the intelligent behavior of human beings. AI is considered a branch of cognitive computing, a term that refers to systems able to learn, reason, and interact with humans. Cognitive computing is a combination of computer science and cognitive science. </p>
<p> Artificial intelligence covers various aspects of human behavior including creativity, planning and scheduling, reasoning, imaging, writing, learning, auditing, and natural language processing. The concept of artificial intelligence, however, is in continuous evolution. In fact, once the use of machines with specific smart features becomes widespread, new systems with even more advanced capabilities are developed. By enhancing equipment functionality and productivity, AI is revolutionizing virtually every sector, from research and development to manufacturing and services. </p>
<p> The Report Includes: </p>
<p> An overview of the global market outlook for machine learning in life sciences </p>
<p> Identification of machine learning applications in the life science sector </p>
<p> Recent achievements in life science due to machine learning </p>
<p> Strategies adopted in machine learning with a focus on life science (e.g., types of algorithms, regression trees, artificial neural networks, and evolutionary computation) </p>
<p> Information on Gaussian process models </p>
<p> Coverage of major issues related to machine learning </p>
<p> Analysis of current and emerging trends in machine learning </p>
<p> Recent Achievements in the Life Sciences Due to Machine Learning </p>
<p> Market Outlook for Machine Learning in the Life Sciences </p>
<p> List of Tables Table 1: Applications of Machine Learning in the Life Sciences, by Field Table 2: Global Market for the Applications of Machine Learning in the Quantum Computing, by Country/Region, Through 2024 Table 3: Current and Emerging Trends in the Applications of Machine Learning in the Life Sciences, by Field Table 4: Global Market for the Applications of Machine Learning in the Life Sciences, by Country/Region, Through 2024 </p>
<p> List of Figures Figure 1: Global Market Shares for the Applications of Machine Learning in the Quantum Computing, by Country/Region, 2024 Figure 2: Global Market Shares for the Applications of Machine Learning in the Life Sciences, by Country/Region, 2024 </p>
<p> About ResearchAndMarkets.com ResearchAndMarkets.com is the world's leading source for international market research reports and market data. We provide you with the latest data on international and regional markets, key industries, the top companies, new products and the latest trends. </p>
<p> Research and Markets also offers Custom Research services providing focused, comprehensive and tailored research. </p>
<p> CONTACT: ResearchAndMarkets.com Laura Wood, Senior Press Manager press@researchandmarkets.com For E.S.T Office Hours Call 1-917-300-0470 For U.S./CAN Toll Free Call 1-800-526-8630 For GMT Office Hours Call +353-1-416-8900 </p>
</article>
<article url="https://www.foxnews.com/tech/artificial-intelligence-global-battle-human-trafficking" parent_folder="ai_corpus" id="file14034862" filename="artificial-intelligence-global-battle-human-trafficking">
<p> How artificial intelligence is transforming the global battle against human trafficking </p>
<p> 'Fox Report' provides some insight into the horrors of human trafficking and the steps that law enforcement is taking to put a stop to it. </p>
<p> It’s one of the world’s deadliest and most barbaric global ventures. </p>
<p> Each year, human trafficking generates more than $150 billion in profits – at the expense of human life – with children accounting for around a third of its victims. It’s a practice that operates underground in almost every country on the planet, and despite the resources thrown at it -- by law enforcement, non-governmental organizations, social media campaigns – it only seems to grow. </p>
<p> Experts on the topic say the tools used in even in the most developed societies fall far short of what is needed to put a dent in this grim and growing enterprise. </p>
<p> But artificial intelligence (AI) and machine learning (ML)? Those could change the game. </p>
<p> “Anytime you have to ingest large amounts of data and information, you try to identify trends and patterns, and it can be very difficult to do well,” Alma Angotti, managing director at Navigant Consulting and a former U.S. regulation official for the Securities and Exchange Commission, and the Financial Industry Regulatory Authority told Fox News. “Typically, it has been a rules-based system – like flagging transactions over a certain amount such or with a certain amount of frequency. The problem with that is you can’t identify patterns and problems.” </p>
<p> The U.S. Department of Homeland Security defines trafficking, also referred to as modern-day slavery, as a crime that “involves the use of force, fraud,or coercion to obtain some type of labor or commercial sex act.” </p>
<p> AI and ML, Angotti said, have the power to analyze more than just financial activity. </p>
<p> “It can highlight social, economic and even political conditions from hundreds of thousands of sources,” she said. “For example, law enforcement can look at young women of a certain age entering the country from certain high-risk jurisdictions. Marry that up with social media and young people missing from home, or people associated with a false employment agency or who think they are getting a nanny job, and you start to develop a complete picture. And the information can be brought up all at once, rather than an analyst having to go through the Dark Web.” </p>
<p> In this Oct. 27, 2015, photo, Dawn Stenberg, from the Junior League of Sioux Falls, stands near the group's anti-human trafficking billboard in Sioux Falls, S.D. (AP) </p>
<p> The current anti-money laundering (AML) environment, Angotti pointed out, relies on “simple transaction-monitoring rules to detect human trafficking," and it "simply does not have the capacity to consider, weight and examine the necessary number of inputs.” </p>
<p> “The problem with it now is that it produces a lot of false positives, so the real issues are lost in the weeds. If you use more machine learning, you can program more variables and machines can use the information it has and then teach itself how to better identify patterns,” she said. </p>
<p> “You get better alerts, and alerts that are more likely to recognize real risks.” </p>
<p> Despite the potential, for now those tools remain underused, Angotti said. </p>
<p> “The government could increase the leveraging of technology to support trained law enforcement in tackling this complex issue. It would be helpful to match dataholders – government and financial institutions – with computational science and AI partners to provide deployable tools to identify human trafficking activity and the money flows associated with it,” she said. “The same networks that traffickers use to recruit their victims can also be used as the source of data to detect criminal activity.” </p>
<p> QuantaVerse CEO and founder David McLaughlin said that while small steps are having a significant impact, there is much more that can be done. Artificial intelligence can follow the money created by human trafficking operations. That means that instead of identifying only lower-level human traffickers, the “beneficial owners” or kingpins of these operations can be discovered, he said. </p>
<p> “AI is better at finding suspicious financial activity than legacy technology alone. Today, banks are required by regulators to report unusual banking activity by filing Suspicious Activity Reports (SARs) to FinCEN. To do this, banks’ anti-money laundering (AML) teams currently rely on antiquated, rules-based Transaction Monitoring Systems (TMS),” McLaughlin explained. “Suspicious transactions are ‘flagged’ by the TMS and handed over to human investigators to determine if a flag should be reported to the authorities. </p>
<p> " Unfortunately, 95 percent of the flags produced by the TMS systems are benign and waste vital investigative resources. Even worse, TMS systems are missing crimes that are going through the banking system undiscovered.” </p>
<p> McLaughlin said AI automates the investigative digging and then produces reports of its findings. AML investigators can now spend their valuable time/expertise analyzing AI findings and making determinations on what may be human trafficking activity faster than ever. </p>
<p> Technology is also playing a prominent role in the private sector, with a community rather than a top-down approach. The revolution of apps has also revolutionized the fight against modern-day slavery, with an added focus on the next step – converting data into something actionable. </p>
<p> U.S. researchers developed an AI engine earlier this year, entitled Hotels-50K, which recognizes a hotel from an image of a hotel room -- a critical development for human trafficking investigations. </p>
<p> “Images directly link victims to places and can help verify where victims have been trafficked and where their traffickers might move them or others in the future. Recognizing the hotel from images is challenging because of low image quality, uncommon camera perspectives, large occlusions (often the victim), and the similarity of objects (e.g., furniture, art, bedding) across different hotel rooms,” the developers wrote. “To support efforts towards this hotel recognition task, we have curated a dataset of over 1 million annotated hotel room images from 50,000 hotels.” </p>
<p> FILE- In this Tuesday, Oct. 9, 2018, file photo New Google Pixel 3 smartphones are displayed in New York. Google’s new Pixel 3 phone plays catch-up with Apple and Samsung on hardware. It’s really designed to showcase Google’s advances in software, particularly in artificial intelligence. (AP Photo/Richard Drew, File) </p>
<p> Those images include professionally captured photographs from travel websites and crowd-sourced images from a mobile application, the developers continued, which are more similar to the types of images analyzed in real-world investigations. The analysts then endeavor to present “a baseline approach based on standard network architecture and a collection of data-augmentation approaches tuned to this problem domain.” </p>
<p> Meanwhile, the “STOP APP” is designed to “enable people anywhere in the world to report suspicious incidents of human trafficking anonymously and securely.” The information submitted is then uploaded directly into a secure database for the app’s parent organization, Stop the Traffik, where it is analyzed alongside multiple different datasets on human trafficking and modern slavery activity. The raw data is used to develop trend reports and alert authorities and communities where necessary. </p>
<p> The likes of IBM have partnered with international money exchange authorities such as Western Union to develop a cloud-centric database to detect questionable payments, identified through established patterns and concerns proven to have highlighted trafficking cases in times past. And the team at HumanSlavery.com is currently developing a “unique solution” involving a reporting mechanism with location tracking that utilizes both existing sensors such as cameras and heat sensors in addition to law enforcement databases to create a map – using artificial intelligence – on which authorities can then operate. </p>
<p> However, experts caution that technology can only ever be a slice of the solution. "The first thing to keep in mind is that human trafficking is a fundamentally human problem, to which AI can only be a small part of the solution. Sex trafficking, for instance, arises as part of a dysfunctional ecosystem created by a host of economic, sociological, and regulatory problems,” added Notre Dame Adjunct Professor of Law, Alexandra Yelderman. “At best, AI will be as good as humans at untangling those complex issues, but probably won't be better.” </p>
<p> Hollie McKay has a been a Fox News Digital staff reporter since 2007. She has extensively reported from war zones including Iraq, Syria, Yemen, Afghanistan, Pakistan, Burma, and Latin America investigates global conflicts, war crimes and terrorism around the world. Follow her on Twitter. </p>
</article>
<article url="https://finance.yahoo.com/news/artificial-intelligence-industrial-iot-smart-111432646.html" parent_folder="ai_corpus" id="file14034841" filename="artificial-intelligence-industrial-iot-smart-111432646.html">
<p> -39.96(-1.22%) </p>
<p> -409.53(-1.42%) </p>
<p> -92.89(-1.00%) </p>
<p> -28.15(-1.71%) </p>
<p> -0.20(-0.38%) </p>
<p> +1.70(+0.11%) </p>
<p> +0.07(+0.38%) </p>
<p> +0.0045(+0.4101%) </p>
<p> Artificial Intelligence, Industrial IoT, and Smart Machines in Enterprise & Industrial Automation (2019-2024) </p>
<p> Embedded AI in support of IIoT smart objects will reach $4.6B globally by 2024 </p>
<p> Hybrid voice and text chatbots market will reach $331.5M USD globally by 2024 </p>
<p> Overall market for AI in big data and IoT will be led by Asia Pac followed by North America </p>
<p> The fastest growing smart machine technology area Neuro-computing, will grow at 22.2% CAGR </p>
<p> AI in industrial machines will reach $415M globally by 2024 with collaborative robot growth at 42.5% CAGR </p>
<p> Smart machines and systems will benefit greatly from low latency and localized processing via 5G and MEC </p>
<p> Artificial Intelligence (AI) algorithms enhance the ability for big data analytics and IoT platforms to provide value to each of these market segments. The report sees three different types of IoT Data: (1) Raw (untouched and unstructured) Data, (2) Meta (data about data), and (3) Transformed (valued-added data). Artificial Intelligence (AI) will be useful in support of managing each of these data types in terms of identifying, categorizing, and decision making. AI coupled with advanced big data analytics provides the ability to make raw data meaningful and useful as information for decision-making purposes. The use of AI for decision making in IoT and data analytics will be crucial for efficient and effective decision making, especially in the area of streaming data and real-time analytics associated with edge computing networks. </p>
<p> Industrial Internet of Things (IIoT) solutions are poised to transform many industry verticals including healthcare, retail, automotive, and transport. For many industries, IIoT will significantly improve reliability, production, and customer satisfaction. While IIoT will initially improve existing processes and augmented current infrastructure, the ultimate goal will be to realize entirely new, and dramatically improved products and services. </p>
<p> Successful companies will be those that understand how and where IoT technologies and solutions will drive opportunities for operational improvements, new and enhanced products and services, as well as completely new business models. IIoT will significantly improve reliability, production, and customer satisfaction. Initially focusing on improving existing processes and augmented current infrastructure, IIoT will rely upon as well as integrate with certain key technologies, devices, software, and applications. IIoT involves a substantial breadth and depth of technologies, many of which require careful integration and orchestration. </p>
<p> Smart machines collectively represent intelligent devices, machinery, equipment, and embedded automation software that perform repetitive tasks and solve complex problem autonomously. Along with Artificial Intelligence, IoT connectivity, and M2M communications, smart machines are a key component of smart systems, which include many emerging technologies such as smart dust, neuro computing, and advanced robotics. The drivers for enterprise and industrial adoption of smart machines include improvements in the smart workplace, smart data discovery, cognitive automation, and more. </p>
<p> Currently conceived smart machine products include autonomous robots (such as service robots), self-driving vehicles, expert systems (such as medical decision support systems), medical robots, intelligent assistants (such as automated online assistants), virtual private assistants (Siri, Google Assistant, Amazon Alexa, etc.), embedded software systems (such as machine monitoring and control systems), neurocomputers (such as purpose-built intelligent machines), and smart wearable devices. </p>
<p> This research evaluates various AI technologies and their use relative to analytics solutions within the rapidly growing enterprise and industrial data arena. The report assesses emerging business models, leading companies, and solutions. It also analyzes how different forms of AI may be best used for problem-solving. The report also evaluates the market for AI in IoT networks and systems. It provides forecasting for unit growth and revenue for both analytics and IoT from 2019-2024. </p>
<p> This research also provides and in-depth assessment of the chatbots market including global, regional, and country forecasts. by industry, application, and business model. The report also includes market sizing by Type (Text, Voice, and Hybrid), Use Case, Deployment Type, Value Chain Component, Market Segment (Consumer, Enterprise, Industrial, Government), Industry Vertical for years 2019 through 2024. The report provides analysis of the chatbot market across industry verticals with use cases in diverse sectors. It also provides analysis of chatbot companies including their strategic initiatives, solutions, applications, and services. </p>
<p> This research also evaluates IIoT technologies, companies, applications, services, and solutions. Report forecasts include overall global and regional IIoT outlook as well as IIoT by industry vertical, software, hardware, and services for the period 2019 to 2024. This research is critical to identifying opportunities for R&D, technology integration, and development of new solutions and applications across industry segments. Our findings, insights, data and forecasts are also a key part of capitalizing upon the market for new and enhanced hardware, software, platforms, and services for emerging IoT networks and systems. In support of these goals, the report provides critical analysis about IIoT technologies, companies, applications, services, and solutions. </p>
<p> This research also evaluates the smart machine ecosystem including technology building blocks, leading company strategies, products and services. The report evaluates various smart machine solutions, products, and services including Autonomous Robots, Expert Systems, Intelligent Assistants, Neurocomputers, and Wearable Devices. This report also evaluates the hardware, embedded software, and related services for smart machines. The report also assesses the market for smart machines in many industry verticals including Aerospace and Defense, Automotive, Banking, Consumer Electronics, Healthcare, Industrial Automation, Security, Transportation and Logistics. </p>
<p> Story continues </p>
<p> Key Topics Covered </p>
<p> Artificial Intelligence in Big Data Analytics and IoT: Market for Data Capture, Information and Decision Support Services 1. Executive Summary </p>
<p> 2. Introduction 2.1 Research Objectives 2.2 Key Findings 2.3 Target Audience 2.4 Companies in the Report </p>
<p> 3. Overview 3.1 Artificial Intelligence and Machine Learning 3.2 AI Types 3.3 AI & ML Language 3.4 Artificial Intelligence Technology 3.4.1 Machine Learning 3.4.2 Natural Language Generation and Processing 3.4.3 Image Processing 3.4.4 Voice Recognition 3.4.5 Artificial Neural Network 3.4.6 Deep Learning 3.4.7 Others 3.5 AI and ML Technology Goal 3.5.1 Reasoning 3.5.2 Knowledge Representation 3.5.3 Planning 3.5.4 Learning 3.5.5 Communication 3.5.6 Machine Perception 3.5.7 Motion Manipulation 3.5.8 Social Intelligence 3.5.9 Creativity 3.5.10 Artificial General Intelligence 3.5.11 Computer Vision 3.5.12 Robotics 3.6 AI Approaches 3.6.1 Cybernetics and Brian Simulation 3.6.2 Symbolic 3.6.3 Sub-Symbolic 3.6.4 Statistical 3.6.5 Integration 3.7 AI Tools 3.7.1 Search and Optimization 3.7.2 Logic 3.7.3 Probability 3.7.4 Classifier and Statistics 3.7.5 Neural Network 3.7.6 Deep Feedforward Neural Network 3.7.7 Deep Recurrent Neural Network 3.7.8 Control Theory 3.7.9 Language 3.8 AI Outcome 3.8.1 Testing Tools 3.8.2 Virtual Assistant 3.8.3 AI Optimized IoT Hardware 3.8.4 Decision Management System 3.8.5 Biometrics Solution 3.8.6 Robotic Process Automation 3.9 Neural Network and Artificial Intelligence 3.10 Deep Learning and Artificial Intelligence 3.11 Predictive Analytics and Artificial Intelligence 3.12 Internet of Things and Big Data Analytics 3.13 IoT and Artificial Intelligence 3.14 Consumer IoT, Big Data Analytics, and Artificial Intelligence 3.15 Industrial IoT, Big Data Analytics, and Machine Learning 3.16 Artificial intelligence and cognitive computing 3.17 Transhumanism or H+ and Artificial Intelligence 3.18 Rise of Analysis of Things (AoT) 3.19 Supervised vs. Unsupervised Learning 3.20 AI as New form of UI </p>
<p> 4. AI Technology in Big Data and IoT 4.1 Machine Learning Everywhere 4.1.1 Machine Learning as Open Source Technology 4.1.2 Machine Learning and Intelligent Discovery in IoT 4.1.3 Supervised and Unsupervised Machine Learning 4.1.4 Machine Learning as Big Data Analysis Technique 4.1.5 Machine Learning AI Robots 4.1.6 Machine Learning and Data Democratization 4.2 Machine Learning APIs and Big Data Development 4.2.1 Phases of Machine Learning APIs 4.2.2 Machine Learning API Challenges 4.2.3 Top Machine Learning APIs 4.2.3.1 IBM Watson API 4.2.3.2 Microsoft Azure Machine Learning API 4.2.3.3 Google Prediction API 4.2.3.4 Amazon Machine Learning API 4.2.3.5 BigML 4.2.3.6 AT&T Speech API 4.2.3.7 Wit.ai 4.2.3.8 AlchemyAPI 4.2.3.9 Diffbot 4.2.3.10 PredictionIO 4.2.4 Machine Learning API in General Application Environment 4.3 Enterprise Benefits of Machine Learning 4.4 Machine Learning in IoT Data 4.5 Ultra Scale Analytics and Artificial Intelligence 4.6 Rise of Algorithmic Business 4.7 Cloud Hosted Machine Intelligence 4.8 Contradiction of Machine Learning 4.9 Value Chain Analysis 4.9.1 AI & Machine Learning Companies 4.9.2 IoT Companies 4.9.3 Big Data Analytics Providers 4.9.4 Connectivity Solution and Infrastructure Providers 4.9.5 Hardware and Equipment Manufacturers 4.9.6 Developers and Data Scientists 4.9.7 End Users </p>
<p> 5. AI Technology Application and Use Case 5.1 Intelligence Performance Monitoring 5.2 Infrastructure Monitoring 5.3 Generating Accurate Models 5.4 Recommendation Engine 5.5 Blockchain and Crypto Technologies 5.6 Enterprise Application 5.7 Contextual Awareness 5.8 Customer Feedback 5.9 Self-Driving Car 5.10 Fraud Detection System 5.11 Personalized Medicine and Healthcare Service 5.12 Predictive Data Modelling 5.13 Smart Machines 5.14 Cybersecurity Solutions 5.15 Autonomous Agents 5.16 Intelligent Assistant 5.17 Intelligent Decision Support System 5.18 Risk Management 5.19 Data Mining and Management 5.20 Intelligent Robotics 5.21 Financial Technology 5.22 Machine Intelligence </p>
<p> 6. AI Technology Impact on Vertical Market 6.1 Enterprise Productivity Gain 6.2 Digital Twinning and Physical Asset Security 6.3 IT Process Efficiency Increase 6.4 AI to Replace Human Form Work 6.5 Enterprise AI Adoption Trend 6.6 Inclusion of AI as IT Requirement </p>
<p> 7. AI Predictive Analytics in Vertical Industry 7.1 E-Commerce Services 7.2 Banking and Finance Services 7.3 Manufacturing Services 7.4 Real Estate Services 7.5 Government and Public Services </p>
<p> 8. Company Analysis 8.1 Google Inc. 8.2 Twitter Inc. 8.3 Microsoft Corporation 8.4 IBM Corporation 8.5 Apple Inc. 8.6 Facebook Inc. 8.7 Amazon.com Inc. 8.8 Skype 8.9 Salesforce.com 8.10 Intel Corporation 8.11 Yahoo Inc. 8.12 AOL Inc. 8.13 NVIDIA Corporation 8.14 x.ai 8.15 Tesla Inc. 8.16 Baidu Inc. 8.17 H2O.ai 8.18 SparkCognition Inc. 8.19 OpenAI 8.20 Inbenta 8.21 CISCO Systems Inc. 8.22 Infineon Technologies AG 8.23 McAfee 8.24 Happiest Minds Technologies 8.25 Tachyus 8.26 Sentrian 8.27 MAANA 8.28 Veros Systems Inc. 8.29 NEURA 8.30 Augury Systems Ltd. 8.31 glassbeam 8.32 Comfy 8.33 mnubo 8.34 C-B4 8.35 PointGrab Ltd. 8.36 Tellmeplus 8.37 moov 8.38 Sentenai Inc. 8.39 imagimob 8.40 FocusMotion 8.41 MoBagel </p>
<p> 9. AI in Big Data and IoT Market Analysis and Forecasts 2019 - 2024 9.1 AI in Big Data and IoT Market 2019 - 2024 9.2 AI in Big Data and IoT Market by Solution Components 2019 - 2024 9.2.1 Embedded AI Solutions 9.2.1.1 IoT Device 9.2.1.1.1 Wearable Devices 9.2.1.1.2 Medical and Healthcare Devices 9.2.1.1.3 Industrial Machines 9.2.1.1.4 Networking Device 9.2.1.1.5 Smart Grid Device 9.2.1.1.6 Robots and Drone 9.2.1.1.6.1 Service Robots 9.2.1.1.7 Smart Appliances 9.2.1.1.8 Security Devices 9.2.1.1.9 Entertainment Devices 9.2.1.1.10 In-Vehicle Device 9.2.1.1.11 Military Device 9.2.1.1.12 Energy Management Device 9.2.1.1.13 Agriculture Specific Device 9.2.1.2 IoT Things/Objects 9.2.1.3 Software 9.2.1.3.1 Digital Personal Assistants 9.2.1.4 IoT Platform 9.2.2 Storage and Analytics 9.2.2.1 Storage and Analytics Tools 9.2.3 Services 9.2.3.1 Professional Services 9.3 AI in Big Data and IoT Market by Management Functions 9.4 AI in Big Data and IoT Market by Technology 9.4.1 Machine Learning 9.5 AI in Big Data and IoT Market by Industry Vertical 9.5.1 Medical and Healthcare 9.5.2 Manufacturing 9.5.3 Consumer Electronics 9.5.4 Automotive and Transportation 9.5.5 Retail and Apparel 9.5.6 Marketing and Advertising 9.5.7 FinTech 9.5.8 Building and Construction 9.5.9 Agriculture 9.5.10 Security and Surveillance 9.5.11 Government, Military, and Aerospace 9.5.12 Human Resource 9.5.13 Legal and Law 9.5.14 Telecommunication and IT 9.5.15 Oil, Gas, and Mining 9.5.16 Logistics 9.5.17 Education and Learning 9.6 AI in Big Data and IoT Market by Solution 9.7 AI in Big Data and IoT Market by Application 9.8 AI in Big Data and IoT Market by Deployment 9.8.1 Cloud Deployment 9.9 AI in Big Data and IoT Market by AI System 9.10 AI in Big Data and IoT Market by AI Type 9.11 AI in Big Data and IoT Market by Connectivity 9.11.1 Non-Telecom Connectivity 9.11.2 Telecom Connectivity 9.11.3 Connectivity Standard 9.11.4 Enterprise 9.12 AI in Big Data and IoT Market by Edge Network 9.13 AI in Big Data and IoT Market in Smart City 9.14 AI in Big Data and IoT Market by Intent Based Networking 9.15 AI in Big Data and IoT Market by Virtualization 9.16 AI in Big Data and IoT Market by 5G 9.17 AI in Big Data and IoT Market by Blockchain Networks 9.18 AI in Big Data and IoT Market by Region 9.18.1 North America 9.18.2 Asia Pacific 9.18.2.1 China 9.18.2.2 South Korea 9.18.2.3 Taiwan 9.18.2.4 Rest of Asia 9.18.3 Europe 9.18.4 Middle East and Africa 9.18.5 Latin America </p>
<p> 10. Conclusions and Recommendations 10.1 AI Prediction 10.2 Data Analytics Providers 10.3 AI and Machine Learning Companies 10.4 IoT Companies and Equipment Manufacturers 10.5 Service Providers 10.6 Enterprises </p>
<p> 11. Appendix 11.1 AI Embedded IoT Unit Deployment Forecast 11.1.1 IoT Unit Deployment by Solution 11.1.1.1 IoT Device 11.1.1.2 IoT Things and Objects 11.1.1.3 IoT Semiconductor 11.1.1.4 Software 11.1.2 IoT Unit Deployment by Region 11.1.2.1 North America 11.1.2.2 Asia Pacific 11.1.2.3 Europe 11.1.2.4 Middle East and Africa 11.1.2.5 Latin America 11.2 AI Embedded IoT Market Forecast 11.2.1 IoT Market by Segments 11.2.1.1 IoT Device 11.2.1.2 IoT Things and Objects 11.2.1.3 IoT Semiconductor 11.2.1.4 Software 11.2.2 IoT Market by Region 11.2.2.1 North America 11.2.2.2 Asia Pacific 11.2.2.3 Europe 11.2.2.4 Middle East and Africa 11.2.2.5 Latin America AI based Chatbot Market by Type, Use Case, Deployment Type, Value Chain Component, Market Segment, Industry Vertical, Region and Country 1. Executive Summary </p>
<p> 2. Introduction 2.1 Intelligent Chatbots 2.2 Chatbots vs. Virtual Personal Assistants 2.3 Chatbots and Conversational UI 2.4 Role of Machine Learning and AI 2.5 Chatbots vs. Traditional Apps 2.6 Chatbots Feature Functionality </p>
<p> 3. Intelligent Chatbots Ecosystem Analysis 3.1 Chatbot Open Development Ecosystem 3.2 Types of Chatbots 3.3 Chatbot Architecture 3.3.1 Generative Models 3.3.2 Retrieval Based Models 3.3.3 Pattern Based Heuristics 3.4 Machine Learning and Response Generation in Chatbots 3.5 Chatbot Ecosystem 3.5.1 Native Chatbots 3.5.2 Third Party Chatbots 3.5.3 Corporate Chatbots 3.5.4 Chatbots Delivery Channel 3.5.5 Technology Assistants 3.5.6 Chatbots Application Industry 3.6 Beyond Chatbots: Messaging is the New Voice 3.7 Potential Business Impact of Chatbots 3.7.1 Establish Scalable Customer Service 3.7.2 Develop Customer Intelligence 3.7.3 Small Businesses become More Competitive 3.7.4 Improve Customer Navigational Experience 3.7.5 Personalized Sales and Marketing 3.8 Developing Chatbots: Building Blocks and Costs Analysis 3.8.1 Building Blocks of Chatbots Development 3.8.2 Develop Prerequisite Capabilities 3.8.3 Development Options and Costs 3.8.4 Choosing a Self Service Solution 3.9 Chatbots to Make Significant Impact on Global Economy 3.9.1 Impact on Global Job Market 3.10 Investment in the Chatbot Ecosystem 3.11 Investment of Slack in Chatbots Ecosystem </p>
<p> 4. Chatbot Market: SWOT Analysis and Use Cases 4.1 SWOT Analysis 4.2 Emerging Chatbot Use Cases 4.2.1 Dialog Systems 4.2.2 Toy Devices 4.2.3 Customer Service 4.2.4 Expedite Purchase Process 4.2.5 Improve Workplace Productivity 4.2.6 Booking Agent 4.2.7 Gaming Expert 4.2.8 Weather Forecaster 4.2.9 News Reporter 4.2.10 Job Hunter 4.2.11 Marketer 4.2.12 Hair Stylist and Retailer 4.2.13 Food Order Taker 4.2.14 Finance Adviser 4.2.15 Teacher 4.2.16 Legal Advisor 4.2.17 Salesman 4.3 Market Learning Self-Driving Car Device Failure 4.4 Amazon Echo Services to Hotel Suites </p>
<p> 5. Chatbot Company and Solution Analysis 5.1 Anboto Group 5.1.1 Overview 5.1.2 Solution and Strategic Initiatives 5.1.2.1 Virtual Assistant for Customer Service 5.1.2.2 Intelligent Chatbots 5.1.2.3 Automatic Email Response and Management 5.1.2.4 Social Module 5.1.2.5 Feedback Management and Customer Engagement Suite 5.2 Apple Inc. 5.2.1 Overview 5.2.2 Apple Siri and Embedded Strategy 5.3 Artificial Solutions Ltd. 5.3.1 Overview 5.3.2 Solution and Strategic Initiatives 5.3.2.1 Teneo Platform 5.3.2.2 Natural Language Interface 5.3.2.3 Digital Employee 5.3.2.4 Natural Language Analytics 5.4 iDAvatars (IDA) 5.4.1 Overview 5.4.2 3D Virtual Assistant and Insyte Dashboard 5.5 Creative Virtual Ltd. 5.5.1 Overview 5.5.2 V-Person technology 5.6 CX Company 5.6.1 Overview 5.6.2 Digital CX Solutions 5.7 eGain Corporation 5.7.1 Overview 5.7.2 Solution and Strategic Initiatives 5.8 Eidoserve Inc. 5.8.1 Overview 5.8.2 Abby and IVR Solution 5.9 Existor 5.9.1 Overview 5.9.2 Existor Chatbots 5.10 Google 5.10.1 Overview 5.10.2 Solution and Strategic Initiatives 5.10.2.1 Google Now 5.10.2.2 Google Assistant 5.10.2.3 Google Home 5.10.2.4 Embedded Strategy 5.10.2.5 Allo 5.10.2.6 DeepMind Acquisition 5.11 Intel Corporation 5.11.1 Overview 5.11.2 Solution and Strategic Initiatives 5.11.2.1 Digital Personal Assistant for the Enterprise 5.11.2.2 Intel AI Acquisition Strategy 5.11.2.3 Intel Ginger 5.11.2.4 Next gen AI Chip Strategy 5.11.2.5 Intel JARVIS 5.12 Microsoft Corporation 5.12.1 Overview 5.12.2 Solution and Strategic Initiatives 5.12.2.1 Microsoft Key Five Assets Strategy 5.12.2.2 Microsoft Cortana 5.12.2.3 Genee and Other Acquisition Strategy 5.12.2.4 Tay Bot 5.12.2.5 Xiaoice 5.12.2.6 Microsoft AI and Research Group 5.12.2.7 Industry Collaboration 5.13 Speaktoit Inc. 5.13.1 Overview 5.13.2 Solution and Strategic Initiatives 5.13.2.1 Assistant.ai 5.14 InteliWISE SA 5.14.1 Overview 5.14.2 Solution and Strategic Initiatives 5.14.2.1 Virtual Assistant Chatbot 5.14.2.2 Facebook Messenger Bot 5.14.2.3 Proactive LiveChat 5.14.2.4 Omnichannel Contact Center 5.14.2.5 eGOV 5.15 Facebook Inc. 5.15.1 Overview 5.15.2 Solution and Strategic Initiatives 5.15.2.1 Facebook M 5.15.2.2 DeepText: Text Understanding Engine 5.15.2.3 Third Party Integration 5.16 Salesforce 5.16.1 Overview 5.16.2 Solution and Strategic Initiatives 5.16.3 Einstein 5.16.4 Acquisition Strategy 5.17 Amazon 5.17.1 Overview 5.17.2 Solution and Strategic Initiatives 5.17.2.1 Amazon Alexa Voice 5.17.2.2 Amazon Echo 5.18 SK Telecom Co, Ltd. 5.18.1 Overview 5.18.2 Solution and Strategic Initiatives 5.18.2.1 NUGU 5.18.2.2 Inclusion of Conexant Systems AI Capabilities 5.19 motion.ai 5.20 Indigo 5.21 Vokul 5.22 24me 5.23 Robin 5.24 Wunderlist 5.25 Cubic 5.26 Hound 5.27 SIRIUS 5.28 Yahoo Inc. 5.28.1 Overview 5.28.2 Yahoo Chatbots on Kik and Facebook Messenger 5.29 Helpshift 5.30 Haptik, Inc. 5.31 Aspect Software, Inc. 5.31.1 Aspect Mila: Workforce Chatbot 5.31.2 Aspect Chatbots based on ITR 5.32 Inbenta Technologies Inc. 5.32.1 Inbenta Chatbots to Skype and Facebook Messenger 5.32.2 Inbenta Chatbot Development Platform 5.33 Twilio 5.33.1 Twilio Supports HelloVote Chatbot 5.33.2 Exclusive Interview of Twilio 5.33.2.1 Overall Twilio's Comments on Bots 5.33.2.2 Twilio's Responds to Key Questions 5.34 IBM Watson </p>
<p> 6. Conclusions and Recommendations 6.1 Chatbots to Redefine HCI 6.2 Marketing Guide for the Future 6.3 AI Chatbots App 6.4 Recommendations to Market Players 6.4.1 Chatbots for Consumer Market 6.4.2 Integration and Convergence in Enterprise and Industrial Segment 6.4.3 Recommendations to Investors </p>
<p> 7. AI Based Chatbot Market Analysis and Forecasts 2019 - 2024 7.1 Global Markets for AI based Chatbots by Type 2019 - 2024 7.2 AI based Chatbots by Interface Type 2019 - 2024 7.2.1 AI based Voice Chatbots by sub-category 2019 - 2024 7.3 Global Market Size AI Chatbots by Value Chain Components 2019 - 2024 7.4 Global Markets for AI based Chatbots by Business Model 2019 - 2024 7.5 Global Markets for AI based Chatbots by Deployment 2019 - 2024 7.6 Global Markets for AI based Chatbots by Market Segment 2019 - 2024 7.7 Global Markets for AI based Chatbots by Applications 2019 - 2024 7.8 Global Markets for AI based Chat by Use Case 2019 - 2024 7.9 Global Markets for AI based Chatbots by Industry Vertical 2019 - 2024 </p>
<p> 8. Regional AI based Chatbot Market 2019 - 2024 8.1 AI based Chatbot Market by Region 2019 - 2024 8.2 North America AI Based Chatbot Markets by Country 2019 - 2024 8.3 Latin America AI Based Chatbot Markets by Country 2019 - 2024 8.4 Europe AI Based Chatbot Markets by Country 2019 - 2024 8.5 APAC AI Based Chatbot Markets by Country 2019 - 2024 8.6 MEA AI Based Chatbot Markets by Country 2019 - 2024 </p>
<p> 9. Conversational AI Forecasts 2019 - 2024 9.1 Global Market for Conversational AI by Deployment Type 2019 - 2024 9.2 Global Markets for Conversational AI by Value Chain Components 2019 - 2024 9.3 Global Markets for Conversational AI by Market Segment 2019 - 2024 9.4 Global Markets for Conversational AI by Applications 2019 - 2024 9.5 Global Markets for Conversational AI by Use Case 2019 - 2024 9.6 Global Markets for Conversational AI by Industry Vertical 2019 - 2024 9.7 Global Markets for Conversational AI by Region 2019 - 2024 9.7.1 North American Markets for Conversational AI by Country 2019 - 2024 9.7.2 Latin American Markets for Conversational AI by Country 2019 - 2024 9.7.3 European Markets for Conversational AI by Country 2019 - 2024 9.7.4 APAC Markets for Conversational AI by Country 2019 - 2024 9.7.5 MEA Markets for Conversational AI by Country 2019 - 2024 Industrial Internet of Things: IIoT Market by Technologies, Solutions and Services 1. Executive Summary 1.1 Scope of Research 1.2 Target Audience 1.3 Key Findings in Report 1.4 Companies in Report </p>
<p> 2. Overview 2.1 The Industrial Internet of Things Market Opportunity 2.1.1 People, Processes, and Technology 2.1.2 IIoT and People 2.1.3 IIoT and Processes 2.1.4 IIoT and Technologies 2.2 Critical Focal Areas for IIoT Execution 2.3 IIoT Application Areas 2.3.1 Process Optimization 2.3.2 Enhance, Integrate and Scale existing Corporate IT Systems 2.3.3 Leverage Potential of Existing Infrastructure 2.4 Forming a Foundation for IIoT 2.4.1 Industrial Internet Consortium 2.4.2 Industry Leading Companies set the Pace 2.4.3 Industry Test Beds for IIoT 2.4.4 Industrial Internet Reference Architecture 2.5 Evaluating the Future Potential of IIoT 2.5.1 Cyber-security is a Critical Concern with IIoT 2.5.2 IIoT is Facilitating a Drive in Industrial Automation 2.5.3 Early IIoT Deployments to Benefit Existing Industries 2.5.4 IIoT will work in Collaboration to achieve Success 2.5.5 IIoT and the Fourth Industry Revolution 2.5.6 IIoT to Facilitate Transition to Smart Factories 2.5.7 Connected Factory: New Roles for Suppliers and Customers 2.5.8 IIoT and Product Transformation to an as a Service Economy 2.5.9 Intelligent Manufacturing: From Smart Factories to Smarter Factories 2.5.10 Teleoperation and Tele-robotics 2.5.11 IIoT and Fifth Generation (5G) Wireless 2.5.12 IIoT and Edge Computing </p>
<p> 3. IIoT Technologies 3.1 Hardware Technologies 3.1.1 Hardware Development Platforms 3.1.2 Smart Sensors 3.2 Software Technologies 3.2.1 Connectivity Platforms 3.2.2 Data Storage Platforms 3.2.3 Data Analytics and Visualization Platforms 3.2.4 IoT Protocols 3.3 IIoT and Manufacturing Execution Systems (MES) 3.3.1 Role and Importance with IIoT 3.3.2 MES and Cyber-Physical Systems 3.3.3 MES in the Cloud and other Convergence 3.3.4 Future of IIoT Enabled MES 3.4 Edge Computing 3.4.1 Introduction to Edge Computing 3.4.2 Mobile Edge Computing (Mult-access Edge Computing) 3.4.3 Fog Computing (Non-Cellular Edge Computing) 3.4.4 Edge Computing in Industrial Networks and Systems 3.5 Teleoperation and Tele-robotics 3.5.1 Teleoperation 3.5.2 Tele-robotics 3.5.3 Cloud Robotics 3.6 Digital Twin Technologies and Solutions 3.6.1 Digital Twinning 3.6.2 Digital Twin Solution Drivers 3.6.3 Digital Twin Solution Use Cases 3.7 Network Technologies in IIoT 3.7.1 Wireless Local Area Network 3.7.2 Wireless Personal Area Network 3.7.3 Wireless Wide Area Networks 3.7.4 Wireless Sensor Networks </p>
<p> 4. IIoT in Industry Verticals 4.1 Automotive and Transportation 4.2 Cargo and Logistics 4.3 Healthcare 4.4 Manufacturing 4.5 Oil and Gas 4.6 Utilities </p>
<p> 5. IIoT Company Analysis 5.1 ABB 5.2 Accenture 5.3 AGT International 5.4 ARM Holdings 5.5 ATOS 5.6 B+B SmartWorx 5.7 Bosch 5.8 C3, Inc. 5.9 Cisco System Inc. 5.10 Digi International 5.11 Echelon Corporation 5.12 Elecsys Corporation 5.13 General Electric 5.14 Hitachi 5.15 IBM 5.16 Oracle 5.17 PTC 5.18 Real Time Innovation 5.19 Rockwell Automation 5.20 SAP 5.21 Sensata Technologies 5.22 Siemens 5.23 Wind River 5.24 Worldsensing 5.25 Wovyn LLC. </p>
<p> 6. IIoT Global Market Analysis and Forecasts 2019 - 2024 6.1 IIoT Market by Region 2019 - 2024 6.2 IIoT Global Market by Products Offered 2019 - 2024 6.2.1 IIoT Market for Hardware in 2019 - 2024 6.2.2 IIoT Market for Software in 2019 - 2024 6.2.3 IIoT Market for Services 2019 - 2024 6.3 IIoT Global Market by Industry Vertical 2019 - 2024 6.3.1 IIoT Deployments in Manufacturing Sector 2019 - 2024 6.3.2 Healthcare Market for IIoT 2019 - 2024 6.3.3 Automotive Industry Market for IIoT 2019 - 2024 6.3.4 Retail industry Market for IIoT 2019 - 2024 6.3.5 Oil and Gas Industry Market for IIoT 2019 - 2024 6.3.6 Market for IIoT by Cargo and Logistic Sector 2019 - 2024 6.3.7 IIoT business in Utilities Sector 2019 - 2024 6.3.8 IIoT business in Hospitality Sector 2019 - 2024 </p>
<p> 7. Future of IIoT Technologies, Solutions, and Deployment 7.1 IIoT Deployment and Support 7.1.1 Carrier Supported IIoT Networks 7.1.2 IIoT and Private Wireless Networks 7.2 Evolution of IIoT Economic Value 7.2.1 Internal Company Benefits 7.2.2 Customer Oriented Benefits 7.2.3 IIoT Data Becomes the Product 7.3 IIoT and Technology Convergence 7.4 IIoT Data as a Service 7.4.1 DaaS Market for Business Data (Enterprise and Industrial) 7.5 DaaS Market by Source: Machine and Non-Machine Data 7.6 DaaS Market by Data Collection: IoT and Non-IoT Data Smart Machines in Enterprise and Industrial IoT Market Outlook and Forecasts 1. Introduction 1.1 Smart Machines in Perspective 1.2 Smart Machine Drivers 1.3 Smart Machine Market Development 1.4 Smart Machine Industry Dynamics </p>
<p> 2. Smart Machine Ecosystem 2.1 Cognitive Computing and Artificial Intelligence 2.2 Sensor Networks and Smart Dust 2.3 Application Specific Algorithm and Machine Learning 2.4 Purpose Built Smart Machines and Neurocomputer 2.5 Intelligent Automation and Robotic Process Automation 2.6 Industrial Automation System 2.7 Workplace Automation Systems 2.8 IoT and Smart Systems 2.9 5G, MEC, and Cloud Computing </p>
<p> 3. Smart Machine Market Analysis and Forecasts 3.1 Global Market Forecast 2019 - 2024 3.1.1 Total Smart Machine Market 3.1.2 Smart Machine Product Market 3.1.3 Smart Machine Technology Market 3.1.3.1 Smart Machine Cognitive Technology Market 3.1.3.1.1 Smart Machine Robotics Technology Market 3.1.3.2 Smart Machine Neurocomputing Technology Market 3.1.4 Smart Machine Market Segment 3.1.4.1 Smart Machine Market in Industry Verticals 3.2 Regional Market Forecast 2019 - 2024 3.2.1 Smart Machine Regional Market 3.2.2 APAC Smart Machine Market 3.2.2.1 APAC Market by Product, Technology, Market Segment, and Industry Vertical 3.2.2.2 APAC Market by Country 3.2.3 North America Smart Machine Market 3.2.3.1 North America Market by Product, Technology, Market Segment, and Industry Vertical 3.2.3.2 North America Market by Country 3.2.4 Europe Smart Machine Market 3.2.4.1 Europe Market by Product, Technology, Market Segment, and Industry Vertical 3.2.4.2 Europe Market by Country 3.2.5 ME&A Smart Machine Market 3.2.5.1 ME&A Market by Product, Technology, Market Segment, and Industry Vertical 3.2.5.2 ME&A Market by Country 3.2.6 Latin America Smart Machine Market 3.2.6.1 Latin America Market by Product, Technology, Market Segment, and Industry Vertical 3.2.6.2 Latin America Market by Country </p>
<p> 4. Company Analysis 4.1 IBM Corporation 4.1.1 Company Overview 4.1.2 Strategic Initiative 4.2 Google Inc. 4.3 Narrative Science Inc. 4.4 Apple Inc. 4.5 Digital Reasoning Systems Inc. 4.6 Microsoft Corporation 4.7 General Electric Co. 4.8 Rockwell Automation Inc. 4.9 ABB Ltd. 4.10 LG Electronics 4.11 NVIDIA Corporation 4.12 SparkCognition Inc. 4.13 Cisco Systems 4.14 Koninklijke Philips N.V. 4.15 Axis Communications AB 4.16 Hewlett Packard Enterprise 4.17 Samsung Electronics Co Ltd. 4.18 Baidu Inc. 4.19 KUKA AG 4.20 Motion Controls Robotics Inc. 4.21 Rethink Robotics 4.22 BAE Systems 4.23 Honeywell International Inc. </p>
<p> Research and Markets also offers Custom Research services providing focused, comprehensive and tailored research. </p>
<p> CONTACT: ResearchAndMarkets.com Laura Wood, Senior Press Manager press@researchandmarkets.com For E.S.T Office Hours Call 1-917-300-0470 For U.S./CAN Toll Free Call 1-800-526-8630 For GMT Office Hours Call +353-1-416-8900 Related Topics: Internet of Things and M2M, Industrial Automation </p>
</article>
<article url="https://in.finance.yahoo.com/news/artificial-intelligence-internet-things-technologies-202708809.html" parent_folder="ai_corpus" id="file14034851" filename="artificial-intelligence-internet-things-technologies-202708809.html">
<p> -94.10(-1.01%) </p>
<p> -15,675.81(-2.31%) </p>
<p> -3.49(-1.79%) </p>
<p> -136.50(-0.52%) </p>
<p> Artificial Intelligence to the Internet of Things: Technologies that defined the way we lived in 2019 </p>
<p> Technology continues to redefine the way we live. It is an enabler that fulfills our wants and needs, and enriches our lives with comfort, convenience, entertainment, good health and even prosperity. And going by the trends, it seems like we can't get enough. </p>
<p> Our growing demand for compute and connectivity on-the-go has led to tremendous innovation in mobile devices. Technological innovations, such as autonomous cars for intelligent and safe travel and electronic banking facility for real-time monetary transactions, seem to emulate the 'change' constant of life. </p>
<p> Here's a look at how this evolution continued in the past year: </p>
<p> Artificial Intelligence (AI) </p>
<p> We have seen AI and machine learning (ML) gradually move out of the cloud and closer to edge devices where analytics happen in real-time. This is because data transmission delays (latency) associated with the cloud can adversely impact mission critical outcomes. In order to keep AI-powered devices, such as those in smart city surveillance systems, autonomous cars and healthcare systems responsive enough, the data needs to reside as close as possible to the source. This shift has also been possible due to System-on-Chip (SoC) processors that lend more computing power to edge devices. </p>
<p> AI based solutions have progressed out of research labs and become mainstream now. For instance, in the world of healthcare, asthmatics have an AI-powered inhaler that runs real-time ML algorithms to recognise a patient's breath pattern with the help of a sensor module. AI-enabled voice assistants such as Amazon Alexa and Google Assistant provide users the comfort and convenience of interacting with devices by simply using speech as the medium of communication. </p>
<p> Internet of Things (IoT) </p>
<p> Gartner forecasts that there will be 20 billion Internet-connected things by 2020. While the list of IoT gadgets for consumers may seem unending, ranging from smart and connected gadgets as well as appliances such as smart refrigerators, air-conditioners, watches, fire alarms, door locks, bicycles, medical sensors, fitness trackers, security systems, etc., there were some that particularly caught our attention this year. Take, for example, a specially designed watch with IoT integration for people suffering from dementia, Alzheimer's disease or autism, allowing the patient and the caregiver to stay connected round the clock. </p>
<p> Several automation products have IoT integration, such as the home automation range of connected smart devices, including those catering to the user's light and music preferences. This year saw several of these devices offering users a hands-free, voice-enabled experience rather than a touch screen. </p>
<p> In India, we've seen applications across retail, education, smart city initiatives, healthcare, among others. From self-service kiosks to smart classroom solutions to remote patient monitoring to surveillance applications, India has seen both product innovation and implementations with potential to scale. </p>
<p> VR, AR and MR </p>
<p> Taking things up a notch, Extended Reality (ER) is another trend that will make headlines in 2020. It can be explained as a term covering several new and revolutionary technologies that create immersive digital experiences. To break it down, this refers to virtual reality (VR), augmented reality (AR) and mixed reality (MR). We have all seen or experienced the digitally immersive experience of a computer-generated world that we can literally walk into using headsets that cut out the real world. AR, on the other hand, overlays digital objects and portrays them in the real world via smartphone screens or any other display. MR is an elaborate version of AR, where users can interact with digital objects in the real world. For example, a user could play holographic drums via an AR headset. The concept of Extended Reality is that of experiences. </p>
<p> Robotics </p>
<p> Powered with advanced AI technology, consumer robots will soon play a defining role in our daily life, assisting us with vacuuming the house, mowing the lawn, and cleaning the pool. The social robots will serve as companions and care for us. Advanced computer vision is also transforming the way drones operate. Drones with AI-enabled vision processing capabilities are being used to assess structural damage in buildings, rescue operations, remote study of wildlife and the effects of climate change, etc., without having to put human life at risk. The world of technology is limitless and the list of technological innovations seemingly unending. There's never a dull moment for technology enthusiasts, and the best is always yet to come. </p>
<p> The writer is VP and MD-Sales and Marketing Group, Intel India </p>
</article>
<article url="https://finance.yahoo.com/news/artificial-intelligence-machine-learning-platform-070000163.html" parent_folder="ai_corpus" id="file14034842" filename="artificial-intelligence-machine-learning-platform-070000163.html">
<p> -40.78(-1.24%) </p>
<p> -408.38(-1.42%) </p>
<p> -92.89(-1.00%) </p>
<p> -28.15(-1.71%) </p>
<p> -0.20(-0.38%) </p>
<p> +1.70(+0.11%) </p>
<p> +0.07(+0.38%) </p>
<p> +0.0045(+0.4101%) </p>
<p> New Artificial Intelligence and Machine Learning Platform for Reconciliation, Matching and Exception Management Operations Introduced by Broadridge </p>
<p> Innovative and vendor agnostic, Intelligent Automation brings new levels of productivity and efficiency to the middle and back office. </p>
<p> LONDON and NEW YORK, Dec. 3, 2019 /PRNewswire/ -- Broadridge Financial Solutions, Inc. (NYSE: BR), a global Fintech leader and part of the S&P 500® Index, today announced the launch of Broadridge Data Control Intelligent Automation, a new artificial intelligence (AI) and machine learning (ML) platform built to be deployed across industry-wide reconciliation, matching and exception management applications. </p>
<p> Broadridge has teamed with Singapore-headquartered Tookitaki Holding Pte Limited, to utilize their award-winning AI and ML technology to deliver a next-generation platform addressing industry-wide reconciliation, matching and exception processing inefficiencies. Customers will be able to license modules on the platform for multiple Intelligent Automation applications with the initial two modules being Break Management and Recon Perform. Both modules provide a true enterprise wide capability, working across not only Broadridge's reconciliations solution but in-house and third-party developed solutions. </p>
<p> "Intelligent Automation will drive performance and productivity gains from incumbent reconciliation systems, especially for organizations that have multiple vendor solutions in place," said Alastair McGill, general manager of Data Control Solutions at Broadridge. "By leveraging AI and ML we are helping eradicate breaks in the exception management world, automatically finding the underlying cause of a problem and resolving it efficiently to ensure the underlying cause is addressed." </p>
<p> Commenting on the announcement Virginie O'Shea, Research Director, Aite Group, stated: "As our recent research has indicated, most firms have more than one reconciliation platform in place, so it is refreshing to see a vendor recognize that financial institutions would benefit from a solution that sits across all of these platforms. Though it would be ideal for firms to deal with only one reconciliation environment, that isn't the current reality, and this is a practical approach to help firms deal with the well-known industry pain points related to break management across the enterprise." </p>
<p> Improving the Process and Experience </p>
<p> The machine learning-powered Break Management module accelerates the investigation process, reducing resolution times by continuously improving break classification according to client-defined business reasons. </p>
<p> The Recon Perform module automates reconciliation builds and improvement tasks with automatic matching scheme configuration using supervised ML models and continuous matching scheme improvement, saving significant time and cost for firms rolling out and managing large volumes of reconciliations. </p>
<p> "Tookitaki is helping Broadridge offer automatic matching and break detection with supporting audit trails. Our patent-pending explainability framework offers a 'glass-box' approach to ML models that allows users to view decisions made by the platform's engine through a simple interface," said Tookitaki Founder and CEO, Abhishek Chatterjee. "This offering is unique to the industry and provides an unprecedented level of transparency to build confidence and trust in the application." </p>
<p> The Data Control Intelligent Automation platform uses the latest distributed computing framework to deliver a high-performance, scalable matching and exception process. It is agnostic to the underlying reconciliation system, making it relevant not just to users of the Broadridge reconciliations platform, but to any reconciliation and exception management team, including those that use more than one solution. It can be deployed on premise, on Broadridge-managed servers or in the Cloud. </p>
<p> About Broadridge </p>
<p> Broadridge Financial Solutions, Inc. (NYSE: BR), a $4 billion global Fintech leader, is a leading provider of investor communications and technology-driven solutions to banks, broker-dealers, asset and wealth managers and corporate issuers. Broadridge's infrastructure underpins proxy voting services for over 50 percent of public companies and mutual funds globally, and processes on average more than U.S.$7 trillion in fixed income and equity securities trades per day. Broadridge is part of the S&P 500® Index and employs over 11,000 full-time associates in 18 countries. For more information about Broadridge, please visit www.broadridge.com. </p>
<p> Story continues </p>
<p> Investors: </p>
<p> W. Edings Thibault Head of Investor Relations Broadridge Financial Solutions +1 516-472-5129 edings.thibault@broadridge.com </p>
</article>
<article url="https://finance.yahoo.com/news/artificial-intelligence-machine-learning-transforming-055831381.html" parent_folder="ai_corpus" id="file14034843" filename="artificial-intelligence-machine-learning-transforming-055831381.html">
<p> -40.78(-1.24%) </p>
<p> -408.65(-1.42%) </p>
<p> -94.67(-1.02%) </p>
<p> -28.15(-1.71%) </p>
<p> -0.16(-0.31%) </p>
<p> +1.60(+0.10%) </p>
<p> +0.07(+0.38%) </p>
<p> +0.0045(+0.4101%) </p>
<p> How Artificial Intelligence And Machine Learning Are Transforming Law Firms And The Legal Sector </p>
<p> Whenever a professional sector faces new technology, questions arise regarding how that technology will disrupt daily operations and the careers of those who choose that profession. And lawyers and the legal profession are no exception. Today, artificial intelligence (AI) is beginning to transform the legal profession in many ways, but in most cases it augments what humans do and frees them up to take on higher-level tasks such as advising to clients, negotiating deals and appearing in court. </p>
<p> What is artificial intelligence? </p>
<p> Artificial intelligence mimics certain operations of the human mind and is the term used when machines are able to complete tasks that typically require human intelligence. The term machine learning is when computers use rules (algorithms) to analyze data and learn patterns and glean insights from the data. Artificial intelligence is a large factor shifting the way legal work is done. </p>
<p> Review documents and legal research </p>
<p> AI-powered software improves the efficiency of document analysis for legal use and machines can review documents and flag them as relevant to a particular case. Once a certain type of document is denoted as relevant, machine learning algorithms can get to work to find other documents that are similarly relevant. Machines are much faster at sorting through documents than humans and can produce output and results that can be statistically validated. They can help reduce the load on the human workforce by forwarding on only documents that are questionable rather than requiring humans to review all documents. It’s important that legal research is done in a timely and comprehensive manner, even though it’s monotonous. AI systems such as the one offered by ROSS Intelligence leverages natural language processing to help analyze documents. </p>
<p> Help perform due diligence </p>
<p> In law offices around the world, legal support professionals are kept busy conducting due diligence to uncover background information on behalf of their clients. This works includes confirming facts and figures and thoroughly evaluating the decisions on prior cases to effectively provide counsel to their clients. Artificial intelligence tools can help these legal support professionals to conduct their due diligence more efficiently and with more accuracy since this work is often tedious for humans. </p>
<p> Contract review and management </p>
<p> A big portion of work law firms do on behalf of clients is to review contracts to identify risks and issues with how contracts are written that could have negative impacts for their clients. They redline items, edit contracts and counsel clients if they should sign or not or help them negotiate better terms. AI can help analyze contracts in bulk as well as individual contracts. There are several software companies who created AI tools specifically for contract review such as Kira Systems, LawGeex and eBrevia that help sort contracts quicker and with fewer errors than humans. </p>
<p> Predict legal outcomes </p>
<p> AI has the capability of analyzing data to help it make predictions about the outcomes of legal proceedings better than humans. Clients are often asking their legal counsel to predict the future with questions such as “If we go to trial, how likely will it be that I win?” or “Should I settle?” With the use of AI that has access to years of trial data, lawyers are able to better answer such questions. </p>
<p> Automating divorce </p>
<p> A typical divorce settlement can take a year or more and can cost $27,000 on average in the United States. With a goal of “making every divorce amicable,” Wevorce provides couples a self-guided online divorce solution for a fraction of the cost. Couples can define their “optimal outcomes” and the AI-powered machine walks them through five modules and all the critical decisions that need to be made for their particular circumstances. There are also legal experts available to step in to provide guidance when needed. </p>
<p> How will AI impact the legal profession? </p>
<p> According to Deloitte, 100,000 legal roles will be automated by 2036. They report that by 2020 law firms will be faced with a “tipping point” for a new talent strategy. Now is the time for all law firms to commit to becoming AI-ready by embracing a growth mindset, set aside the fear of failure and begin to develop internal AI practices. There are many who believe innovation is the key to transforming the legal profession. That’s precisely what NextLaw Labs, “the first legal technology venture created by a law firm,” plans to do. </p>
<p> Story continues </p>
<p> It’s clear that AI and machine learning are already transforming law firms and the legal sector. What changes have you seen? </p>
<p> Also, you might like to read more about how data and analytics are transforming HR in Data-Driven HR. It’s packed with real-life examples and practical ways HR teams can deliver maximum value in our increasingly data-driven world. </p>
</article>
<article url="https://finance.yahoo.com/news/artificial-intelligence-primed-disrupt-health-144723831.html" parent_folder="ai_corpus" id="file14034844" filename="artificial-intelligence-primed-disrupt-health-144723831.html">
<p> +0.07(+0.38%) </p>
<p> +0.0045(+0.4101%) </p>
<p> Artificial Intelligence is Primed to Disrupt Health Care Industry </p>
<p> Artificial intelligence (AI) is one of the prime technologies leading the wave of disruption that is going on within the health care sector. Recent studies have shown that AI technology can outperform doctors when it comes to cancer screenings and disease diagnoses. </p>
<p> In particular, this could mean specialists such as radiologists and pathologists could be replaced by AI technology. Per an article by the Association of American Medical Colleges, "a New England Journal of Medicine article predicted that 'machine learning will displace much of the work of radiologists and anatomical pathologists,' adding that 'it will soon exceed human accuracy.' That same year, Geoffrey Hinton, PhD, a professor emeritus at the University of Toronto who also designs machine learning algorithms for Google (and who received the Association for Computing Machinery’s A.M. Turing Award, often called the Nobel Prize of computing, in 2019), declared, 'We should stop training radiologists now.'" </p>
<p> Investment Opportunities in AI </p>
<p> AI is gaining widespread attention for its ability to be a disruptive technology that spans across a variety of sectors. In the financial space, AI can be used to perform risk-reward analysis, fraud detection and advisory services, but is it a smart idea to invest in AI-focused exchange-traded funds (ETFs)? </p>
<p> Whether society is ready for it or not, robotics, artificial intelligence (AI), machine learning, or any other type of disruptive technology will be the next wave of innovation. For investors who missed out on the bull market run of FAANG (Facebook, Amazon, Apple, Netflix, Google) stocks, they can look to capitalize on disruptive tech options in 2019 and beyond that. </p>
<p> Disruptive technology is not relegated to certain sectors as it will permeate into all industries in some form or fashion. For example, augmented reality is technology comprised of digital images superimposed over the real world, and its use is primed to drive industry growth–industries like real estate and manufacturing are already putting the technology to use in a variety of ways. </p>
<p> According to the Harvard Business Review, global firm Deloitte identified seven disruptive forces that leaders should understand and incorporate into their strategy for future growth: </p>
<p> Internet of things (IoT): disrupting the labor market and forcing employees to be “tech fluent.” </p>
<p> Continued growth of big data via analytics in organizations </p>
<p> “Cyber-physical world” that focuses on efficiency and the automation of manual tasks </p>
<p> Automation and higher-level value creation </p>
<p> The concept of “career” is changing via technology, resulting in a 60-70-year work life with continuous learning and career shifts. </p>
<p> An explosion in contingent work with a distributed talent pool that improves productivity and speed </p>
<p> Diversity and generational change for the workforce </p>
<p> One ETF to consider is the ARK Innovation ETF (ARKK) . ARKK is an actively-managed fund that invests in domestic and foreign equity securities of companies that are relevant to the fund's investment theme of disruptive innovation. </p>
<p> Another fund to consider is the Robo Global Healthcare Technology and Innovation ETF (HTEC) . HTEC seeks to provide investment results that, before fees and expenses, correspond generally to the price and yield performance of the ROBO Global Healthcare Technology and Innovation Index. </p>
<p> The fund will normally invest at least 80 percent of its total assets in securities of the index or in depositary receipts representing securities of the index. The index is designed to measure the performance of companies that have a portion of their business and revenue derived from the field of healthcare technology, and the potential to grow within this space through innovation and market adoption of such companies, products and services. </p>
</article>
<article url="https://finance.yahoo.com/news/artificial-intelligence-stocks-10-best-212037542.html" parent_folder="ai_corpus" id="file14034845" filename="artificial-intelligence-stocks-10-best-212037542.html">
<p> +1.70(+0.11%) </p>
<p> +0.07(+0.38%) </p>
<p> +0.0045(+0.4101%) </p>
<p> Artificial Intelligence Stocks: The 10 Best AI Companies </p>
<p> Artificial intelligence is already revolutionizing industry, like it or not. </p>
<p> Wall Street occasionally seizes upon futuristic themes with religious fervor, bidding up shares in companies that supposedly lead in one space or another. AI once occupied that "fascinating-but-far-off" thematic market sector, but the best artificial intelligence stocks to buy today use techniques like machine learning and neural networks routinely as a core function of their business. Millions of consumers interact with AI directly or indirectly on a day-to-day basis via virtual assistants, facial-recognition technology, mapping applications and a host of other software. That said, this is just the early innings, and the area's profit potential is hard to overstate. Here are 10 AI companies betting big on artificial intelligence. </p>
<p> Even if you've only casually followed the best ways to invest in artificial intelligence, you likely know Nvidia, the specialized semiconductor company whose technology plays a central role in many young, high-growth areas of tech. Central to Nvidia's leadership is the company's graphics processing unit (GPU), which powers autonomous vehicles, high-performance gaming, cloud computing and many other areas requiring deep learning. Sony (SNE) recently partnered with Nvidia to introduce a car prototype at the Consumer Electronics Show in 2020. NVDA is marketing itself to automakers as the go-to solution for unified architecture across software, AV chips, data center and more. NVDA's first-mover advantage in high-performance GPUs has eroded with competition, but it remains a market leader and one of the best AI stocks to buy. </p>
<p> Google parent Alphabet has a practically existential interest in investing heavily in artificial intelligence. Google uses AI and deep learning to automate many vital parts of its sprawling software business: relevant search results, speech recognition, self-driving technology, ad pricing, personal assistant software and much more. Much of Alphabet's nearly $1 trillion valuation depends on maintaining and improving these services. With many observers believing AI could be a winner-take-all market, GOOG has the resources, motivation and experience to win, which would certainly make it one of the best artificial intelligence stocks to buy. In late 2019 Google announced it had achieved "quantum supremacy" with its Sycamore processor, solving a computation in 200 seconds that would take the world's fastest supercomputer 10,000 years. Until proven otherwise, this may make GOOG the single most exciting AI company in the world. </p>
<p> Salesforce, the customer relationship management software giant, regularly acquires hot tech startups to improve its software-as-a-service (SaaS) offerings. In 2019 it acquired Bonobo AI, a firm using automated analysis of customer phone calls, texts, and chats to deliver actionable insights. This fits perfectly with Salesforce Einstein, the company's AI-powered software that uses data to identify previously unseen business patterns, deliver the hottest sales leads, predict what marketing copy will perform best, and generally optimize how businesses operate and convert. It's no coincidence that Salesforce and a handful of the other best AI companies in the world are also now large-cap growth stocks, routinely growing their own sales more than 20% each year. </p>
<p> The second company to ever reach a $1 trillion valuation, Amazon couldn't have hit that level by now if it weren't all-in on artificial intelligence. Like Google, returning relevant search results is central to Amazon's business, and AI also powers key capabilities like forecasting product demand, optimizing logistics and warehousing, and improving the voice-powered Amazon Alexa virtual assistant. Amazon Web Services (AWS), the company's cash cow, is also the leading cloud provider of machine learning services, making Amazon's expertise here even more vital (and lucrative). With hundreds of jobs in AI and machine learning posted globally, the e-tailer is working rabidly to stay at the forefront of the fast-growing field. </p>
<p> The most valuable tech companies in the world, without exception, all invest in artificial intelligence. Microsoft's cloud computing service, Azure, is home to AI-driven tools for medicine, language, robotics, medical imaging and many other areas. A 2019 $1 billion investment in Elon Musk-founded OpenAI aims to produce the holy grail of AI, artificial general intelligence (AGI), the technology that can do anything human intelligence can. If successful, Microsoft becomes OpenAI's preferred partner for commercialization. If AGI is feasible it'll likely take decades, but the profit potential is virtually unthinkable. Anyone who wants a slice should own the top AI companies today -- and that means owning MSFT, one of the few tech giants not currently being targeted by U.S. regulators. </p>
<p> China's leading search engine predictably uses AI to improve results and serve ads. But it goes further, winning a 2019 facial recognition competition against competitors including Alibaba Group Holding (BABA), Huawei and elite Chinese universities. Arguably China's most devoted AI investor, Baidu's self-driving software platform Apollo has over 135 auto industry partners, and Baidu logged 91% of all self-driving miles in Beijing in 2018. Analysts expect earnings growth above 20% in both 2020 and 2021, and after falling in 2019, BIDU's valuation combined with China's willingness to incentivize AI research, and a large population, means BIDU is one of the top AI stocks to buy today. </p>
<p> One of the more conservative ways to bet on this space is Intel, the blue-chip, dividend-paying semiconductor giant. Investors get the benefit of an established, well-diversified tech leader -- and a cash cow with $15 billion in free cash flow. That's some decent spare change for boosting R&D, making acquisitions and hiring talent. Intel already provides key hardware components behind the magic; Microsoft uses Intel's field-programmable gate arrays to run deep learning models on its cloud. Additionally, Intel's vision processing units power machine vision in surveillance cameras that can count crowds, perform facial recognition and analyze behavior. Its Mobileye division, which helps vehicles prevent potential collisions, grew by 20% last quarter. </p>
<p> "TWLO may have the greatest risk/reward of the top AI companies," U.S. News's original write-up of the best AI stocks, circa early 2018, read. "At $3.8 billion, the cloud software business could be wildly overvalued -- or shares could quintuple in the next five years." Well, it didn't take that long. By summer 2019, its valuation hit $20 billion. It's pulled back some since, but Twilio -- which offers cloud-based application programming interfaces (APIs) allowing developers to build voice, video and messaging features into their apps -- still remains a wildly popular, useful and fast-growing service. Like some others on this list, Twilio's high growth means high multiples. While only investors comfortable with greater volatility should consider TWLO, it still deserves mention as a top artificial intelligence company in 2020. </p>
<p> Facebook is deeply committed to machine intelligence, and since January 2018 has had Jérôme Pesenti, a legend in the field who famously led IBM's (IBM) Watson division, running point on Facebook's AI Research team. Automating self-teaching algorithms to improve Facebook's News Feed algorithm is central to FB's success, and using AI to screen for hate speech and fake news has never been more important to the company (or society). With 2.4 billion monthly active users (MAUs) and 2.8 billion MAUs across Facebook, Instagram, WhatsApp and Messenger, FB has a singular opportunity to test machine learning techniques with massive real-time datasets, giving FB a huge theoretical advantage over peers. After its AI team spent months studying them, the social media network announced it is banning misleading deepfake videos on its platform ahead of 2020 elections. </p>
<p> Tencent (TCEHY) </p>
<p> Transitioning from the largest social company in the U.S. to the largest social company in China, the tech conglomerate Tencent rounds out the list of the best AI stocks to buy. The nearly $500 billion company largely hit the jackpot with WeChat, a dynamic app ubiquitously used in China for messaging, payments, ride-hailing, social media, mail and other functions. One can imagine the practically endless ways machine learning and artificial intelligence could augment that service -- and in the meantime, how WeChat's more than 1 billion daily users can be used to test and rapidly improve this technology. TCEHY has recruited several top AI experts in recent years from rivals including Microsoft and Baidu. </p>
</article>
<article url="https://news.yahoo.com/artificial-intelligence-stocks-10-best-ai-companies-181036254.html" parent_folder="ai_corpus" id="file14034859" filename="artificial-intelligence-stocks-10-best-ai-companies-181036254.html">
<p> Artificial Intelligence Stocks: The 10 Best AI Companies </p>
<p> Artificial intelligence is already revolutionizing industry, like it or not. </p>
<p> Wall Street occasionally seizes upon futuristic themes with a religious fervor, bidding up shares in companies that supposedly lead in one space or another. AI once occupied that "fascinating-but-far-off" thematic market sector, but the best artificial intelligence stocks to buy today use techniques like machine learning and neural networks routinely as a core function of their business. Millions of consumers interact with AI directly or indirectly on a day-to-day basis via virtual assistants, facial-recognition technology, mapping applications and a host of other software. That said, this is the tip of the iceberg, and the area's profit potential is hard to overstate. Here are 10 AI companies betting big on the technology. </p>
<p> Even if you've only casually followed the best ways to invest in artificial intelligence, you likely know Nvidia, the specialized semiconductor company whose technology plays a central role in many young, high-growth areas of tech. Central to Nvidia's leadership is the company's graphics processing unit (GPU), which powers autonomous vehicles, high-performance gaming, cloud computing and many other areas requiring deep learning. NVDA's superior technology and jump-start on high-performance GPUs gave it the upper hand for years, and while shares fell in 2018 after a meteoric multi-year rise, NVDA currently enjoys a more reasonable valuation. NVDA now faces more competition, but remains a market leader and one of the best AI stocks to buy. </p>
<p> Google parent Alphabet has a practically existential interest in investing heavily in artificial intelligence. Google uses AI and deep learning to power or automate many extremely important parts of its business. Producing relevant search results, self-driving technology, digital ad pricing, personal assistant software, image- and speech-recognition software -- all of it's powered by AI. With a market capitalization approaching $1 trillion, much of Alphabet's valuation relies explicitly on maintaining and improving these services, and with many observers believing AI could be a winner-take-all market, GOOG has the resources, motivation and experience that make it one of the best artificial intelligence stocks to buy. </p>
<p> If there's one thing Salesforce, the customer relationship management software giant, is known for, it's an obsessive focus on seeking growth and opportunities to scale. The company regularly acquires hot tech startups to improve its software-as-a-service (SaaS) offerings, and in 2019 acquired Bonobo AI, a firm using automated analysis of customer phone calls, texts, and chats to deliver actionable insights. This fits perfectly with Salesforce Einstein, the company's AI-powered software that uses data to identify previously unseen business patterns, deliver the hottest sales leads, predict what marketing copy will perform best, and generally optimize how businesses operate and convert. An increasing focus on these incredibly powerful services makes Salesforce the newest member on this list of best AI companies. </p>
<p> It's no coincidence that the second company to ever reach a $1 trillion valuation, and the company whose CEO became the richest person in the world, invests heavily in artificial intelligence. Like Google, returning relevant search results is central to Amazon's business, and AI also powers key capabilities like forecasting product demand, optimizing logistics and warehousing, and improving the voice-powered Amazon Alexa virtual assistant. Amazon Web Services (AWS), the company's cash cow, is also the leading cloud provider of machine learning services, making Amazon's expertise here even more vital. With about 360 AI jobs posted nationwide, the e-tailer is working rabidly to stay at the forefront of the fast-growing field. </p>
<p> The most valuable tech companies in the world, without exception, all invest in artificial intelligence. Microsoft's cloud computing service, Azure, is home to AI-driven tools in medicine, language, robotics and medical imaging, to name just a few. A recent $1 billion investment in OpenAI aims to produce the holy grail of AI, artificial general intelligence (AGI), technology that can do anything human intelligence can. If successful, Microsoft becomes OpenAI's preferred partner for commercialization. If AGI is feasible it'll likely take decades, but the profit potential is practically limitless. Anyone who wants a slice should own the top AI companies today -- and that means owning MSFT. </p>
<p> China's leading search engine predictably uses AI to improve results and serve ads. But it goes much further. Baidu recently won a facial recognition competition against competitors including Alibaba Group Holding (BABA), Huawei and elite Chinese universities. Arguably China's most devoted AI investor, Baidu's self-driving software platform Apollo has 135 partners in the auto industry, and Baidu logged 91 percent of all self-driving miles in Beijing last year. Baidu enjoys a head start, vast resources and unique expertise. China's 1.4 billion population and the government's willingness to subsidize its way to AI dominance, combined with a recent pullback in shares, make BIDU one of the top AI stocks to buy today. </p>
<p> One of the more conservative ways to bet on this space is Intel, the blue-chip, dividend-paying semiconductor giant. Investors get the benefit of an established, well-diversified tech leader -- and a cash cow with $14 billion in free cash flow. That's some decent spare change for boosting R&D, making acquisitions and hiring talent. Intel already provides key hardware components behind the magic; Microsoft uses Intel's field-programmable gate arrays to run deep learning models on its cloud. Additionally, Intel's vision processing units power machine vision in surveillance cameras that can count crowds, perform facial recognition and analyze behavior. Its Mobileye division, which helps vehicles prevent potential collisions, grew by 38% last quarter. </p>
<p> In U.S. News's original write-up of the best AI stocks circa early 2018, Twilio was singled out as a uniquely opportunistic investment. "TWLO may have the greatest risk/reward of the top AI companies," the article read. "At $3.8 billion, the cloud software business could be wildly overvalued -- or shares could quintuple in the next five years." Well, it didn't take that long. By summer 2019, its market value had quintupled to roughly $20 billion. Twilio -- which offers cloud-based application programming interfaces (APIs) allowing developers to build voice, video and messaging features into their apps -- indeed still remains a wildly popular, useful and fast-growing service. So while still deserving mention as a top artificial intelligence company, its risk/reward prospects as an investment are less attractive after its rapid rise. Risk-tolerant investors should consider adding when euphoria dies off. </p>
<p> Facebook is deeply committed to machine intelligence, and since January 2018 has had Jérôme Pesenti, a legend in the field who famously led IBM's (IBM) Watson division, running point on Facebook's AI Research team. Automating self-teaching algorithms to improve Facebook's News Feed algorithm is core to FB's success, and using AI to screen for hate speech and fake news has never been more important to the company. With 2.4 billion monthly active users (MAUs) and 2.7 billion MAUs across all its platforms, FB has a singular opportunity to test machine learning techniques with massive real-time datasets, giving Facebook a huge theoretical advantage over peers. The sprawling social network just released a bevy of machine learning tools that map unmapped parts of the world, and use crowdsourced user feedback to improve the algo. </p>
<p> Tencent (TCEHY) </p>
<p> Transitioning from the largest social company in the U.S. to the largest social company in China, the tech conglomerate Tencent rounds out the list of the best AI stocks to buy. The $400 billion-plus company largely hit the jackpot with WeChat, a dynamic app ubiquitously used in China for messaging, payments, ride-hailing, social media, mail and other functions. One can imagine the practically endless ways machine learning and artificial intelligence could augment that service -- and in the meantime, how WeChat's more than 1 billion daily users can be used to test and rapidly improve this technology. TCEHY has recruited several top AI experts in recent years from rivals including Microsoft and Baidu. </p>
</article>
<article url="https://in.news.yahoo.com/careerbytes-courses-artificial-intelligence-ai-192457508.html" parent_folder="ai_corpus" id="file14034853" filename="careerbytes-courses-artificial-intelligence-ai-192457508.html">
<p> #CareerBytes: Courses in Artificial Intelligence (AI) offered by IITs </p>
<p> 30 Mar 2019: #CareerBytes: Courses in Artificial Intelligence (AI) offered by IITs </p>
<p> Artificial Intelligence (AI) is transforming the world. AI is being integrated into various fields like healthcare, banking, transport, defense, and education among others. </p>
<p> Today, AI is everywhere - from search engines to digital assistants, smart home appliances, self-driving cars, etc. The need for people with knowledge about AI is on the rise. </p>
<p> Here are some courses in AI offered in India by various IITs. </p>
<p> #1: IIT Hyderabad has BTech programme in Artificial Intelligence </p>
<p> It is the first full-fledged bachelor's programme in AI in India and only the third such course in the world. </p>
<p> To be eligible for the new course, having 20 seats, one has to clear the JEE Advanced. </p>
<p> #2: Courses in AI being offered by IIT Kanpur </p>
<p> IIT-Kanpur (IIT-K) has three short-term courses on Artificial Intelligence, Internet of Things, and Robotics for students and professionals. </p>
<p> "Introduction to AI, IoT & Robotics" programme begins on 3 Jun'2019. The 15-day Basic course ends on 17 June, 25-day Long course on 27 June, and 40-day Extended course on 12 July. Registrations are currently open; fees, accommodation, and other details are available on IIT-K's website. </p>
<p> Fact: #3: A six-month course offered by IIT-KGP </p>
<p> IIT-Kharagpur earlier announced it would launch a six-month Certificate Program on "Foundations on Artificial Intelligence and Machine Learning" for engineering students and working professionals from March 2019. Applications for the March course are closed but candidates can apply for upcoming ones on the IIT-KGP website. </p>
<p> #4: Other AI courses offered by various IITs </p>
<p> The IIT-Madras faculty, in January, launched a start-up, One Fourth Labs, for training students in Artificial Intelligence. </p>
<p> The start-up's "PadhAI" online school offers affordable AI courses. However, enrolments are currently closed. Though the courses aren't directly offered by IIT-Madras, they could be quite useful for students. </p>
<p> Apart from these, MTech-level courses in AI are offered by IIT-Bombay, IIT-Madras, and IIT-Kharagpur, and IIT-Hyderabad too. </p>
</article>
<article url="https://www.washingtonpost.com/news/the-switch/wp/2016/10/13/china-has-now-eclipsed-us-in-ai-research/" parent_folder="ai_corpus" id="file14034867" filename="china-has-now-eclipsed-us-in-ai-research">
<p> China has now eclipsed us in AI research </p>
<p> Humanity may still be years if not decades away from producing sentient artificial intelligence. But with the rise of machine-learning services in our smartphones and other devices, one type of narrow, specialized AI has become all the rage. And the research on this branch of AI is only accelerating. </p>
<p> In fact, as more industries and policymakers awaken to the benefits of machine learning, two countries appear to be pulling away in the research race. The results will probably have significant implications for the future of AI. </p>
<p> If you're not familiar with the term, “deep learning” is a subset of the overall branch of AI known as machine learning — which basically involves the use of computer algorithms to perform pattern recognition and analysis. It's this type of AI that powers personal digital assistants such as Google Now, for example. </p>
<p> AD </p>
<p> AD </p>
<p> The chart above was published Wednesday by the Obama administration as part of a new strategic plan aimed at spurring U.S. development of artificial intelligence. What's striking about it is that although the United States was an early leader on deep-learning research, China has effectively eclipsed it in terms of the number of papers published annually on the subject. The rate of increase is remarkably steep, reflecting how quickly China's research priorities have shifted. </p>
<p> The quality of China's research is also striking. The chart below narrows the research to include only those papers that were cited at least once by other researchers, an indication that the papers were influential in the field. </p>
<p> Compared with other countries, the United States and China are spending tremendous research attention on deep learning. But, according to the White House, the United States is not investing nearly enough in basic research. </p>
<p> AD </p>
<p> AD </p>
<p> “Current levels of R&D spending are half to one-quarter of the level of R&D investment that would produce the optimal level of economic growth,” a companion report published this week by the Obama administration finds. </p>
<p> The government is pushing for a major role for itself in AI research, and here's why: Becoming a leader in artificial-intelligence research and development puts the United States in a better position to establish global norms on how AI should be used safely. When AI stands to transform virtually everything including labor, the environment, and the future of warfare and cyberconflict, the United States could be put at a disadvantage if other countries, such as China, get to dictate terms instead. </p>
<p> Today's Headlines </p>
<p> We noticed you’re blocking ads! </p>
<p> Keep supporting great journalism by turning off your ad blocker. Or purchase a subscription for unlimited access to real news you can count on. </p>
</article>
<article url="https://www.washingtonpost.com/video/national/health-science/is-artificial-intelligence-intelligent-how-machine-learning-has-developed/2019/04/10/de018b2a-4c8a-44ee-ae42-c352a8097229_video.html" parent_folder="ai_corpus" id="file14034870" filename="de018b2a-4c8a-44ee-ae42-c352a8097229_video.html">
<p> (Video: Brian Monroe/The Washington Post, Photo: Brian Monroe/The Washington Post) </p>
<p> LIVE </p>
<p> Health and Science </p>
<p> Is artificial intelligence, intelligent? How machine learning has developed. </p>
<p> Can we say that artificial intelligence is actually demonstrating intelligence? The concept of AI has been around for decades and has progressed to a point where doctors may be able to use it to search for Alzheimer's and other patterns of disease. But what does current research on the brain say about how smart artificial intelligence really is? </p>
<p> CDC warns consumers of romaine lettuce E. coli contamination </p>
<p> 4:34 </p>
<p> A doctor's dire warning, as vaping illnesses rise </p>
<p> 7:25 </p>
<p> The Amazon rainforest in Brazil is burning. Who started the fires? | The Fact Checker </p>
<p> 3:17 </p>
<p> How a wave of mysterious illnesses sparked an e-cig crackdown. Here’s what you need to know </p>
<p> 9:25 </p>
<p> 200 years of vaccine skepticism | The Vaccines Project, Episode 1 </p>
<p> 10:48 </p>
<p> What ingredients are in vaccines? | The Vaccines Project, Episode 2 </p>
<p> Vaping-related illnesses on the rise, health officials warn </p>
<p> 1:54 </p>
<p> Why you should be worried about the fires raging in the Amazon </p>
<p> 0:41 </p>
<p> Some panthers in Florida are having trouble walking, and scientists don't know why </p>
</article>
<article url="https://finance.yahoo.com/news/global-artificial-intelligence-ai-market-111100886.html" parent_folder="ai_corpus" id="file14034846" filename="global-artificial-intelligence-ai-market-111100886.html">
<p> -40.83(-1.24%) </p>
<p> -409.39(-1.42%) </p>
<p> -94.50(-1.02%) </p>
<p> -28.11(-1.71%) </p>
<p> -0.17(-0.33%) </p>
<p> +1.50(+0.09%) </p>
<p> +0.07(+0.38%) </p>
<p> +0.0045(+0.4101%) </p>
<p> Global Artificial Intelligence (AI) Market Analysis, Trends, and Forecasts, 2024 - Growing Focus on AI by Leading Tech Companies with Huge Financial Resources - ResearchAndMarkets.com </p>
<p> The report provides separate comprehensive analytics for the US, Canada, Japan, Europe, Asia-Pacific, and Rest of World. Annual estimates and forecasts are provided for the period 2015 through 2024. Market data and analytics are derived from primary and secondary research. This report analyzes the worldwide markets for Artificial Intelligence (AI) in US$ Million. </p>
<p> Key Topics Covered: </p>
<p> 1. INTRODUCTION, METHODOLOGY & PRODUCT DEFINITIONS </p>
<p> 2. INDUSTRY OVERVIEW </p>
<p> Artificial Intelligence (AI): Allowing Machines to Perform Human-like Tasks, Automate Processes, Improve Productivity and Enhance User Experience </p>
<p> Digitization of Business, Industrial & Consumer Processes and Expanding Use Cases to Propel AI Revenues Worldwide </p>
<p> Inherent Advantages of AI Technology to Accelerate Adoption in Varied Applications </p>
<p> Data Deluge from Digital Devices: AI Emerges as a Solution to Manage, Analyze and Gain Insights from Data </p>
<p> Constant Advancements in Computing Power: An Essential Factor for Commercialization of AI Applications </p>
<p> AI-based Software Segment Captures Major Share of Global AI Market </p>
<p> Developed Markets Dominate AI Market, Asia-Pacific to Spearhead Future Growth </p>
<p> Countries Adopt Strategic Plans to Promote AI </p>
<p> Automotive and Healthcare: Promising End-Use Markets for Artificial Intelligence </p>
<p> Deep Learning and Digital Assistant Technologies Present Significant Growth Potential </p>
<p> Challenges Restraining AI Adoption </p>
<p> Investors Flock to Fund AI Startups: An Indication to the High Potential of AI Technology </p>
<p> Use of AI Algorithms among Unicorns across Industries </p>
<p> AI Research Continues to Attract Investment </p>
<p> 3. GROWTH DRIVERS, MARKET TRENDS AND ISSUES </p>
<p> Rising Significance of Internet of Things (IoT) for AI </p>
<p> Convergence of AI and IoT: Creating Intelligent and Smart Things </p>
<p> Funding to AI in IoT/IIoT </p>
<p> Promising Early Stage AI Companies in IoT and IIoT Sector </p>
<p> AI as a Service Market: Obviating the Need to Make Huge Initial Investments </p>
<p> Increasing Adoption of AI Technology to Boost AI Chipsets Market </p>
<p> Combination of Robotics and AI Set to Cause Significant Disruption in Various Industries </p>
<p> AI Set to Transform Service Robotics Market </p>
<p> Industrial Robots Evolve as Thinkers with Advancements in AI </p>
<p> Catalysts for Innovations in Artificial Intelligence Market </p>
<p> The Use of Unsupervised Learning Models </p>
<p> Rising Significance of Robotics Process Automation (RPA) </p>
<p> Emergence of Intelligent AI-Integrated Apps in Enterprises </p>
<p> AI Developments to Enable Emotional Understanding </p>
<p> Impact of AI on the Job Market - Despite Concerns Many Positives Exist </p>
<p> 4. END-USE ANALYSIS </p>
<p> Aviation Industry: A Nascent End-Use with Tremendous Untapped Potential for AI Technology </p>
<p> Story continues </p>
<p> Air Transport Industry Taps AI for Efficient Baggage Handling </p>
<p> AI-Enabled Advanced Electronic Warfare Systems Help Airborne Platforms to Counter Threats from Adaptive Radars </p>
<p> Intelligent Drones and AI Technology to Provide Actionable Intelligence and Insights </p>
<p> AI in Media & Advertising: Targeting Customers with Right Marketing Content </p>
<p> Funding for AI in Advertising & Marketing </p>
<p> Promising Early Stage AI Companies in Advertising and Marketing Sector </p>
<p> Possibilities Galore for AI in Digital Marketing </p>
<p> Marketing Functions Where AI is Yet Impossible to Deploy </p>
<p> AI-Enabled CRM Market: Promising Growth Opportunities in Store </p>
<p> Artificial Intelligence to Transform Delivery of Healthcare Services </p>
<p> Healthcare AI Market to Experience Remarkable Expansion </p>
<p> AI to Improve Basic Healthcare Services </p>
<p> AI Potential in Improving Utilization of Resources </p>
<p> Growing Focus on Patient Care and Management </p>
<p> R&D Efforts to Promote Use AI in Healthcare </p>
<p> Robot-Assisted Surgery and Virtual Nursing Assistants: Major Applications in Healthcare AI Market </p>
<p> AI in Medical Diagnostics and Pharmaceutical Sectors </p>
<p> Rising Prevalence of Diabetes to Drive AI Adoption in Diabetes Management Market </p>
<p> North America Dominates the Global Healthcare AI Market </p>
<p> Despite High Potential, Certain Barriers Restrain AI Adoption in Healthcare Sector </p>
<p> AI in Healthcare Market - A Fragmented Landscape </p>
<p> Healthcare AI Attracts Investor Interest </p>
<p> Promising Early-Stage AI Companies in Healthcare Industry </p>
<p> AI in Retail Market: Multi-Channel Retailing and e-Commerce Favor Segment Growth </p>
<p> AI for a Competitive Edge for Retail Organizations </p>
<p> Emerging AI Tools Set to Transform the Retail Industry </p>
<p> E-Commerce: A Sector with Tremendous Potential for AI Technology </p>
<p> Lash Group Introduces AI-Powered Electronic Benefit Verification Solution </p>
<p> Oracle Announces New AI Cloud Applications for Manufacturing Companies </p>
<p> Google Introduces Third Generation AI Chips </p>
<p> NetSuite Announces AI and Machine Learning-based Intelligent Cloud Suite </p>
<p> Oracle Launches AI-based Applications for Oracle Customer Experience (CX) Cloud Suite </p>
<p> SAS Launches SAS Viya with Embedded AI and Automation Capabilities </p>
<p> Philips Introduces AI-based HealthSuite Insights Platform </p>
<p> Nuance Unveils New TTS Technology with Deep Neural Networks </p>
<p> Oracle Unveils AI-based Applications for ERP </p>
<p> Nuance Unveils AI-Powered Solutions for Cars and Smart Homes </p>
<p> Nuance Releases Nuance AI Marketplace for Diagnostic Imaging </p>
<p> SAP Incorporates ML and Predictive Analytics for Cloud-Based Integrated Business Planning Suite </p>
<p> 7.3 Recent Industry Activity </p>
<p> Microsoft Takes Over Semantic Machines </p>
<p> Cisco Acquires Accompany </p>
<p> Paylocity Chooses eGain's AI Reasoning Solution for Guiding Customer Service Experience </p>
<p> NVIDIA and Canon Partner for Promoting Deep Learning in Healthcare </p>
<p> C3 IoT Enters into Strategic Partnership with Microsoft for AI in Enterprise Sector </p>
<p> SAS Creates New Division to Combat Fraud with AI and Advanced Analytics </p>
<p> Adobe Inks Strategic Partnership Deal with NVIDIA for AI and Deep Learning Technologies </p>
<p> NVIDIA Forges Partnership with Arm for Deep Learning Technology </p>
<p> L'Oral Takes Over ModiFace </p>
<p> Siemens and Munich Airport in Partnership for Using AI </p>
<p> S&P Global to Take Over Kensho Technologies </p>
<p> Xiaomi and Microsoft Ink Deal to Strengthen AI and Cloud Computing </p>
<p> Publicis Groupe Enters into Partnership with Microsoft for Developing Marcel AI Platform </p>
<p> Uber Selects NVIDIA technology for AI Computing System in Self-Driving Fleets </p>
<p> Volkswagen and NVIDIA Partner to Integrate NVIDIA DRIVE IX Platform in Intelligent Vehicles </p>
<p> Google Establishes New AI Research Center in China </p>
<p> Intuit Chooses AWS for AI and Machine Learning </p>
<p> GE Healthcare and NVIDIA Team Up for Promoting AI Adoption in Healthcare </p>
<p> Nuance and NVIDIA to Provide Machine Learning for Radiology </p>
<p> SAP Expands SAP Leonardo Machine Learning Foundation </p>
<p> Genpact Takes Over Rage Frameworks </p>
<p> Mercedes-Benz Partners with NVIDIA for AI Car Technology </p>
<p> HERE Extends Collaboration with NVIDIA for AI-based HERE HD Live Map </p>
<p> NVIDIA Collaborates with ZENRIN for AI-Powered HD Mapping for Japan </p>
<p> Vector and mPrest Develop AI and ML System for Managing Auckland's Electricity Network </p>
<p> Microsoft Establishes AI-based Healthcare Division </p>
<p> Facebook Sets Up AI Research Lab in Montreal </p>
<p> IBM and MIT Partner to Establish MIT-IBM Watson AI Lab </p>
</article>
<article url="https://mashable.com/2017/05/17/google-io-artificial-intelligence-plan/" parent_folder="ai_corpus" id="file14034856" filename="google-io-artificial-intelligence-plan">
<p> Tech </p>
<p> Google's vision for AI is the right one </p>
<p> Google is right. Artificial Intelligence can help us, dammit. </p>
<p> The notion of a coming AI apocalypse has grown tiresome, especially because it invariably makes the leap from the nascent forms of AI we experience now to a terrifying future were every robot can out-think and, eventually, annihilate us. </p>
<p> It’s time to focus on the now, which is why I was so pleased with Google’s I/O 2017 developer’s keynote on Wednesday. </p>
<p> In it, Google CEO Sundar Pichai described the fundamental shift from a mobile-first landscape to an AI-first one. </p>
<p> Putting AI first doesn’t cut out mobile. In fact, mobile hardware and software remain a crucial part of Google’s strategy, but now all of it is infused, at some level, with artificial intelligence and, especially, machine learning. </p>
<p> Google’s approach to neural nets and deep learning — core components of machine learning and AI — though, stands in contrast to Facebook’s approach where, during its own developer’s conference, Facebook took us right to the edge of computer-human interface insanity. </p>
<p> Google, on the other hand, appeared less interested in wowing us than it did it showing us repeatedly the practical applications of AI and machine learning in our everyday lives. </p>
<p> They also, smartly, extended last year’s open-source TensorFlow machine learning platform to the Google Cloud. This puts the awesome power of a machine learning brain in the hands of the broadest array of people— who, perhaps unlike Google, might see applications beyond the knowledge graph, Google Platforms and making sure apps don’t suck the life out of the Android phones. </p>
<p> That said, I’m a big fan of virtually every machine-learning integration Google showed off on Wednesday. </p>
<p> To understand what Google is doing with AI and machine learning, you need to look at the speech and vision systems. The two are set to transform how we engage with images, search and the unknown. </p>
<p> Broadly, Google AI wants to answer two of our biggest and most basic questions, “What is that?” and “Now what?” </p>
<p> Googles object identification (the “What is that” part) in Google Lens is impressive, but also not necessarily groundbreaking. Everyone from Samsung to even Pinterest uses image recognition tools to identify objects. </p>
<p> The second part is, obviously, where the machine-learning magic comes in. </p>
<p> Google’s ability to help you act (that’s the “Now what?” part) on what it identifies is another level of AI utility. My favorite example, and the one that generated the most applause during the keynote, was the ability to point Google Lens at a router wireless setting label and automatically pick up the SSID and password, enter them into your system settings, and connect you. </p>
<p> Google Photos has so many machine-learning capabilities, I could scarcely mention them all here. But the ability to ID faces in photos and auto-share new images with those people, and automate the creation of physical photo books, make the cloud-based backup tool worth a second look. </p>
<p> The Google Photo prowess is also a reminder of how much artificial intelligence can do for you when you’re not paying attention. Yes, everyone likes to make fun of AI assistants (like Google Assistant, which does a better job with conversation than Alexa and Siri) that can’t answer questions or carry on a decent conversation, but, like robotics, the AI’s best work is done in the background. </p>
<p> Google is more than willing to tout the work it’s doing with AI, but the results can be subtle. Google for Jobs, for example, is a powerful machine learning enhancement for Google Search solely designed to help people find jobs. That’s the least showy kind of AI, yet it could have the most meaningful and direct impact on individuals. That, I believe, is the true promise of AI. </p>
<p> Google's approach to AI reminds me of Microsoft's: less flash, more function. Microsoft's intelligence is mostly inside its productivity tools, but is quickly bleeding out across the rest of its strategy. There is also a crucial difference between the two companies. Microsoft's business model is not built on advertising, so it's unlikely they'll also use the data they're collecting for profit. </p>
<p> Google's approach to AI reminds me of Microsoft's: less flash, more function </p>
<p> "For consumers, Google’s AI strategy seems a lot more compelling than Facebook’s, but no less scary," said Patrick Moorhead, president and principal analyst for Moor Insights. </p>
<p> "For Google’s AI work well, it needs loads and loads of personal information. That personal information will improve functionality for Home and Photos and it will be used commercially to create denser user profiles." </p>
<p> I know there are many who, like Moorhead, believe that Google is using the world’s search data to drive advertising and fill Google executives and shareholders' pockets with cash – and maybe they are. </p>
<p> Yet, the Google I/O keynote reminds us that Google also has the potential to do, and help others do, enormous good with artificial intelligence. </p>
<p> As Sundar Pichai said in his blog post on AI: </p>
<p> We believe huge breakthroughs in complex social problems will be possible if scientists and engineers can have better, more powerful computing tools and research at their fingertips. </p>
<p> Google even launched an AI web site to connect everyone with its best work and tools in the space. </p>
<p> You may not love AI and perhaps you still fear the rise of our robot overlords, but I encourage you to pause for just a moment and appreciate the beauty of a selection tool that doesn’t assume you've highlighted six unrelated words on your phone, when you're really selecting an address and want to find it on a map now. </p>
<p> Google’s AI knows the difference and you should say, “Thank you.” </p>
</article>
<article url="https://gizmodo.com/hackers-have-already-started-to-weaponize-artificial-in-1797688425" parent_folder="ai_corpus" id="file14034849" filename="hackers-have-already-started-to-weaponize-artificial-in-1797688425">
<p> Last year, two data scientists from security firm ZeroFOX conducted an experiment to see who was better at getting Twitter users to click on malicious links, humans or an artificial intelligence. The researchers taught an AI to study the behavior of social network users, and then design and implement its own phishing bait. In tests, the artificial hacker was substantially better than its human competitors, composing and distributing more phishing tweets than humans, and with a substantially better conversion rate. </p>
<p> The AI, named SNAP_R, sent simulated spear-phishing tweets to over 800 users at a rate of 6.75 tweets per minute, luring 275 victims. By contrast, Forbes staff writer Thomas Fox-Brewster, who participated in the experiment, was only able to pump out 1.075 tweets a minute, making just 129 attempts and luring in just 49 users. </p>
<p> Advertisement </p>
<p> Thankfully this was just an experiment, but the exercise showed that hackers are already in a position to use AI for their nefarious ends. And in fact, they’re probably already using it, though it’s hard to prove. In July, at Black Hat USA 2017, hundreds of leading cybersecurity experts gathered in Las Vegas to discuss this issue and other looming threats posed by emerging technologies. In a Cylance poll held during the confab, attendees were asked if criminal hackers will use AI for offensive purposes in the coming year, to which 62 percent answered in the affirmative. </p>
<p> The era of artificial intelligence is upon us, yet if this informal Cylance poll is to be believed, a surprising number of infosec professionals are refusing to acknowledge the potential for AI to be weaponized by hackers in the immediate future. It’s a perplexing stance given that many of the cybersecurity experts we spoke to said machine intelligence is already being used by hackers, and that criminals are more sophisticated in their use of this emerging technology than many people realize. </p>
<p> “Hackers have been using artificial intelligence as a weapon for quite some time,” said Brian Wallace, Cylance Lead Security Data Scientist, in an interview with Gizmodo. “It makes total sense because hackers have a problem of scale, trying to attack as many people as they can, hitting as many targets as possible, and all the while trying to reduce risks to themselves. Artificial intelligence, and machine learning in particular, are perfect tools to be using on their end.” These tools, he says, can make decisions about what to attack, who to attack, when to attack, and so on. </p>
<p> “What does strike me as a bit odd is that 62 percent of infosec professionals are making an AI prediction,” Goodman told Gizmodo. “AI is defined by many different people many different ways. So I’d want further clarity on specifically what they mean by AI.” </p>
<p> Indeed, it’s likely on this issue where the expert opinions diverge. </p>
<p> The funny thing about artificial intelligence is that our conception of it changes as time passes, and as our technologies increasingly match human intelligence in many important ways. At the most fundamental level, intelligence describes the ability of an agent, whether it be biological or mechanical, to solve complex problems. We possess many tools with this capability, and we have for quite some time, but we almost instantly start to take these tools for granted once they appear. </p>
<p> Advertisement </p>
<p> Centuries ago, for example, the prospect of a calculating machine that could crunch numbers millions of times faster than a human would’ve most certainly been considered a radical technological advance, yet few today would consider the lowly calculator as being anything particularly special. Similarly, the ability to win at chess was once considered a high mark of human intelligence, but ever since Deep Blue defeated Garry Kasparov in 1997, this cognitive skill has lost its former luster. And so and and so forth with each passing breakthrough in AI. </p>
<p> Advertisement </p>
<p> Today, rapid-fire developments in machine learning (whereby systems learn from data and improve with experience without being explicitly programmed), natural language processing, neural networks (systems modeled on the human brain), and many other fields are likewise lowering the bar on our perception of what constitutes machine intelligence. In a few years, artificial personal assistants (like Siri or Alexa), self-driving cars, and disease-diagnosing algorithms will likewise lose, unjustifiably, their AI allure. We’ll start to take these things for granted, and disparage these forms of AI for not being perfectly human. But make no mistake—modern tools like machine intelligence and neural networks are a form of artificial intelligence, and to believe otherwise is something we do at our own peril; if we dismiss or ignore the power of these tools, we may be blindsided by those who are eager to exploit AI’s full potential, hackers included. </p>
<p> A related problem is that the term artificial intelligence conjures futuristic visions and sci-fi fantasies that are far removed from our current realities. </p>
<p> Advertisement </p>
<p> “The term AI is often misconstrued, with many people thinking of Terminator robots trying to hunt down John Connor—but that’s not what AI is,” said Wallace. “Rather, it’s a broad topic of study around the creation of various forms of intelligence that happen to be artificial.” </p>
<p> Wallace says there are many different realms of AI, with machine learning being a particularly important subset of AI at the current moment. </p>
<p> Advertisement </p>
<p> “In our line of work, we use narrow machine learning—which is a form of AI—when trying to apply intelligence to a specific problem,” he told Gizmodo. “For instance, we use machine learning when trying to determine if a file or process is malicious or not. We’re not trying to create a system that would turn into SkyNet. Artificial intelligence isn’t always what the media and science fiction has depicted it as, and when we [infosec professionals] talk about AI, we’re talking about broad areas of study that are much simpler and far less terrifying.” </p>
<p> Evil intents </p>
<p> These modern tools may be less terrifying than clichéd Terminator visions, but in the hands of the wrong individuals, they can still be pretty scary. </p>
<p> Advertisement </p>
<p> Deepak Dutt, founder and CEO of Zighra, a mobile security startup, says there’s a high likelihood that sophisticated AI will be used for cyberattacks in the near future, and that it might already be in use by countries such as Russia, China, and some Eastern European countries. In terms of how AI could be used in nefarious ways, Dutt has no shortage of ideas. </p>
<p> “Artificial intelligence can be used to mine large amounts of public domain and social network data to extract personally identifiable information like date of birth, gender, location, telephone numbers, e-mail addresses, and so on, which can be used for hacking [a person’s] accounts,” Dutt told Gizmodo. “It can also be used to automatically monitor e-mails and text messages, and to create personalized phishing mails for social engineering attacks [phishing scams are an illicit attempt to obtain sensitive information from an unsuspecting user]. AI can be used for mutating malware and ransomware more easily, and to search more intelligently and dig out and exploit vulnerabilities in a system.” </p>
<p> Advertisement </p>
<p> Dutt suspects that AI is already being used for cyberattacks, and that criminals are already using some sort of machine learning capabilities, for example, by automatically creating personalized phishing e-mails. </p>
<p> “But what is new is the sophistication of AI in terms of new machine learning techniques like Deep Learning, which can be used to achieve the scenarios I just mentioned with a higher level of accuracy and efficiency,” he said. Deep Learning, also known as hierarchical learning, is a subfield of machine learning that utilizes large neural networks. It has been applied to computer vision, speech recognition, social network filtering, and many other complex tasks, often producing results superior to human experts. </p>
<p> Advertisement </p>
<p> “Also the availability of large amounts of social network and public data sets (Big Data) helps. Advanced machine learning and Deep Learning techniques and tools are easily available now on open source platforms—this combined with the relatively cheap computational infrastructure effectively enables cyberattacks with higher sophistication.” </p>
<p> These days, the overwhelming number of cyber attacks is automated, according to Goodman. The human hacker going after an individual target is far rarer, and the more common approach now is to automate attacks with tools of AI and machine learning—everything from scripted Distributed Denial of Service (DDoS) attacks to ransomware, criminal chatbots, and so on. While it can be argued that automation is fundamentally unintelligent (conversely, a case can be made that some forms of automation, particularly those involving large sets of complex tasks, are indeed a form of intelligence), it’s the prospect of a machine intelligence orchestrating these automated tasks that’s particularly alarming. An AI can produce complex and highly targeted scripts at a rate and level of sophistication far beyond any individual human hacker. </p>
<p> Advertisement </p>
<p> Indeed, the possibilities seem almost endless. In addition to the criminal activities already described, AIs could be used to target vulnerable populations, perform rapid-fire hacks, develop intelligent malware, and so on. </p>
<p> Staffan Truvé, Chief Technology Officer at Recorded Future, says that, as AI matures and becomes more of a commodity, the “bad guys,” as he puts it, will start using it to improve the performance of attacks, while also cutting costs. Unlike many of his colleagues, however, Truvé says that AI is not really being used by hackers at the moment, claiming that simpler algorithms (e.g. for self-modifying code) and automation schemes (e.g. to enable phishing schemes) are working just fine. </p>
<p> Advertisement </p>
<p> “I don’t think AI has quite yet become a standard part of the toolbox of the bad guys,” Truvé told Gizmodo. “I think the reason we haven’t seen more ‘AI’ in attacks already is that the traditional methods still work—if you get what you need from a good old fashioned brute force approach then why take the time and money to switch to something new?” </p>
<p> AI on AI </p>
<p> With AI now part of the modern hacker’s toolkit, defenders are having to come up with novel ways of defending vulnerable systems. Thankfully, security professionals have a rather potent and obvious countermeasure at their disposal, namely artificial intelligence itself. Trouble is, this is bound to produce an arms race between the rival camps. Neither side really has a choice, as the only way to counter the other is to increasingly rely on intelligent systems. </p>
<p> Advertisement </p>
<p> “For security experts, this is Big Data problem—we’re dealing with tons of data—more than a single human could possibly produce,” said Wallace. “Once you’ve started to deal with an adversary, you have no choice but to use weaponized AI yourself.” </p>
<p> Advertisement </p>
<p> To stay ahead of the curve, Wallace recommends that security firms conduct their own internal research, and develop their own weaponized AI to fight and test their defenses. He calls it “an iron sharpens iron” approach to computer security. The Pentagon’s advanced research wing, DARPA, has already adopted this approach, organizing grand challenges in which AI developers pit their creations against each other in a virtual game of Capture the Flag. The process is very Darwinian, and reminiscent of yet another approach to AI development—evolutionary algorithms. For hackers and infosec professionals, it’s survival of the fittest AI. </p>
<p> Goodman agrees, saying “we will out of necessity” be using increasing amounts of AI “for everything from fraud detection to countering cyberattacks.” And in fact, several start-ups are already doing this, partnering with IBM Watson to combat cyber threats, says Goodman. </p>
<p> Advertisement </p>
<p> “AI techniques are being used today by defenders to look for patterns—the antivirus companies have been doing this for decades—and to do anomaly detection as a way to automatically detect if a system has been attacked and compromised,” said Truvé. </p>
<p> At his company, Recorded Future, Truvé is using AI techniques to do natural language processing to, for example, automatically detect when an attack is being planned and discussed on criminal forums, and to predict future threats. </p>
<p> Advertisement </p>
<p> “Bad guys [with AI] will continue to use the same attack vectors as today, only in a more efficient manner, and therefore the AI based defense mechanisms being developed now will to a large extent be possible to also use against AI based attacks,” he said. </p>
<p> Dutt recommends that infosec teams continuously monitor the cyber attack activities of hackers and learn from them, continuously “innovate with a combination of supervised and unsupervised learning based defense strategies to detect and thwart attacks at the first sign,” and, like in any war, adopt superior defenses and strategy. </p>
<p> Advertisement </p>
<p> The bystander effect </p>
<p> So our brave new world of AI-enabled hacking awaits, with criminals becoming increasingly capable of targeting vulnerable users and systems. Computer security firms will likewise lean on a AI in a never ending effort to keep up. Eventually, these tools will escape human comprehension and control, working at lightning fast speeds in an emerging digital ecosystem. It’ll get to a point where both hackers and infosec professionals have no choice but to hit the “go” button on their respective systems, and simply hope for the best. A consequence of AI is that humans are increasingly being kept out of the loop. </p>
</article>
<article url="https://in.mashable.com/tech/4752/how-artificial-intelligence-is-helping-tourism" parent_folder="ai_corpus" id="file14034852" filename="how-artificial-intelligence-is-helping-tourism">
<p> How Artificial Intelligence Is Helping Tourism </p>
<p> In today’s day and age, it’s hard to spot an industry that’s not been impacted by Artificial Intelligence. From banking to agriculture to retail, all the fields have been radically transformed by the wonders of Artificial Intelligence. Another industry that’s leveraging the transformational benefits of AI is the tourism industry. </p>
<p> As per Statista, the travel and tourism industry is one of the world’s largest industries with a global economic contribution of over 7.6 trillion U.S. dollars in 2016. Also, the direct economic impact of the tourism industry, including accommodation, transportation, entertainment and attractions, amounted up to approximately 2.3 trillion U.S. dollars that year. So, it makes sense for such a growing industry to use technology as groundbreaking as Artificial Intelligence. </p>
<p> As Artificial Intelligence brings along with it the power of automation, it is helping make travel experiences more niche and targeted towards travellers. AI can help travel agents analyze travellers profile by looking at their preferences, budget, location, eating habits, and choices, thereby, helping produce personalized and tailor-made suggestions for travellers. There are many companies in the market that use AI to enhance travel experiences too. </p>
<p> In conversation with Mashable India, Vice-president for global experiences, Ram Papatla, Booking.com, talks about how AI makes it easy for travellers to plan their trip. </p>
<p> How are you integrating AI, especially with Booking.Com for Indian users? </p>
<p> We think of AI as the core of what we do. And it's really hard to say that we do it only for a specific market. But what is interesting is that we're looking at patterns and anti-patterns in sort of every market and sort of learning from that and figuring out. At the moment, there is no specific plan for India. </p>
<p> When a user logs onto to Booking.com, the app offers suggestions. On what basis are these suggestions offered? Is it based on any specific data? </p>
<p> There are many ways. The journey starts with what we call as an ‘unknown state’ which means we don’t know where you are going. There will be three states – we don’t know where you are going, we know you are going, and we know you are there. SO depending on those three states, we can really reflect the right content for the user. So when you register for the time, there will be a lot we know about you, and a lot we don’t. </p>
<p> Is this because we log on from social media apps such as Facebook? </p>
<p> Possible. If you log in from an iPhone, or from India or a particular bandwidth and perhaps there are cohorts of very similar people like you, who can start to understand it. With the help of Google and Facebook, or any other signals who know a little bit more about you from the ad portal too. So I think that’s what we start from. We start really broad, and then we can see it become very narrow. The moment a user makes an account with us, and do their first booking, of course, we get to know a lot more as we get to know a little more about your price affinity and the kind of travel you’d like. And then we can help you suggest. </p>
<p> How exactly do you think machine learning will transform tourism in the future? </p>
<p> I think machine learning is a fantastic hub. But tourism and travel are all about serendipity. It’s really about telling you the next thing to do. For example, when you look at e-commerce websites, and for instance, if you want to buy diapers, they’ll probably also tell you to buy baby wipes, or maybe when you buy a lipstick, you should probably get a lip liner. But u can’t do this with travel. It’s really hard to say that. For instance, you can’t tell someone that just because they took a boat ride, you should go on a bike ride. It doesn’t make any sense. It’s more about serendipity – it’s more about how many days you are there or it’s more about the weather. It’s more about what else are you doing during your trip. It's more deeply thinking about the customer and using that as the context. That’s why AI in travel is very hard. </p>
<p> Is there any risk of using AI in tourism? </p>
<p> The fundamental thing about using AI is really about possible discrimination (situations where the host was caught neglecting a few customers) because those patterns can be learned by computers. They also need to have a very good un-learning mechanism as well. So where the computers don’t learn about the things that they are not supposed to. So the big risk is that the company should be very responsible about the end-to-end flows and not just about getting a conversion head or worrying about a transaction. But worrying about this is the right thing. For example, if one sees something offensive in images, one should be responsible to say that he/she would do something about it and not just walk away from the issue. So that’s the worrisome part about AI. </p>
<p> Any specific plans for India? </p>
<p> As a company, the main thing we are looking in India is how we’re thinking about experiences and how we unlock such a complicated market because the diversity is daunting, and there are so many different regions and a lot of friction in terms of digital tools. A lot of tours or activities in the country and are still phone-based or paper-based. And it’s a really big challenge for us to work with India to get everybody on board an additional platform, just like we’ve done with Accommodations. At the moment, we are harvesting the market, learning about it and what we’ve realized is that it’s a very complex market. But the opportunities are amazing. And it’s going to be a long road, in terms of how we organize it. </p>
<p> So as it appears, there’s still a long way to go before Artificial Intelligence establishes itself well in the tourism industry. Travel companies are persistently trying to look for areas where AI can fit in a way where these companies would be able to truly leverage its wonders. Given that Artificial Intelligence is quite a complex field and comes with its own set of challenges, it only seems right for travel companies to take their time to explore what AI can do for them. </p>
</article>
<article url="https://www.cnn.com/2019/02/17/investing/artificial-intelligence-investors-machine-learning/index.html" parent_folder="ai_corpus" id="file14034861" filename="index.html">
<p> How elite investors use artificial intelligence and machine learning to gain an edge </p>
<p> Chat with us in Facebook Messenger. Find out what's happening in the world as it unfolds. </p>
<p> New York (CNN Business)Artificial intelligence and machine learning might sound like the stuff of sci-fi movies. But hedge funds, major banks and private equity firms are already deploying next-generation technologies to gain an edge. </p>
<p> Citigroup (C) uses machine learning to make portfolio recommendations to clients. High-frequency trading firms rely on machine learning tools to rapidly read and react to financial markets. And quant shops like PanAgora Asset Management have developed complex algorithms to test sophisticated investment ideas. </p>
<p> "It takes emotion out of it. Everything is rational," Mike Chen, an equity portfolio manager at Boston-based PanAgora, told CNN Business from the sidelines of the Cayman Alternative Investment Summit in Grand Cayman. </p>
<p> "We're not crazy pointed-hair scientists," said Chen, whose quantitative investment firm manages about $43 billion in assets. </p>
<p> Much of the technology that elite investors use isn't really new. Financial firms are just better able to harness the power of AI and machine learning because today's computers can process information much faster. And there now exists vastly more data than there did years ago. </p>
<p> Read More </p>
<p> The rise of machine learning </p>
<p> Still, technology is rapidly disrupting the financial industry -- and will continue to do so. </p>
<p> "The rise of machine learning will really make our industry unrecognizable in the future," said Anthony Cowell, head of asset management for KPMG in the Cayman Islands. His clients include some of the world's largest asset managers, hedge funds and private-equity firms. </p>
<p> For instance, Citi Private Bank has deployed machine learning to help financial advisors answer a question they're frequently asked: What are other investors doing with their money? By using technology, the bank can anonymously share portfolio moves being made by clients all over the planet. </p>
<p> "Traditionally that kind of information was sourced from your network. You might have had a few coffees or heard about it over a cocktail," Philip Watson, head of the global investment lab at Citi and chief innovation officer at Citi Private Bank, told CNN Business. "Now, we can share insight that is very valuable." </p>
<p> Citi also built a recommender engine that uses machine learning tools to advise clients. The platform recommends tailored research reports, solutions and even alerts clients of major events such as the maturity of a bond in their portfolio. </p>
<p> Machines assist high-speed traders </p>
<p> Domeyard, a Boston hedge fund that focuses on high-frequency trading, depends on machine learning to decipher 300 million data points in the New York Stock Exchange's opening hour of trading alone. </p>
<p> "We rely on the help of machines to make easier and faster predictions of what will happen in the next second or minute," said Christine Qi, Domeyard's co-founder and partner. </p>
<p> But Qi cautioned that machines are "only as smart as the data you're feeding it." </p>
<p> Earlier this year, PanAgora, the Boston quant shop, expanded its exposure to China by launching a "self-learning" algorithm that deciphers Chinese "cyber slang" used by investors on social media to get around government censorship, Chen said. The findings give portfolio managers at PanAgora a valuable window into sentiment among retail investors, who dominate the market in China. </p>
<p> Man vs. machine? </p>
<p> Technology executives warn not to believe all the hype about artificial intelligence and machine learning -- especially about robots taking over. </p>
<p> "Some of the effects can be wildly exaggerated," said Citi's Watson. "It's a human plus machine world. It's not a machine-only model. Nor do I see it becoming a machine-only model for a long, long time." </p>
<p> PanAgora's Chen agreed. "It's not man versus machine. It's man plus machine." </p>
<p> At PanAgora, humans have the final say on investment decisions and at times override what the computer models tell them to do. </p>
<p> "Machines are not sentient. Terminators are not going to rise up and kill us all in the next 10 years," Chen said. "I hope." </p>
<p> Most jobs will be impacted </p>
<p> But that doesn't mean humans won't be disrupted. </p>
<p> "We do believe that 100% of all roles and jobs could be impacted," said Mark Foster, senior vice president of IBM (IBM) Global Business Services. </p>
<p> Foster said that the most optimistic outcome is that businesses, governments and education systems get ahead of this disruption by re-skilling workers. </p>
<p> "Probably the world is moving more slowly than that. There is a risk that people will be left behind," Foster said. "It's incumbent upon us in business that we're helping our workforces get ahead of the curve." </p>
<p> Rather than getting outright displaced, Citi's Watson thinks many workers doing menial back-office jobs could be moved to more rewarding positions. </p>
<p> What's next? </p>
<p> In the future, the financial industry will be further disrupted by the rise of emerging technologies -- like quantum computing. </p>
<p> "It will be able to solve problems we could never touch before," said Mark Jackson, scientific lead at UK-based Cambridge Quantum Computing. </p>
<p> IBM (IBM), Google, Intel (INTC) and other major companies have spent heavily to develop quantum technologies, but experts aren't exactly sure what these super computers will be used for. </p>
<p> "We actually don't know yet," Jackson said when asked for specific use cases. "We're just beginning to understand the power of this." </p>
<p> He said it's already clear that quantum computers will excel in several areas: encryption, security, chemistry and machine learning. </p>
<p> "It will live up to the hype," Jackson said. </p>
<p> There are still many things that computers can't do in the financial realm. </p>
<p> For instance, sophisticated investors often use game theory to map out how other market players will react to a given situation. Game theory allows firms to cash in by positioning themselves -- before sharp market swings occur. </p>
<p> PanAgora's Chen said that machines can't do that -- yet. </p>
<p> "I hope to see it in the next five to 15 years," he said. </p>
</article>
<article url="https://answers.yahoo.com/question/index?qid=1006011906755" parent_folder="ai_corpus" id="file14034838" filename="index?qid=1006011906755">
<p> what is the difference between machine learning and artificial intelligence? </p>
<p> 4 Answers </p>
<p> This is just the way I see it, machine learning is a machine learning, by training or whatever process, how to execute a process rather than it being preprogrammed. An example of this is the adaptive programming in the engine control computers of cars that have been around for almost 20 years. </p>
<p> Artificial intelligence would, in my opinion, not only would it learn what to do, but also decide when to do what it wants to do. Intelligence, at least partly, is the ability to make decisions without instruction and programming. </p>
<p> I know that this is vague, but I am not sure if that is what you were looking for. Hope this helps. </p>
<p> Machine Learning is actually an advanced type of artificial learning... now if you ask what is the difference between data mining and machine learning (which are both advanced artificial intelligence field) -- data mining is essentially the art of finding relations from a huge amount of data whereas machine learning has limited and usually good quality of data to learn rules from (both of these could be applied/used in a system to make it artificially intelligent :) </p>
<p> Virtual reality...does not actually exist...."virtual " meaning it only exists in imagination or parallel segment of real life Artificial intelligence....robots, machines, computers...that's artificial intelligence, providers of manufactured resources of intelligence The relation might be they both are related to next stage of PC development </p>
<p> mchine learning is something that to get the experience and Artficial intelligence is using these experience to make decisions. </p>
<p> 000 </p>
<p> Login to reply the answersPost </p>
<p> Still have questions? Get your answers by asking now. </p>
</article>
<article url="https://www.washingtonpost.com/science/2019/04/12/is-artificial-intelligence-intelligent-how-machine-learning-has-developed/" parent_folder="ai_corpus" id="file14034869" filename="is-artificial-intelligence-intelligent-how-machine-learning-has-developed">
<p> Is artificial intelligence intelligent? How machine learning has developed. </p>
<p> What makes artificial intelligence intelligent? Is it able to learn from errors or recognize, say, the letters of the alphabet in a set of random shapes like a human can? </p>
<p> These are some of the questions developers of AI ask. What began as sluggish programs on hulking machines has taken the form of code that anyone in a particular field could test out and manipulate to suit their needs. </p>
<p> Sohn’s research is still developing, but with the early success of the algorithm to detect these subtle changes, AI may have an important role to come in the health industry. </p>
<p> While AI’s practical applications continue to be evaluated, our understanding of natural intelligence and what makes for accurate pattern recognition is being studied as well. Jeff Hawkins, co-founder of Numenta, decided early on that if machines were to start behaving more intelligently, he was going to have to study the brain. </p>
<p> One of Hawkins’s recent areas of focus in the brain is cortical columns, which are structural units in the neocortex of the brain where, it is theorized, models of the objects we encounter in the world are constructed and stored. Hawkins said that one of the key components to knowing about how the brain understands objects and recognizes patterns is movement. The information we get from our senses as well as the location information of where we experience them over time is essential to our ability to recognize those patterns that define objects. Hawkins believes AI will continue to be limited in its emulation of the brain if we do not consider movement in the equation for intelligence. </p>
<p> In the video above, we take a closer look at a bit of the history of AI and where it stands today in its abilities and limitations as an “intelligent” tool. </p>
<p> Today's Headlines </p>
<p> We noticed you’re blocking ads! </p>
<p> Keep supporting great journalism by turning off your ad blocker. Or purchase a subscription for unlimited access to real news you can count on. </p>
</article>
<article url="https://www.newyorker.com/news/news-desk/is-deep-learning-a-revolution-in-artificial-intelligence" parent_folder="ai_corpus" id="file14034864" filename="is-deep-learning-a-revolution-in-artificial-intelligence">
<p> Is “Deep Learning” a Revolution in Artificial Intelligence? </p>
<p> Can a new technique known as deep learning revolutionize artificial intelligence, as yesterday’s front-page article at the New York Times suggests? There is good reason to be excited about deep learning, a sophisticated “machine learning” algorithm that far exceeds many of its predecessors in its abilities to recognize syllables and images. But there’s also good reason to be skeptical. While the Times reports that “advances in an artificial intelligence technology that can recognize patterns offer the possibility of machines that perform human activities like seeing, listening and thinking,” deep learning takes us, at best, only a small step toward the creation of truly intelligent machines. Deep learning is important work, with immediate practical applications. But it’s not as breathtaking as the front-page story in the New York Times seems to suggest. </p>
<p> The technology on which the Times focusses, deep learning, has its roots in a tradition of “neural networks” that goes back to the late nineteen-fifties. At that time, Frank Rosenblatt attempted to build a kind of mechanical brain called the Perceptron, which was billed as “a machine which senses, recognizes, remembers, and responds like the human mind.” The system was capable of categorizing (within certain limits) some basic shapes like triangles and squares. Crowds were amazed by its potential, and even The New Yorker was taken in, suggesting that this “remarkable machine…[was] capable of what amounts to thought.” </p>
<p> But the buzz eventually fizzled; a critical book written in 1969 by Marvin Minsky and his collaborator Seymour Papert showed that Rosenblatt’s original system was painfully limited, literally blind to some simple logical functions like “exclusive-or” (As in, you can have the cake or the pie, but not both). What had become known as the field of “neural networks” all but disappeared. </p>
<p> Rosenblatt’s ideas reëmerged however in the mid-nineteen-eighties, when Geoff Hinton, then a young professor at Carnegie-Mellon University, helped build more complex networks of virtual neurons that were able to circumvent some of Minsky’s worries. Hinton had included a “hidden layer” of neurons that allowed a new generation of networks to learn more complicated functions (like the exclusive-or that had bedeviled the original Perceptron). Even the new models had serious problems though. They learned slowly and inefficiently, and as Steven Pinker and I showed, couldn’t master even some of the basic things that children do, like learning the past tense of regular verbs. By the late nineteen-nineties, neural networks had again begun to fall out of favor. </p>
<p> Hinton soldiered on, however, making an important advance in 2006, with a new technique that he dubbed deep learning, which itself extends important earlier work by my N.Y.U. colleague, Yann LeCun, and is still in use at Google, Microsoft, and elsewhere. A typical setup is this: a computer is confronted with a large set of data, and on its own asked to sort the elements of that data into categories, a bit like a child who is asked to sort a set of toys, with no specific instructions. The child might sort them by color, by shape, or by function, or by something else. Machine learners try to do this on a grander scale, seeing, for example, millions of handwritten digits, and making guesses about which digits looks more like one another, “clustering” them together based on similarity. Deep learning’s important innovation is to have models learn categories incrementally, attempting to nail down lower-level categories (like letters) before attempting to acquire higher-level categories (like words). </p>
<p> Deep learning excels at this sort of problem, known as unsupervised learning. In some cases it performs far better than its predecessors. It can, for example, learn to identify syllables in a new language better than earlier systems. But it’s still not good enough to reliably recognize or sort objects when the set of possibilities is large. The much-publicized Google system that learned to recognize cats for example, works about seventy per cent better than its predecessors. But it still recognizes less than a sixth of the objects on which it was trained, and it did worse when the objects were rotated or moved to the left or right of an image. </p>
<p> Realistically, deep learning is only part of the larger challenge of building intelligent machines. Such techniques lack ways of representing causal relationships (such as between diseases and their symptoms), and are likely to face challenges in acquiring abstract ideas like “sibling” or “identical to.” They have no obvious ways of performing logical inferences, and they are also still a long way from integrating abstract knowledge, such as information about what objects are, what they are for, and how they are typically used. The most powerful A.I. systems, like Watson, the machine that beat humans in “Jeopardy,” use techniques like deep learning as just one element in a very complicated ensemble of techniques, ranging from the statistical technique of Bayesian inference to deductive reasoning. </p>
<p> In August, I had the chance to speak with Peter Norvig, Director of Google Research, and asked him if he thought that techniques like deep learning could ever solve complicated tasks that are more characteristic of human intelligence, like understanding stories, which is something Norvig used to work on in the nineteen-eighties. Back then, Norvig had written a brilliant review of the previous work on getting machines to understand stories, and fully endorsed an approach that built on classical “symbol-manipulation” techniques. Norvig’s group is now working within Hinton, and Norvig is clearly very interested in seeing what Hinton could come up with. But even Norvig didn’t see how you could build a machine that could understand stories using deep learning alone. </p>
<p> To paraphrase an old parable, Hinton has built a better ladder; but a better ladder doesn’t necessarily get you to the moon. </p>
<p> Photograph by Frederic Lewis/Archive Photos/Getty. </p>
<p> Gary Marcus is a professor of cognitive science at N.Y.U. and the author of “Guitar Zero.” </p>
<p> The Daily </p>
<p> Sign up for our daily newsletter and get the best of The New Yorker in your in-box. </p>
</article>
<article url="https://mashable.com/shopping/jan-16-ai-and-machine-learning-training-bundle/" parent_folder="ai_corpus" id="file14034857" filename="jan-16-ai-and-machine-learning-training-bundle">
<p> Shopping </p>
<p> Don't want a robot stealing your job? Take a course on AI and machine learning. </p>
<p> Just to let you know, if you buy something featured here, Mashable might earn an affiliate commission. </p>
<p> By StackCommerceMashable Shopping2020-01-16 19:44:17 UTC </p>
<p> From facial recognition to self-driving vehicles, machine learning is taking over modern life as we know it. It may not be the flying cars and world-dominating robots we envisioned 2020 would hold, but it's still pretty futuristic and frightening. The good news is if you're one of the pros making these smart systems and machines, you're in good shape. And you can get your foot in the door by learning the basics with this Essential AI and Machine Learning Certification Training Bundle. </p>
<p> This training bundle provides four comprehensive courses introducing you to the world of artificial intelligence and machine learning. And right now, you can get the entire thing for just $39.99. </p>
<p> These courses cover natural language processing, computer vision, data visualization, and artificial intelligence basics, and will ultimately teach you to build machines that learn as they're fed human input. Through hands-on case studies, practice modules, and real-time projects, you'll delve into the world of intelligent systems and machines and get ahead of the robot revolution. </p>
<p> Here's what you can expect from each course: </p>
<p> Artificial Intelligence (AI) & Machine Learning (ML) Foundation Course </p>
<p> Access 72 lectures and six hours of content exploring topics like convolutional neural networks (CNNs), recurrent neural networks (RNNs), and other deep architectures using TensorFlow. Ultimately, you'll build a foundation in both artificial intelligence, which is the concept in which machines develop the ability to simulate natural intelligence to carry out tasks, and machine learning, which is an application of AI aiming to learn from data and build on it to maximize performance. </p>
<p> Data Visualization with Python and Matplotlib Training Course </p>
<p> Through seven hours of content, you'll learn how to arrange critical data in a visual format — think graphs, charts, and pictograms. You'll also learn to deploy data visualization through Python using Matplotlib, a library that helps in viewing the data. Finally, you'll tackle actual geographical plotting using the Matplotlib extension called Basemap. </p>
<p> Computer Vision Training Course </p>
<p> In just 5.5 hours, this course gives you a more in-depth look at the role of CNNs, the knowledge of transfer learning, object localization, object detection, and using TensorFlow. You'll also learn the challenges of working with real-world data and how to tackle them head-on. </p>
<p> Natural Language Processing Training Course </p>
<p> Natural language processing (NLP) is a field of AI which allows machines to interpret and comprehend human language. Through 5.5 hours of content, you'll understand the processes involved in this field and learn how to build artificial intelligence for automation. The course itself provides an innovative methodology and sample exercises to help you dive deep into NLP. </p>
<p> Originally $656, you can slash 93% off and get a year's worth of access to the Essential AI and Machine Learning Bundle for just $39.99 right now. </p>
</article>
<article url="https://finance.yahoo.com/news/kensci-using-artificial-intelligence-machine-140000964.html" parent_folder="ai_corpus" id="file14034847" filename="kensci-using-artificial-intelligence-machine-140000964.html">
<p> +0.07(+0.38%) </p>
<p> +0.0045(+0.4101%) </p>
<p> KenSci: Using Artificial Intelligence and Machine Learning to Save Lives </p>
<p> While using artificial intelligence and machine learning to optimize health care isn’t a novel concept, KenSci proclaims its mission is more broadly to fight death with data science. By collecting big data, analyzing variables and outcomes, and suggesting cost-effective and successful solutions, KenSci is aiding medical professionals in fending off the grim reaper. Keys to the company’s success is its ability to provide customers proof of a return on investment while improving patient outcomes, as well as providing an easy path for integrating right into the systems a hospital or health facility already uses. </p>
<p> AI and health care is an active field for investing, as many companies try to tackle outcomes cross optimized with costs, and venture capitalists are paying up. According to Frost & Sullivan, the AI health market is expected to reach $6.6 billion by 2021, growing at a compound annual growth rate of 40 percent. Accenture believes that key clinical health AI applications can potentially create $150 billion in annual savings for the United States healthcare economy by 2026. </p>
<p> As an example of a recent investment, in January, Health Catalyst raised $100 million at a lofty $1 billion valuation given sales of just $110 million in 2018. This brings its total funding to $392 million. In its recent round, funding was comprised of $85 million in debt and $15 million in equity and is being used to invest in development of its data platform and increase its clinical, financial, and operational consultative teams. It touts sepsis treatment as an example where it has most successfully used AI and patient data to improve outcomes. The key has been to identify and treat correctly it as quickly as possible. This includes rapid diagnosis and making sure the correct treatment is executed. Customers can then track how compliance achieved better outcomes and saved lives. </p>
<p> While most companies are tackling care from the enterprise side, there are even consumer facing companies using AI to help users diagnose themselves. For example, K Health provides an app that asks users questions and then compares them with over a billion AI analyzed patent records to suggest possible causation and even treatment. Founded in 2016, it has already raised $44 million and has partnered with primary care providers to help drive patients to doctors when necessary. </p>
<p> Not all companies using AI in healthcare are venture-backed startups. IBM (IBM) has a big push in this area via its Watson Health division. The company offers a wide range of solutions for the health care vertical market and has select offerings using AI such as its AI Patient Companion for Hospitals. It is a turnkey solution leveraging IBM Watson and other AI technology to help improve patient outcomes, reduce labor costs, and increase hospital revenue. Labor is the biggest component of a hospital’s costs and nurses are the largest subset. This system, with a Siri type interface, answers questions for patients thus decreasing nursing labor. These questions could be things such as “When am I scheduled to go down for X-rays?” or “What is the lunch menu?” Another AI based offering is Micromedex with Watson that had been used to allow natural language queries of drug databases to help pharmacists get quick answers for drug classes, dosing and administration, medication safety, mechanism of action, pharmacokinetics and drug interactions. </p>
<p> NVIDIA (NVDA) also has a big healthcare push fueled by imagery in diagnostics that requires high-end graphics processing, its forte. It has introduced its Clara platform that enables developers to build and deploy medical imaging applications. It is the foundation to enable of intelligent instruments and automated healthcare workflows. NVIDIA takes what it learned in the graphics required for gaming and helps customers apply it to the medical imaging industry. Its SDK has been used for processing for medical reconstruction, image processing and rendering, and computational workflows for CT, MRI, and ultrasound images. In November, the company announced it is working with GE Healthcare and Nuance to bring artificial intelligence to their medical imaging solutions. The companies plan to integrate GE installed base of 50,000 machines onto NVIDIA’s platform, and to accelerate the creation and use of deep learning algorithms for its instruments. Nuance plans to bring machine learning to radiologists and data scientists through its AI Marketplace for Diagnostic Imaging, which has been built on NVIDIA’s deep learning platform. It will create algorithms to help the workflow of the radiologists, aiding them to detect and quantify clinical findings more quickly and improve care. Nuance has a large installed base of image-sharing and reporting solutions, and they are now used by 70% of radiologists. </p>
<p> In contrast to the focus on these two large companies, KenSci is more like Health Catalyst. However Health Catalyst has focused on building a data warehouse architecture and uses analytics, while KenSci has focused on AI and machine learning to improve algorithms utilizing the science where its founders excel. Two friends from India, who both earned degrees in computer science from Maharaja Sayajirao University, co-founded KenSci in 2015. KenSci is based in Seattle, Washington and has offices in India and Singapore. Its CEO, Samir Majure, has an MS in Computer Science from Perdue and a Wharton MBA. Before co-founding KenSci, he spent 17 years at Microsoft. In his last position there he managed a portfolio of CRM products and integrated online services for marketing and sales. He also successfully launched new innovative products in Small Business CRM category. In this role he had direct responsibility for managing a multi-discipline product unit of about 75 people, who included developers, program managers, and professionals in Quality Assurance, User Experience and User Assistance. The second co-founder, and the current CTO of KenSci, is Ankur Teredesai. In addition to his role at KenSci, he is a professor at the University of Washington in Seattle where he teaches applied machine learning and is Executive Director of the school’s Center for Data Science. </p>
<p> KenSci was incubated at University of Washington's Center for Data Science at University of Washington Tacoma, and designed on the cloud with help from Microsoft's Azure4Research grant program. The company got its start with grants from DARPA and NASA JPL, and partnerships with leading Health agencies like The Center for Disease Control. The KenSci platform is a set of services that are built on Microsoft Azure ML, SQL and uses Power BI. The services make it easy for machine learning workloads especially in healthcare. It is essentially a scoring platform at the heart of it, but it also has services that make it easy to develop models. It also has bank of service features out of the box with pre-implemented models to be used as a starting point. Today the company employs about 60 people with 90% located in Seattle. It has projects worldwide and boasts projects in the UK, Singapore and India where is seeks to expand further. In fact, during 2018 the company doubled in size. </p>
<p> KenSci had used AI and machine learning to predict the course of a variety of medical issues as shown below, including diabetes, CHF, COPD, CKD, and sepsis. The company's platform is based on a database of over 150 machine learning model and the algorithms are developed based on over 10 million sets of data. These data sets are clinical data (medical records), financial data (insurance and health care costs) and patient biometric data (for example heart rate). KenSci software reorders and analyzes the patient data to identify patterns that may indicate potential risks and provide predictive information. This technology can then be used to reduce the rate of hospital readmission of patients. </p>
<p> The platform has been used for a variety of custom solutions too. It has: • Improved emergency department staffing and patient experience at Rush University Medical Center • Identified lifetime healthcare costs for 9/11 first responders for the Center for Disease Control (CDC) • Reduced the cost of prescriptions at a system level without sacrificing quality for Beaumont Health in Michigan • And created risk stratification and readmission predictions for military personnel for the Madigan Army Medical Center. </p>
<p> One fascinating project the company took on using CDC data is a look at predicting the opioid crisis using historical data from 1999 to 2015. By taking data from all US counties, the company is able to predict how widespread the problem may become in a few short years as deaths are increasing logarithmically throughout the country with current hotspots in New Mexico and Appalachia. </p>
<p> On Friday, the company announced it had raised its second round of financing. It raised $22 million in Series B funding. The round was led by Polaris Partners, and was joined by investors UL ventures and included additional funding from Ignition Partners, Osage University Partners, and Mindset Ventures. This round brings KenSci's total funding to $30.5 million. </p>
<p> Back in January of 2017, the company raised $8.5 million in a Series A round led by Bellevue-based firm Ignition Partners, and included Osage University Partners and Mindset Ventures. The company used the funds to increase its workforce and invest in sales, marketing and customer service to support more customers. </p>
<p> With its new capital it has quickly moved to strengthen its staff. On the 23rd of January, it announced four strategic hires in engineering. All four have experience in AI, healthcare and cloud solutions for enterprises. </p>
<p> The new hires are: • Sudarshan Chitre, former Vice President of Engineering at Oracle, who brought with him 20 years of experience building software for enterprise and consumers. In his career, he has had the opportunity to lead teams of exceptional engineers to build v1 cloud platform services for Azure (HDinsight) and AWS (Internet of things). He was also the technical co-founder of Brimbee and held various roles at Amazon. He began his career at Microsoft where he spent 16 years. </p>
<p> • Ryan Brush, former Distinguished Engineer at Cerner, spent the last several years there on data engineering, analysis, and the application of very large healthcare datasets. He created Clara, an open source rules engine, Bunsen, an open source library for large-scale analysis of FHIR datasets, and has spoken at conferences including Strata, Strangeloop, ApacheCon, FHIR DevDays, and others. As an author, Ryan has contributed chapters to the books 97 Things Every Programmer Should Know and Hadoop: The Definitive Guide. </p>
<p> • Neelesh Kamkolkar, former Lead of Product Management at Tableau, brought over 15 years of experience building platforms, solutions, and services. Most recently, he led enterprise product management at Tableau Software, where he built a platform that enabled data analytics to be accessible to everyone in a secure, scalable way. </p>
<p> • Tim Kellogg, former Senior Software Engineer, at Amazon Web Services, brought with him over a decade of experience. As an experienced full stack software engineer with a proven track record of building performance-critical systems, Tim has a comprehensive knowledge of garbage collection and JIT compilation in .NET that he has used to build scalable applications in C#. </p>
<p> SUBSCRIBE TO ZACKS SMALL CAP RESEARCH to receive our articles and reports emailed directly to you each morning. Please visit our website for additional information on Zacks SCR. </p>
<p> DISCLOSURE: Zacks SCR has received compensation from the issuer directly or from an investor relations consulting firm, engaged by the issuer, for providing research coverage for a period of no less than one year. Research articles, as seen here, are part of the service Zacks provides and Zacks receives quarterly payments totaling a maximum fee of $30,000 annually for these services. Full Disclaimer HERE. </p>
</article>
<article url="https://mashable.com/2016/12/19/microsoft-machine-learning-artificial-intelligence-blindness-india/" parent_folder="ai_corpus" id="file14034854" filename="microsoft-machine-learning-artificial-intelligence-blindness-india">
<p> Tech </p>
<p> Microsoft is using machine learning to help fight blindness </p>
<p> Though robots and artificial intelligence may not replace our doctors entirely in the foreseeable future, they are already starting to make a difference. </p>
<p> Microsoft is now using machine learning and artificial intelligence to help doctors in India to diagnoze and treat eye diseases. </p>
<p> Earlier this year, Microsoft began working with the not-for-profit LV Prasad Eye Institute (LVPEI) in India to have its Azure machine learning and Power BI services analyze patterns among cases and predict the surgical outcome of eye surgery patients. </p>
<p> The collaboration saw Microsoft going through a trove of data — anonymized records of 1.1 million people — and provide doctors with insights into how the blindness spreads in the country, Anil Bhansali, Managing Director of Microsoft India (R&D), explained to Mashable India in a conversation. </p>
<p> Microsoft says it utilized Azure machine learning service to crunch the numbers and Power BI service to visualize those numbers to make sense out of them. These numbers helped the doctors, Microsoft says, to ascertain how much time a patient has before their eye issues extrapolate. </p>
<p> Microsoft says after going through such voluminous data, its AI-platform was also able to predict how likely it is that doctors will be able to successfully perform eye surgeries. Though the company didn't share how accurate its projections have been, it said it is ready to expand the initiatives with other academic and research organizations. </p>
<p> Today the company announced it has partnered with Bascom Palmer - University of Miami, Flaum Eye Institute - University of Rochester (USA), Federal University of Sao Paulo (Brazil), and Brien Holden Vision Institute (Australia). </p>
<p> As part of the partnership, Microsoft and institutes will closely work on the diverse datasets of patients across geographies to find predictive models for vision impairment and eye disease. </p>
<p> Some of the issues that doctors and Microsoft would be working on include finding the rate of change of myopia in children and conditions that impact children's eyesight. They will also try to predict outcomes of refractive surgery and determine optimal surgery parameters for higher probability of success. </p>
<p> India accounts for nearly 55 million of the 285 million eye disease cases worldwide. Bhansali says it was one of the reasons why the company piloted the initiative in India. </p>
<p> India accounts for nearly 55 million of the 285 million eye disease cases worldwide. </p>
<p> The company maintains several other AI-driven initiatives in India, such as digital agricultural applications, and its work with the Andhra Pradesh sate government to help identify students who are likely to drop out. </p>
<p> Microsoft isn't the only Silicon Valley giant trying to make use of its artificial intelligence platforms to better serve Indians, though. In July, for instance, Manipal Hospitals partnered with IBM Watson at six locations to provide information and insights to physicians to help them identify personalized, evidence-based cancer care options across India. </p>
<p> IBM's Watson has gotten impressively accurate over the years. At the University of North Carolina School of Medicine, Watson was able to recommend the same treatment as human experts for cancer diagnosis 99 percent of the time. More interestingly, in 30 percent of the cases, Watson found treatment options that the doctors had missed. </p>
</article>
<article url="https://mashable.com/2017/02/20/microsoft-satya-nadella-artificial-intelligence-focus/" parent_folder="ai_corpus" id="file14034855" filename="microsoft-satya-nadella-artificial-intelligence-focus">
<p> Tech </p>
<p> Microsoft CEO says artificial intelligence is the 'ultimate breakthrough' </p>
<p> Microsoft CEO Satya Nadella spoke at a public event in India on Monday, stressing upon the immense potential of artificial intelligence (AI), calling it the "ultimate breakthrough" in technology. </p>
<p> "Because for all the advances in computer interface, there is nothing to beat language [the ability to do human-level speech recognition]," he said during a fireside chat with Nandan Nilekani — India's premier technocrat and the brain behind the Aadhaar identification system. </p>
<p> The chat was streamed live on the Microsoft Developer page on Facebook. </p>
<p> Nadella and Nilekani were later joined by Binny Bansal, CEO of Flipkart, India's largest e-commerce company that announced a cloud partnership with Microsoft's Azure. </p>
<p> Calling AI "the third run time", Nadella said, "If the operating system was the first run time, the second run time you could say was the browser, and the third run time can actually be the agent. Because in some sense, the agent knows you, your work context, and knows the work. And that's how we are building Cortana. We are giving it a really natural language understanding." </p>
<p> AI has been the buzzword at Microsoft for a while now. And the CEO has gone on record to say that it "is at the intersection of our ambitions.” Cortana is an intelligent assistant (agent) that “can take text input, can take speech input, and that knows you deeply." </p>
<p> However, until not very long ago, AI had few takers, as revealed by Flipkart's Bansal. </p>
<p> "When I was in IIT-Delhi from 2001-2005, we had a course on AI and nobody wanted to take it because nothing was happening in AI. What has changed?" he asked Nadella. </p>
<p> The Microsoft chief responded: "If I broadly talk about AI including machine learning, the thing that's been most exciting in the last five years is this one specialized branch of 'deep neural network' that is fundamentally giving us human perception, whether it is speech or image recognition, and that's just magical to see." </p>
<p> Nadella went on to cite one of Microsoft's projects in the state of Punjab in northern India. "We took all the call center data around public services and analyzed the speech so that the government could get a better handle on issues from people who were happy with their services." </p>
<p> However, despite all the buzz around AI, Nadella warned that we shouldn't "over-hype" it. </p>
<p> "We should not claim that artificial general intelligence is just around the corner," he said. "I think we are on the right ladder this time... We are all grounded in where we are. Ultimately, the real challenge is human language understanding that still doesn't exist. We are not even close to it... We just have to keep taking steps on that ladder." </p>
<p> Nadella also mentioned augmented reality (AR) as one of the things that's keeping him "very excited." </p>
<p> "The first time I put on a HoloLens was to see something Cleveland Clinic [a non-profit academic medical center] had built for medical innovation... As an electrical engineer who never understood Maxwell's equations, I thought if I had a HoloLens, I would have been a better electrical engineer. Overall I feel that augmented reality is perhaps the ultimate computer," he said. </p>
</article>
<article url="https://mashable.com/shopping/oct-29-machine-learning-artificial-intelligence-course-bundle/" parent_folder="ai_corpus" id="file14034858" filename="oct-29-machine-learning-artificial-intelligence-course-bundle">
<p> Shopping </p>
<p> Learn AI and machine learning from a top online instructor for $29 </p>
<p> Just to let you know, if you buy something featured here, Mashable might earn an affiliate commission. </p>
<p> By StackCommerceMashable Shopping2019-10-29 09:00:00 UTC </p>
<p> Artificial intelligence is no longer just the plot of sci-fi movies. It's here and it's one of the fastest growing tech sectors. In fact, AI powers everything from self-driving cars to Netflix suggestions. And you know how your internet browser seems way too familiar with your interests? Yup, AI and machine learning are to blame. </p>
<p> This bundle includes eight different courses and 44 hours of training, led by top instructor Minerva Singh, that you can access any time. You'll explore ways to use programming languages like Python and frameworks like Tensorflow to discover the power of big data. Then you'll dive into basic analysis tools like Numpy Arrays and Matrices and data structures and reading in Pandas to store, filter, manage, and manipulate data in Python. Plus, you'll complete hands-on labs to learn machine learning terminology and processes in order to make computers learn for themselves. </p>
<p> If this sounds like a heavy course load, that's because it is. But, don't worry, you'll have lifetime access so you can study it as often as you wish. There won't be any robots taking over your life after these courses. </p>
<p> Learn how to build machines that think for themselves with the Machine Learning & Artificial Intelligence Certification Bundle, which is on sale now for just $29 (or just $3.62 per course). That's a whopping 98% savings. </p>
</article>
<article url="https://uk.finance.yahoo.com/news/rib-software-se-rib-software-094012894.html" parent_folder="ai_corpus" id="file14034860" filename="rib-software-se-rib-software-094012894.html">
<p> -213.93(-2.95%) </p>
<p> -3.49(-1.79%) </p>
<p> -41.14(-1.25%) </p>
<p> RIB Software SE: RIB Software strengthens its Internet of Things (IoT), Artificial Intelligence (AI), Machine Learning (ML) and Blockchain R&D capabilities through investment into leading emerging tech software provider Winjit </p>
<p> DGAP-News: RIB Software SE / Key word(s): Investment 02.08.2019 / 11:40 The issuer is solely responsible for the content of this announcement. </p>
<p> 02-August-2019 </p>
<p> RIB Software strengthens its Internet of Things (IoT), Artificial Intelligence (AI), Machine Learning (ML) and Blockchain R&D capabilities through investment into leading emerging tech software provider Winjit </p>
<p> Hong Kong & Nashik, India, 02 August 2019. RIB Software SE, the world's leading provider of iTWO 4.0 Cloud Enterprise Platform Technology for the construction and real estate industries, today announced the successful closing of an investment into leading Indian-based IoT, AI, ML and Blockchain software provider Winjit. </p>
<p> 40% organic growth p.a. and controlling interest within four years </p>
<p> The investment is based on an EBITDA multiple of 7x on expected fiscal year 2019 EBITDA. RIB acquires a 15% stake in Winjit and has the option to acquire a further controlling interest in Winjit through call options exercisable over the next 4 years. Winjit's organic growth is expected to reach 40% p.a. </p>
<p> Award winning company "Top 10 IoT and AI solutions provider of India" </p>
<p> Winjit's cutting-edge software in the fields of artificial intelligence, machine learning and IoT has been recognized through several awards, such as The Economics Times India MSE Award and being nominated as one of the ten most promising industrial IoT solutions providers by CIO Insider in 2019, as well as one of the ten most recommended AI solution providers. </p>
<p> 300 IT Experts with focus on the United States plus 35 countries </p>
<p> With over 300 IT experts in New York, Johannesburg, Bangalore, Nashik and Pune, Winjit supports global clients on digital transformation in more than 35 countries, with a strong focus on the US market. </p>
<p> MTWO New Software Modules IoTSense, PredictSense & VisionSense can win 100.000 MTWO Platform users in the midterm </p>
<p> With their products IoTSense, PredictSense and VisionSense, Winjit has developed state-of-the-art software applications, which will be integrated into the RIB MTWO vertical cloud platform: IoTSense is an advanced full-scale IoT Platform, which connects modern as well legacy protocol sensors on the edge & cloud securely to provide real-time analytics, rule-based actions & machine-to-machine communication; PredictSense is an automated machine learning platform that helps organizations solve complex real-time business problems with high-power algorithms on an open API structure; and with VisionSense, Winjit is bringing image recognition solutions to various industries' process challenges. </p>
<p> The integration will accelerate the digitalization and automation of the AEC industry by bringing Winjit's emerging tech IPR applications, that span IoT, AL & ML, and blockchain into RIB's product portfolio and MTWO platform technology. Particularly the planned integration of Winjit's software products into iTWO Facility Management and into iTWO Supply Chain Management will contribute to this target. </p>
<p> Founded in 2004 by two young Indian entrepreneurs, Abhijit Junagade and Ashwin Kandoi, Winjit has spent almost two decades in building up its core competencies in emerging technologies, such as IoT, AI & ML, blockchain and fintech solutions. These technologies are crucial components in the MTWO product portfolio and MTWO platform and will enable new digital business models in the AEC and EPC industries. </p>
<p> Winjit's set of solutions will also provide further momentum to RIB's push for the world's first artificial intelligence engineer, McTWO. Winjit's and RIB's technology stack will work as complements, using the MTWO infrastructure backbone. </p>
<p> Abhijit Junagade, CEO of Winjit: "We are excited at Winjit to be a part of the RIB family. Our strategy and focus on IoT, Artificial Intelligence and Machine Learning software applications aligns with RIB's MTWO platform. We are looking forward to work closely with RIB teams worldwide in the AEC industry. RIB's commitment to Winjit proves the scalability of its business model. This partnership further strengthens Winjit to serve its customers and employees much better worldwide." </p>
<p> Tom Wolf, CEO of RIB Group: "IoT, AI, Machine Learning and Blockchain are the direction of future technologies for smart city and smart living. I am very happy to work with the two young and visionary entrepreneurs, Abhijit Junagade and Ashwin Kandoi, who shared the same vision with me to deliver the best infrastructure for the next generation. The investment in Winjit demonstrates RIB Group's strong commitment to further strengthen our solution portfolio to advance the industry." </p>
<p> About Winjit </p>
<p> Founded in 2004 by tech entrepreneurs Abhijit Junagade and Ashwin Kandoi, Nashik-based Winjit is India's leading provider of innovative software engineering solutions. Winjit employs more than 300 experts in the fields of IoT, AI, ML and Blockchain and offers its products and services to clients worldwide. Supported by sales offices in South Africa (Johannesburg) and the United States (New York and San Francisco), Winjit has and continues to successfully deliver emerging tech solutions to its 100+ global clients. Through its growing line of software solutions, Winjit has created a quickly deployable set of IoT, AI and ML solutions that make emerging tech a reality for their clients. </p>
<p> RIB Software SE is an innovator in building and construction industry. The company creates, develops and offers cutting-edge digital technologies for construction enterprises and projects across various industries worldwide. iTWO 4.0, RIB's flagship cloud-based platform, provides the world's first enterprise cloud technology based on 5D BIM with AI integration for construction companies, industrial companies, developers and project owners, etc. With over 50 years of experiences in construction industry, RIB Software SE focuses on IT and engineering and becomes the pioneer in construction innovation, exploring and bringing in new thinking, new working methods and new technologies to enhance construction productivity. RIB is headquartered in Stuttgart, Germany and Hong Kong, China, and listed on the prime standard Frankfurt Stock Exchange since 2011. With over 1,200 talents in more than 30 locations worldwide, RIB is targeting to transform the construction industry into the most advanced and digitalized industry in the 21st century. </p>
<p> 02.08.2019 Dissemination of a Corporate News, transmitted by DGAP - a service of EQS Group AG. The issuer is solely responsible for the content of this announcement. </p>
<p> The DGAP Distribution Services include Regulatory Announcements, Financial/Corporate News and Press Releases. Archive at www.dgap.de </p>
<p> Regulated Market in Frankfurt (Prime Standard); Regulated Unofficial Market in Berlin, Dusseldorf, Hamburg, Munich, Stuttgart, Tradegate Exchange </p>
</article>
<article url="https://finance.yahoo.com/news/vectorspace-ai-datasets-now-available-161500065.html" parent_folder="ai_corpus" id="file14034848" filename="vectorspace-ai-datasets-now-available-161500065.html">
<p> -40.74(-1.24%) </p>
<p> -409.13(-1.42%) </p>
<p> -94.45(-1.02%) </p>
<p> -28.07(-1.70%) </p>
<p> -0.16(-0.31%) </p>
<p> +1.40(+0.09%) </p>
<p> +0.07(+0.38%) </p>
<p> +0.0045(+0.4101%) </p>
<p> Vectorspace AI Datasets are Now Available to Power Machine Learning (ML) and Artificial Intelligence (AI) Systems in Collaboration with Elastic </p>
<p> SAN FRANCISCO, Jan. 22, 2020 /PRNewswire/ -- Vectorspace AI (VXV) announces datasets that power data engineering, machine learning (ML) and artificial intelligence (AI) systems. Vectorspace AI alternative datasets are designed for predicting unique hidden relationships between objects including current and future price correlations between equities. </p>
<p> Vectorspace AI enables data, ML and Natural Language Processing/Understanding (NLP/NLU) engineers and scientists to save time by testing a hypothesis or running experiments faster to achieve an improvement in bottom line revenue and information discovery. Vectorspace AI datasets underpin most of ML and AI by improving returns from R&D divisions of any company in discovering hidden relationships in drug development. </p>
<p> "We are happy to be working with Vectorspace AI based on their most recent collaboration with us based on the article we published titled 'Generating and visualizing alpha with Vectorspace AI datasets and Canvas'. They represent the tip of the spear when it comes to advances in machine learning and artificial intelligence. Our customers and partners will certainly benefit from our continued joint development efforts in ML and AI," Shaun McGough, Product Engineering, Elastic. </p>
<p> Increasing the speed of discovery in every industry remains the aim of Vectorspace AI, along with a particular goal which relates to engineering machines to trade information with one another, connected to exchanging and transacting data in a way that minimizes a selected loss function. Data vendors such as Neudata.co, asset management companies and hedge funds including WorldQuant, use Vectorspace AI datasets to improve and protect 'alpha'. </p>
<p> Limited releases of Vectorspace AI datasets will be available in partnership with Amazon and Microsoft. </p>
<p> Vectorspace AI focuses on context-controlled NLP/NLU (Natural Language Processing/Understanding) and feature engineering for hidden relationship detection in data for the purpose of powering advanced approaches in Artificial Intelligence (AI) and Machine Learning (ML). Our platform powers research groups, data vendors, funds and institutions by generating on-demand NLP/NLU correlation matrix datasets. We are particularly interested in how we can get machines to trade information with one another or exchange and transact data in a way that minimizes a selected loss function. Our objective is to enable any group analyzing data to save time by testing a hypothesis or running experiments with higher throughput. This can increase the speed of innovation, novel scientific breakthroughs and discoveries. For a little more on who we are, see our latest reddit AMA on r/AskScience or join our 24 hour communication channel here. Vectorspace AI offers NLP/NLU services and alternative datasets consisting of correlation matrices, context-controlled sentiment scoring, and other automatically engineered feature attributes. These services are available utilizing the VXV token and VXV wallet-enabled API. Vectorspace AI is a spin-off from Lawrence Berkeley National Laboratory (LBNL) and the U.S. Dept. of Energy (DOE). The team holds patents in the area of hidden relationship discovery. </p>
</article>
